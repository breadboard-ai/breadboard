{
  "title": "Inferring a query for the RAG pattern",
  "description": "This board is a prototype to infer the query from the original prompt for  retrieval-augmented generation (RAG). The basic idea is that the user provides a template with a placeholder for the retrieved data, and the query to retrieve this data is inferred from the template itself.",
  "version": "0.0.1",
  "edges": [
    {
      "from": "questionGenerator",
      "to": "printResults",
      "out": "completion",
      "in": "text"
    },
    {
      "from": "secrets-1",
      "to": "questionGenerator",
      "out": "PALM_KEY",
      "in": "PALM_KEY"
    },
    {
      "from": "inferringPrompt",
      "to": "questionGenerator",
      "out": "prompt",
      "in": "text"
    },
    {
      "from": "promptStuffer",
      "to": "inferringPrompt",
      "out": "result",
      "in": "result"
    },
    {
      "from": "promptToInfer",
      "to": "promptStuffer",
      "out": "prompt",
      "in": "json"
    },
    {
      "from": "askForTemplate",
      "to": "promptToInfer",
      "out": "text",
      "in": "template"
    }
  ],
  "nodes": [
    {
      "id": "askForTemplate",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Template",
              "format": "multiline",
              "description": "Provide the text of the template, using {{context}} to specify location of context to be retrieved."
            }
          }
        }
      }
    },
    {
      "id": "printResults",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Result",
              "description": "The final result of RAG with inferrred query."
            }
          }
        }
      }
    },
    {
      "id": "promptToInfer",
      "type": "promptTemplate",
      "configuration": {
        "context": "\n\nCONTEXT GOES HERE\n\n"
      }
    },
    {
      "id": "inferringPrompt",
      "type": "promptTemplate",
      "configuration": {
        "template": "\nThe JSON below represents a prompt that the user wants to populate with more context to better answer questions within the prompt. The context will supplied by a search engine and will be inserted in place of the \"CONTEXT GOES HERE\" placeholder.\n\nYour job is to analyze the prompt and summarize all of the information within it, then formulate a query that would allow retrieving the relevant context from a search engine.\n\nReply as valid JSON in the following format:\n{\n  \"summary: [\n    \"the list of points in the prompt that will be used to formulate the query\"\n  ]\n  \"query\": \"the detailed, comprehensive query that may consist of several questions\"\n}\n\nJSON:\n{{result}}\n\nQuestion:"
      }
    },
    {
      "id": "promptStuffer",
      "type": "jsonata",
      "configuration": {
        "expression": "{ \"prompt\": $ }"
      }
    },
    {
      "id": "questionGenerator",
      "type": "palm-generateText"
    },
    {
      "id": "secrets-1",
      "type": "secrets",
      "configuration": {
        "keys": [
          "PALM_KEY"
        ]
      }
    }
  ],
  "kits": [
    {
      "url": "npm:@google-labs/llm-starter"
    },
    {
      "url": "npm:@google-labs/palm-kit"
    }
  ]
}