{
  "title": "The simplest LLM-based recipe",
  "description": "This recipe is as simple as it gets: takes text as input and invokes Gemini to generate a text response as output.",
  "version": "0.0.3",
  "edges": [
    {
      "from": "gemini",
      "to": "response",
      "out": "*",
      "in": ""
    },
    {
      "from": "text",
      "to": "gemini",
      "out": "*",
      "in": ""
    }
  ],
  "nodes": [
    {
      "id": "response",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Response",
              "description": "The completion generated by the LLM"
            }
          },
          "required": [
            "text"
          ]
        }
      }
    },
    {
      "id": "gemini",
      "type": "invoke",
      "configuration": {
        "path": "/graphs/gemini-generator.json"
      }
    },
    {
      "id": "text",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Prompt",
              "description": "The prompt to generate a completion for",
              "examples": [
                "Tell me a fun story about playing with breadboards"
              ]
            }
          },
          "required": [
            "text"
          ]
        }
      }
    }
  ],
  "graphs": {}
}