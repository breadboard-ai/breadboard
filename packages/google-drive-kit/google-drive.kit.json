{
  "title": "Google Drive Kit",
  "description": "Components for reading & writing to files in Google Drive, including Docs and Sheets",
  "version": "0.0.1",
  "url": "npm:@breadboard-ai/google-drive-kit",
  "exports": [
    "#getFileContent",
    "#listFiles",
    "#exportFile",
    "#getBreadboardFolder",
    "#saveContextToDrive",
    "#loadContextFromDrive",
    "#appendToDoc",
    "#readFromDoc",
    "#contextToSlides"
  ],
  "graphs": {
    "getFileContent": {
      "title": "Get File Content",
      "description": "Get the content of a file in Google Drive",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-1",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "output-0",
          "out": "response",
          "in": "content"
        },
        {
          "from": "input-0",
          "to": "runJavascript-0",
          "out": "fileId",
          "in": "fileId"
        },
        {
          "from": "runJavascript-0",
          "to": "urlTemplate-0",
          "out": "id",
          "in": "fileId"
        },
        {
          "from": "runJavascript-1",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-0",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "fileId": {
                  "type": "object",
                  "behavior": [
                    "google-drive-file-id",
                    "config"
                  ],
                  "title": "File ID",
                  "description": "The ID of the file.\nSee https://developers.google.com/drive/api/reference/rest/v3/files/get#body.PATH_PARAMETERS.file_id",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "preview": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "id",
                    "preview"
                  ],
                  "additionalProperties": false
                }
              },
              "required": [
                "fileId"
              ]
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "content": {
                  "type": [
                    "array",
                    "boolean",
                    "null",
                    "number",
                    "object",
                    "string"
                  ],
                  "title": "Content",
                  "description": "The content of the file"
                }
              },
              "required": [
                "content"
              ]
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {}
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({fileId:fileId2})=>{return{id:fileId2.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "fileId": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "preview": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "id",
                    "preview"
                  ],
                  "additionalProperties": false,
                  "behavior": [
                    "google-drive-file-id",
                    "config"
                  ]
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-1",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files/{fileId}?alt=media"
          }
        }
      ]
    },
    "listFiles": {
      "title": "List Files",
      "description": "List files in Google Drive.\n\nSee https://developers.google.com/drive/api/guides/search-files for more details.",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "cast-0",
          "to": "unnest-0",
          "out": "value",
          "in": "nested"
        },
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-0",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "cast-0",
          "out": "response",
          "in": "value"
        },
        {
          "from": "input-0",
          "to": "urlTemplate-0",
          "out": "query",
          "in": "query"
        },
        {
          "from": "runJavascript-0",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "unnest-0",
          "to": "output-0",
          "out": "files",
          "in": "files"
        },
        {
          "from": "unnest-0",
          "to": "output-0",
          "out": "incompleteSearch",
          "in": "incompleteSearch"
        },
        {
          "from": "unnest-0",
          "to": "output-0",
          "out": "nextPageToken",
          "in": "nextPageToken",
          "optional": true
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-0",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string",
                  "behavior": [
                    "google-drive-query"
                  ],
                  "title": "Query",
                  "description": "A Google Drive search query.\nSee https://developers.google.com/drive/api/guides/search-files for details.",
                  "examples": [
                    "'<folder id>' in parents",
                    "name = 'hello'",
                    "fullText contains 'hello'",
                    "mimeType = 'application/vnd.google-apps.folder'",
                    "sharedWithMe and name contains 'hello'"
                  ]
                }
              },
              "required": [
                "query"
              ]
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  },
                  "title": "Files",
                  "description": "The list of files. If nextPageToken is populated, then this list may be incomplete and an additional page of results should be fetched.\n\nSee https://developers.google.com/drive/api/reference/rest/v3/files/list#body.FileList.FIELDS.files"
                },
                "incompleteSearch": {
                  "type": "boolean",
                  "title": "Incomplete Search",
                  "description": "Whether the search process was incomplete. If true, then some search results might be missing, since all documents were not searched. This can occur when searching multiple drives with the 'allDrives' corpora, but all corpora couldn't be searched. When this happens, it's suggested that clients narrow their query by choosing a different corpus such as 'user' or 'drive'.\n\nSee https://developers.google.com/drive/api/reference/rest/v3/files/list#body.FileList.FIELDS.incomplete_search"
                },
                "nextPageToken": {
                  "type": "string",
                  "title": "Next Page Token",
                  "description": "The page token for the next page of files. This will be absent if the end of the files list has been reached. If the token is rejected for any reason, it should be discarded, and pagination should be restarted from the first page of results. The page token is typically valid for several hours. However, if new items are added or removed, your expected results might differ.\n\nSee https://developers.google.com/drive/api/reference/rest/v3/files/list#body.FileList.FIELDS.next_page_token"
                }
              },
              "required": [
                "files",
                "incompleteSearch"
              ]
            }
          }
        },
        {
          "id": "cast-0",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#fileList"
                  ]
                },
                "nextPageToken": {
                  "type": "string"
                },
                "incompleteSearch": {
                  "type": "boolean"
                },
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "kind",
                "incompleteSearch",
                "files"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {}
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "unnest-0",
          "type": "unnest",
          "configuration": {}
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files?q={query}"
          }
        }
      ]
    },
    "exportFile": {
      "title": "Export File",
      "description": "Export a Google Workspace document to the requested MIME type.",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-1",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "output-0",
          "out": "response",
          "in": "content"
        },
        {
          "from": "input-0",
          "to": "runJavascript-0",
          "out": "fileId",
          "in": "fileId"
        },
        {
          "from": "input-0",
          "to": "urlTemplate-0",
          "out": "mimeType",
          "in": "mimeType"
        },
        {
          "from": "runJavascript-0",
          "to": "urlTemplate-0",
          "out": "id",
          "in": "fileId"
        },
        {
          "from": "runJavascript-1",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-0",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "fileId": {
                  "type": "object",
                  "behavior": [
                    "google-drive-file-id",
                    "config"
                  ],
                  "title": "File ID",
                  "description": "The ID of the Google Drive file.\nSee https://developers.google.com/drive/api/reference/rest/v3/files/export#body.PATH_PARAMETERS.file_id",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "preview": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "id",
                    "preview"
                  ],
                  "additionalProperties": false
                },
                "mimeType": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ],
                  "title": "MIME Type",
                  "description": "The MIME type of the format requested for this export.\nSee https://developers.google.com/drive/api/reference/rest/v3/files/export#body.QUERY_PARAMETERS.mime_type"
                }
              },
              "required": [
                "fileId",
                "mimeType"
              ]
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "content": {
                  "type": [
                    "array",
                    "boolean",
                    "null",
                    "number",
                    "object",
                    "string"
                  ],
                  "title": "Content",
                  "description": "The content of the file\nSee https://developers.google.com/drive/api/reference/rest/v3/files/export#response-body"
                }
              },
              "required": [
                "content"
              ]
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {}
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({fileId:fileId2})=>{return{id:fileId2.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "fileId": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string"
                    },
                    "preview": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "id",
                    "preview"
                  ],
                  "additionalProperties": false,
                  "behavior": [
                    "google-drive-file-id",
                    "config"
                  ]
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-1",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files/{fileId}/export{?mimeType}"
          }
        }
      ]
    },
    "getBreadboardFolder": {
      "title": "Get Breadboard Folder",
      "description": "Gets (or creates if doesn't exist) a dedicated \"Breadboard\" folder in Google Drive. This folder can be used for story various Breadboard-specifc assets and boards.",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "cast-0",
          "to": "runJavascript-0",
          "out": "value",
          "in": "response"
        },
        {
          "from": "cast-1",
          "to": "runJavascript-3",
          "out": "value",
          "in": "createFolderResponse"
        },
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-2",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "cast-0",
          "out": "response",
          "in": "value"
        },
        {
          "from": "fetch-1",
          "to": "cast-1",
          "out": "response",
          "in": "value"
        },
        {
          "from": "input-0",
          "to": "runJavascript-4",
          "out": "folderName",
          "in": "folderName"
        },
        {
          "from": "runJavascript-0",
          "to": "output-0",
          "out": "id",
          "in": "id"
        },
        {
          "from": "runJavascript-0",
          "to": "runJavascript-4",
          "out": "notFound",
          "in": "notFound"
        },
        {
          "from": "runJavascript-1",
          "to": "urlTemplate-0",
          "out": "query",
          "in": "query"
        },
        {
          "from": "runJavascript-2",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-2",
          "to": "fetch-1",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-3",
          "to": "output-1",
          "out": "id",
          "in": "id"
        },
        {
          "from": "runJavascript-4",
          "to": "fetch-1",
          "out": "body",
          "in": "body"
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-0",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "folderName": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ],
                  "title": "Name",
                  "description": "The name of the folder. \"Breadboard\" will be used if not specified.",
                  "default": "Breadboard"
                }
              },
              "required": []
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              },
              "required": [
                "id"
              ]
            }
          },
          "metadata": {
            "title": "Get Folder Output",
            "description": "Outputting ID of the existing folder"
          }
        },
        {
          "id": "output-1",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              },
              "required": [
                "id"
              ]
            }
          },
          "metadata": {
            "title": "Create Folder Output",
            "description": "Outputtting ID of the newly created folder"
          }
        },
        {
          "id": "cast-0",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#fileList"
                  ]
                },
                "nextPageToken": {
                  "type": "string"
                },
                "incompleteSearch": {
                  "type": "boolean"
                },
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "kind",
                "incompleteSearch",
                "files"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "cast-1",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#file"
                  ]
                },
                "mimeType": {
                  "type": "string"
                },
                "id": {
                  "type": "string"
                },
                "name": {
                  "type": "string"
                },
                "resourceKey": {
                  "type": "string"
                }
              },
              "required": [
                "kind",
                "mimeType",
                "id",
                "name"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {},
          "metadata": {
            "title": "List Files",
            "description": "Calling the List Files API"
          }
        },
        {
          "id": "fetch-1",
          "type": "fetch",
          "configuration": {
            "method": "POST",
            "url": "https://www.googleapis.com/drive/v3/files"
          },
          "metadata": {
            "title": "Create Folder",
            "description": "Calling the File Create API"
          }
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({response})=>{const first=response.files?.at(0);if(!first){return{notFound:true}}return{id:first.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "response": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#fileList"
                      ]
                    },
                    "nextPageToken": {
                      "type": "string"
                    },
                    "incompleteSearch": {
                      "type": "boolean"
                    },
                    "files": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "kind": {
                            "type": "string",
                            "enum": [
                              "drive#file"
                            ]
                          },
                          "mimeType": {
                            "type": "string"
                          },
                          "id": {
                            "type": "string"
                          },
                          "name": {
                            "type": "string"
                          },
                          "resourceKey": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "kind",
                          "mimeType",
                          "id",
                          "name"
                        ],
                        "additionalProperties": false
                      }
                    }
                  },
                  "required": [
                    "kind",
                    "incompleteSearch",
                    "files"
                  ],
                  "additionalProperties": false
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                },
                "notFound": {
                  "type": "boolean"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Route from List",
            "description": "Deciding whether to create a new folder"
          }
        },
        {
          "id": "runJavascript-1",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ()=>{return{query:`appProperties has { key = 'breadboard' and value = 'root' } and trashed = false`}};",
            "inputSchema": {
              "type": "object",
              "properties": {}
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Create List Query",
            "description": "Creating a query to list the files."
          }
        },
        {
          "id": "runJavascript-2",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-3",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({createFolderResponse:createFolderResponse2})=>{return{id:createFolderResponse2.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "createFolderResponse": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#file"
                      ]
                    },
                    "mimeType": {
                      "type": "string"
                    },
                    "id": {
                      "type": "string"
                    },
                    "name": {
                      "type": "string"
                    },
                    "resourceKey": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "kind",
                    "mimeType",
                    "id",
                    "name"
                  ],
                  "additionalProperties": false
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Get ID",
            "description": "Retrieving ID of the newly created folder"
          }
        },
        {
          "id": "runJavascript-4",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({folderName:folderName2})=>{folderName2??=\"Breadboard\";return{body:{name:folderName2,mimeType:\"application/vnd.google-apps.folder\",appProperties:{breadboard:\"root\"}}}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "notFound": {
                  "type": "boolean"
                },
                "folderName": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ]
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": false
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Make Body",
            "description": "Make body of the \"Create Folder\" API call"
          }
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files?q={query}"
          }
        }
      ]
    },
    "saveContextToDrive": {
      "title": "Save Context To Drive",
      "description": "Saves LLM Conversation Context to Google Drive.",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "cast-0",
          "to": "passthrough-0",
          "out": "value",
          "in": "saveContextResponse"
        },
        {
          "from": "cast-1",
          "to": "runJavascript-2",
          "out": "value",
          "in": "createFolderResponse"
        },
        {
          "from": "cast-2",
          "to": "runJavascript-5",
          "out": "value",
          "in": "response"
        },
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-0",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-3",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "cast-0",
          "out": "response",
          "in": "value"
        },
        {
          "from": "fetch-1",
          "to": "cast-1",
          "out": "response",
          "in": "value"
        },
        {
          "from": "fetch-2",
          "to": "cast-2",
          "out": "response",
          "in": "value"
        },
        {
          "from": "input-0",
          "to": "passthrough-0",
          "out": "context",
          "in": "context"
        },
        {
          "from": "input-0",
          "to": "runJavascript-1",
          "out": "context",
          "in": "context"
        },
        {
          "from": "input-0",
          "to": "runJavascript-1",
          "out": "key",
          "in": "key"
        },
        {
          "from": "input-0",
          "to": "runJavascript-4",
          "out": "breadboardFolderId",
          "in": "rootId"
        },
        {
          "from": "input-0",
          "to": "runJavascript-6",
          "out": "breadboardFolderId",
          "in": "rootId"
        },
        {
          "from": "passthrough-0",
          "to": "output-0",
          "out": "context",
          "in": "context"
        },
        {
          "from": "runJavascript-0",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-1",
          "to": "fetch-0",
          "out": "body",
          "in": "body"
        },
        {
          "from": "runJavascript-2",
          "to": "runJavascript-1",
          "out": "id",
          "in": "id"
        },
        {
          "from": "runJavascript-3",
          "to": "fetch-1",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-3",
          "to": "fetch-2",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-4",
          "to": "fetch-1",
          "out": "body",
          "in": "body"
        },
        {
          "from": "runJavascript-5",
          "to": "runJavascript-1",
          "out": "id",
          "in": "id"
        },
        {
          "from": "runJavascript-5",
          "to": "runJavascript-4",
          "out": "notFound",
          "in": "notFound"
        },
        {
          "from": "runJavascript-6",
          "to": "urlTemplate-0",
          "out": "query",
          "in": "query"
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-2",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "breadboardFolderId": {
                  "type": "string",
                  "title": "Root ID",
                  "description": "The Drive id of the Breadboard folder that is used as root for storing data. Use \"Get Breadboard Folder\" component to obtain it"
                },
                "context": {
                  "type": "array",
                  "title": "Context in",
                  "description": "The conversation context to save to Google Drive.",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": false,
                    "behavior": [
                      "llm-content"
                    ]
                  }
                },
                "key": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ],
                  "title": "Key",
                  "description": "A unique key associated with this context, used to later load it from Google Drive."
                }
              },
              "required": [
                "breadboardFolderId",
                "context",
                "key"
              ]
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "context": {
                  "type": [
                    "array",
                    "boolean",
                    "null",
                    "number",
                    "object",
                    "string"
                  ],
                  "title": "Context out",
                  "description": "LLM Conversation Context that was passed in"
                }
              },
              "required": [
                "context"
              ]
            }
          }
        },
        {
          "id": "cast-0",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#file"
                  ]
                },
                "mimeType": {
                  "type": "string"
                },
                "id": {
                  "type": "string"
                },
                "name": {
                  "type": "string"
                },
                "resourceKey": {
                  "type": "string"
                }
              },
              "required": [
                "kind",
                "mimeType",
                "id",
                "name"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "cast-1",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#file"
                  ]
                },
                "mimeType": {
                  "type": "string"
                },
                "id": {
                  "type": "string"
                },
                "name": {
                  "type": "string"
                },
                "resourceKey": {
                  "type": "string"
                }
              },
              "required": [
                "kind",
                "mimeType",
                "id",
                "name"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "cast-2",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#fileList"
                  ]
                },
                "nextPageToken": {
                  "type": "string"
                },
                "incompleteSearch": {
                  "type": "boolean"
                },
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "kind",
                "incompleteSearch",
                "files"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {
            "method": "POST",
            "url": "https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart"
          },
          "metadata": {
            "title": "Save context",
            "description": "Calling the File Create API"
          }
        },
        {
          "id": "fetch-1",
          "type": "fetch",
          "configuration": {
            "method": "POST",
            "url": "https://www.googleapis.com/drive/v3/files"
          },
          "metadata": {
            "title": "Create \"saved\" Folder",
            "description": "Calling the File Create API"
          }
        },
        {
          "id": "fetch-2",
          "type": "fetch",
          "configuration": {},
          "metadata": {
            "title": "Search for the \"saved\" folder",
            "description": "Search for the \"saved\" folder"
          }
        },
        {
          "id": "passthrough-0",
          "type": "passthrough",
          "configuration": {}
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`,[\"Content-Type\"]:`multipart/related; boundary=BBBBBBBBBBB`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-1",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({id,key:key2,context:context2})=>{const boundary=\"BBBBBBBBBBB\";const metadata={name:key2,mimeType:\"application/json\",parents:[id]};const multipartBody=`--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata,null,2)}\n--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(context2,null,2)}\n--${boundary}--`;return{body:multipartBody}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": [
                    "string",
                    "string"
                  ]
                },
                "key": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ]
                },
                "context": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": false,
                    "behavior": [
                      "llm-content"
                    ]
                  }
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Make the request body to save context",
            "description": "Make the request body to save context"
          }
        },
        {
          "id": "runJavascript-2",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({createFolderResponse:createFolderResponse2})=>{return{id:createFolderResponse2.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "createFolderResponse": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#file"
                      ]
                    },
                    "mimeType": {
                      "type": "string"
                    },
                    "id": {
                      "type": "string"
                    },
                    "name": {
                      "type": "string"
                    },
                    "resourceKey": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "kind",
                    "mimeType",
                    "id",
                    "name"
                  ],
                  "additionalProperties": false
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Get ID",
            "description": "Retrieving ID of the newly created folder"
          }
        },
        {
          "id": "runJavascript-3",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-4",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({folderName,rootId:rootId2})=>{return{body:{name:folderName,mimeType:\"application/vnd.google-apps.folder\",parents:[rootId2]}}};",
            "folderName": "saved",
            "inputSchema": {
              "type": "object",
              "properties": {
                "notFound": {
                  "type": "boolean"
                },
                "folderName": {
                  "type": "string"
                },
                "rootId": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": false
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Make request body to create saved folder",
            "description": "Make request body to create saved folder"
          }
        },
        {
          "id": "runJavascript-5",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({response})=>{const first=response.files?.at(0);if(!first){return{notFound:true}}return{id:first.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "response": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#fileList"
                      ]
                    },
                    "nextPageToken": {
                      "type": "string"
                    },
                    "incompleteSearch": {
                      "type": "boolean"
                    },
                    "files": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "kind": {
                            "type": "string",
                            "enum": [
                              "drive#file"
                            ]
                          },
                          "mimeType": {
                            "type": "string"
                          },
                          "id": {
                            "type": "string"
                          },
                          "name": {
                            "type": "string"
                          },
                          "resourceKey": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "kind",
                          "mimeType",
                          "id",
                          "name"
                        ],
                        "additionalProperties": false
                      }
                    }
                  },
                  "required": [
                    "kind",
                    "incompleteSearch",
                    "files"
                  ],
                  "additionalProperties": false
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                },
                "notFound": {
                  "type": "boolean"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Route from List",
            "description": "Deciding whether to create a new folder"
          }
        },
        {
          "id": "runJavascript-6",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({rootId:rootId2})=>{return{query:`\"${rootId2}\" in parents and mimeType = \"application/vnd.google-apps.folder\" and name = \"saved\" and trashed = false`}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "rootId": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Query \"Saves\" Folder",
            "description": "Making a query to find the \"saved\" folder"
          }
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files?q={query}"
          },
          "metadata": {
            "title": "Make Find Saves URL Template",
            "description": "Make Find Saves URL Template"
          }
        }
      ]
    },
    "loadContextFromDrive": {
      "title": "Load Context from Drive",
      "description": "Loads previously saved LLM Conversation context from Google Drive",
      "version": "0.1.0",
      "metadata": {
        "icon": "google-drive"
      },
      "edges": [
        {
          "from": "cast-0",
          "to": "runJavascript-0",
          "out": "value",
          "in": "response"
        },
        {
          "from": "cast-1",
          "to": "runJavascript-3",
          "out": "value",
          "in": "response"
        },
        {
          "from": "cast-2",
          "to": "output-2",
          "out": "value",
          "in": "context"
        },
        {
          "from": "connection:google-drive-limited-secret",
          "to": "runJavascript-2",
          "out": "connection:google-drive-limited",
          "in": "token"
        },
        {
          "from": "fetch-0",
          "to": "cast-0",
          "out": "response",
          "in": "value"
        },
        {
          "from": "fetch-1",
          "to": "cast-1",
          "out": "response",
          "in": "value"
        },
        {
          "from": "fetch-2",
          "to": "cast-2",
          "out": "response",
          "in": "value"
        },
        {
          "from": "input-0",
          "to": "runJavascript-0",
          "out": "key",
          "in": "key"
        },
        {
          "from": "input-0",
          "to": "runJavascript-1",
          "out": "rootId",
          "in": "rootId"
        },
        {
          "from": "runJavascript-0",
          "to": "output-0",
          "out": "context",
          "in": "notFound"
        },
        {
          "from": "runJavascript-0",
          "to": "urlTemplate-1",
          "out": "query",
          "in": "query"
        },
        {
          "from": "runJavascript-1",
          "to": "urlTemplate-0",
          "out": "query",
          "in": "query"
        },
        {
          "from": "runJavascript-2",
          "to": "fetch-0",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-2",
          "to": "fetch-1",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-2",
          "to": "fetch-2",
          "out": "headers",
          "in": "headers"
        },
        {
          "from": "runJavascript-3",
          "to": "output-1",
          "out": "context",
          "in": "notFound"
        },
        {
          "from": "runJavascript-3",
          "to": "urlTemplate-2",
          "out": "id",
          "in": "id"
        },
        {
          "from": "urlTemplate-0",
          "to": "fetch-0",
          "out": "url",
          "in": "url"
        },
        {
          "from": "urlTemplate-1",
          "to": "fetch-1",
          "out": "url",
          "in": "url"
        },
        {
          "from": "urlTemplate-2",
          "to": "fetch-2",
          "out": "url",
          "in": "url"
        }
      ],
      "nodes": [
        {
          "id": "input-0",
          "type": "input",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "key": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ],
                  "title": "Key",
                  "description": "A unique key that was used to save LLM Conversation context to Google Drive."
                },
                "rootId": {
                  "type": "string",
                  "title": "Root ID",
                  "description": "The Drive id of the Breadboard folder that is used as root for storing data. Use \"Get Breadboard Folder\" component to obtain it"
                }
              },
              "required": [
                "key",
                "rootId"
              ]
            }
          }
        },
        {
          "id": "output-0",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "notFound": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": true,
                    "behavior": [
                      "llm-content"
                    ]
                  },
                  "title": "Not Found"
                }
              },
              "required": [
                "notFound"
              ]
            }
          },
          "metadata": {
            "title": "Breadboard root not found",
            "description": "Breadboard root not found"
          }
        },
        {
          "id": "output-1",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "notFound": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": true,
                    "behavior": [
                      "llm-content"
                    ]
                  },
                  "title": "Not Found"
                }
              },
              "required": [
                "notFound"
              ]
            }
          },
          "metadata": {
            "title": "Saved file not found",
            "description": "Saved file not found"
          }
        },
        {
          "id": "output-2",
          "type": "output",
          "configuration": {
            "schema": {
              "type": "object",
              "properties": {
                "context": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": true,
                    "behavior": [
                      "llm-content"
                    ]
                  },
                  "title": "Context out"
                }
              },
              "required": [
                "context"
              ]
            }
          },
          "metadata": {
            "title": "Output loaded context",
            "description": "Output loaded context"
          }
        },
        {
          "id": "cast-0",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#fileList"
                  ]
                },
                "nextPageToken": {
                  "type": "string"
                },
                "incompleteSearch": {
                  "type": "boolean"
                },
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "kind",
                "incompleteSearch",
                "files"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "cast-1",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string",
                  "enum": [
                    "drive#fileList"
                  ]
                },
                "nextPageToken": {
                  "type": "string"
                },
                "incompleteSearch": {
                  "type": "boolean"
                },
                "files": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {
                      "kind": {
                        "type": "string",
                        "enum": [
                          "drive#file"
                        ]
                      },
                      "mimeType": {
                        "type": "string"
                      },
                      "id": {
                        "type": "string"
                      },
                      "name": {
                        "type": "string"
                      },
                      "resourceKey": {
                        "type": "string"
                      }
                    },
                    "required": [
                      "kind",
                      "mimeType",
                      "id",
                      "name"
                    ],
                    "additionalProperties": false
                  }
                }
              },
              "required": [
                "kind",
                "incompleteSearch",
                "files"
              ],
              "additionalProperties": false
            }
          }
        },
        {
          "id": "cast-2",
          "type": "cast",
          "configuration": {
            "type": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {},
                "required": [],
                "additionalProperties": true,
                "behavior": [
                  "llm-content"
                ]
              }
            }
          }
        },
        {
          "id": "connection:google-drive-limited-secret",
          "type": "secrets",
          "configuration": {
            "keys": [
              "connection:google-drive-limited"
            ]
          }
        },
        {
          "id": "fetch-0",
          "type": "fetch",
          "configuration": {},
          "metadata": {
            "title": "Search for the \"saved\" folder",
            "description": "Search for the \"saved\" folder"
          }
        },
        {
          "id": "fetch-1",
          "type": "fetch",
          "configuration": {},
          "metadata": {
            "title": "Search for the saved file",
            "description": "Search for the saved file"
          }
        },
        {
          "id": "fetch-2",
          "type": "fetch",
          "configuration": {},
          "metadata": {
            "title": "Get saved file",
            "description": "Get saved file"
          }
        },
        {
          "id": "runJavascript-0",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({response,key:key2})=>{const first=response.files?.at(0);if(!first){return{context:[]}}return{query:`\"${first.id}\" in parents and mimeType = \"application/json\" and name = \"${key2}\" and trashed = false`}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "response": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#fileList"
                      ]
                    },
                    "nextPageToken": {
                      "type": "string"
                    },
                    "incompleteSearch": {
                      "type": "boolean"
                    },
                    "files": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "kind": {
                            "type": "string",
                            "enum": [
                              "drive#file"
                            ]
                          },
                          "mimeType": {
                            "type": "string"
                          },
                          "id": {
                            "type": "string"
                          },
                          "name": {
                            "type": "string"
                          },
                          "resourceKey": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "kind",
                          "mimeType",
                          "id",
                          "name"
                        ],
                        "additionalProperties": false
                      }
                    }
                  },
                  "required": [
                    "kind",
                    "incompleteSearch",
                    "files"
                  ],
                  "additionalProperties": false
                },
                "key": {
                  "type": "string",
                  "behavior": [
                    "config"
                  ]
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string"
                },
                "context": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": true,
                    "behavior": [
                      "llm-content"
                    ]
                  }
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Route from List",
            "description": "Deciding if to load or skip"
          }
        },
        {
          "id": "runJavascript-1",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({rootId:rootId2})=>{return{query:`\"${rootId2}\" in parents and mimeType = \"application/vnd.google-apps.folder\" and name = \"saved\" and trashed = false`}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "rootId": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string"
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Query \"Saves\" Folder",
            "description": "Making a query to find the \"saved\" folder"
          }
        },
        {
          "id": "runJavascript-2",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({token})=>({headers:{Authorization:`Bearer ${token}`}});",
            "inputSchema": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string"
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "headers": {
                  "type": "object",
                  "properties": {},
                  "required": [],
                  "additionalProperties": {
                    "type": "string"
                  }
                }
              }
            },
            "raw": true
          }
        },
        {
          "id": "runJavascript-3",
          "type": "runJavascript",
          "configuration": {
            "code": "const run = ({response})=>{const first=response.files?.at(0);if(!first){return{context:[]}}return{id:first.id}};",
            "inputSchema": {
              "type": "object",
              "properties": {
                "response": {
                  "type": "object",
                  "properties": {
                    "kind": {
                      "type": "string",
                      "enum": [
                        "drive#fileList"
                      ]
                    },
                    "nextPageToken": {
                      "type": "string"
                    },
                    "incompleteSearch": {
                      "type": "boolean"
                    },
                    "files": {
                      "type": "array",
                      "items": {
                        "type": "object",
                        "properties": {
                          "kind": {
                            "type": "string",
                            "enum": [
                              "drive#file"
                            ]
                          },
                          "mimeType": {
                            "type": "string"
                          },
                          "id": {
                            "type": "string"
                          },
                          "name": {
                            "type": "string"
                          },
                          "resourceKey": {
                            "type": "string"
                          }
                        },
                        "required": [
                          "kind",
                          "mimeType",
                          "id",
                          "name"
                        ],
                        "additionalProperties": false
                      }
                    }
                  },
                  "required": [
                    "kind",
                    "incompleteSearch",
                    "files"
                  ],
                  "additionalProperties": false
                }
              }
            },
            "name": "run",
            "outputSchema": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string"
                },
                "context": {
                  "type": "array",
                  "items": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": true,
                    "behavior": [
                      "llm-content"
                    ]
                  }
                }
              }
            },
            "raw": true
          },
          "metadata": {
            "title": "Route from List of saved files",
            "description": "Route from List of saved files"
          }
        },
        {
          "id": "urlTemplate-0",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files?q={query}"
          },
          "metadata": {
            "title": "Make Find \"saved\" folder URL template",
            "description": "Make Find \"saved\" folder URL template"
          }
        },
        {
          "id": "urlTemplate-1",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files?q={query}&orderBy=createdTime+desc"
          },
          "metadata": {
            "title": "Make Find saved file URL template",
            "description": "Make Find saved file URL template"
          }
        },
        {
          "id": "urlTemplate-2",
          "type": "urlTemplate",
          "configuration": {
            "template": "https://www.googleapis.com/drive/v3/files/{id}?alt=media"
          },
          "metadata": {
            "title": "Make template to retrieve saved file",
            "description": "Make template to retrieve saved file"
          }
        }
      ]
    },
    "appendToDoc": {
      "title": "Append To Doc",
      "description": "Appends conversation context to  a Google Document, converting Markdown to proper formatting.",
      "version": "0.1.0",
      "nodes": [
        {
          "type": "input",
          "id": "input",
          "configuration": {
            "schema": {
              "properties": {
                "context": {
                  "type": "array",
                  "title": "Context in",
                  "items": {
                    "type": "object",
                    "behavior": [
                      "llm-content"
                    ]
                  },
                  "default": "[{\"role\":\"user\",\"parts\":[]}]",
                  "description": "Incoming conversation context to append to Google Document."
                },
                "title": {
                  "type": "string",
                  "title": "Document Title",
                  "description": "The title of the Google Document to which the incoming context will be appended. The document will be created if does not already exist.",
                  "default": "Untitled Document (Created with Breadboard)",
                  "behavior": [
                    "config"
                  ]
                }
              },
              "type": "object",
              "required": []
            }
          },
          "metadata": {
            "visual": {
              "x": -298,
              "y": -470,
              "collapsed": "expanded"
            },
            "logLevel": "debug"
          }
        },
        {
          "type": "output",
          "id": "output",
          "configuration": {
            "schema": {
              "properties": {
                "id": {
                  "type": "string",
                  "title": "Document ID",
                  "format": "markdown",
                  "description": "The Google Drive ID of the Google Document to which the conversation context was appended.",
                  "default": ""
                }
              },
              "type": "object",
              "required": []
            }
          },
          "metadata": {
            "visual": {
              "x": 421,
              "y": -394.99999999999994,
              "collapsed": "expanded"
            },
            "logLevel": "debug"
          }
        },
        {
          "id": "runModule-7f9c8340",
          "type": "runModule",
          "metadata": {
            "visual": {
              "x": 8,
              "y": -469,
              "collapsed": "expanded"
            },
            "title": "Run Module",
            "logLevel": "debug"
          },
          "configuration": {
            "$module": "append-to-doc"
          }
        }
      ],
      "edges": [
        {
          "from": "input",
          "to": "runModule-7f9c8340",
          "out": "context",
          "in": "context"
        },
        {
          "from": "input",
          "to": "runModule-7f9c8340",
          "out": "title",
          "in": "title"
        },
        {
          "from": "runModule-7f9c8340",
          "to": "output",
          "out": "id",
          "in": "id"
        }
      ],
      "modules": {
        "api": {
          "metadata": {
            "description": "",
            "url": "api.js"
          },
          "code": "import fetch from \"@fetch\";\nimport secrets from \"@secrets\";\n\nconst connectionId = \"connection:google-drive-limited\";\n\nexport {\n  connect,\n  get,\n  create,\n  del,\n  query,\n  createMultipart,\n  getDoc,\n  updateDoc,\n  unwrap,\n};\n\nasync function get(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply file id.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"GET\"\n  );\n}\n\nasync function create(token, body, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the file to create.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    \"https://www.googleapis.com/drive/v3/files\",\n    \"POST\",\n    body\n  );\n}\n\nasync function query(token, query, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!query) {\n    return error(\"Please supply the query.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`,\n    \"GET\"\n  );\n}\n\nasync function del(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the file to delete\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"DELETE\"\n  );\n}\n\nasync function getDoc(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the doc id to get.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}`,\n    \"GET\"\n  );\n}\n\nasync function updateDoc(token, id, body, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the doc to update.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the doc update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function connect(metadata) {\n  const { [connectionId]: token } = await secrets({\n    ...meta(metadata),\n    keys: [connectionId],\n  });\n  return token;\n}\n\nasync function createMultipart(token, metadata, body, mimeType, $metadata) {\n  const boundary = \"BB-BB-BB-BB-BB-BB\";\n  const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n  const request = {\n    ...meta($metadata),\n    url,\n    method: \"POST\",\n    headers: {\n      Authorization: `Bearer ${token}`,\n      [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n    },\n    body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\n\n${body}\n--${boundary}--`,\n  };\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error };\n  }\n  return { success: true, info: response };\n}\n\nasync function api(metadata, token, url, method, body = null) {\n  const request = {\n    ...meta(metadata),\n    url,\n    method,\n    headers: {\n      Authorization: `Bearer ${token}`,\n    },\n  };\n  if (body) {\n    request.body = body;\n  }\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error };\n  }\n  return { success: true, info: response };\n}\n\nfunction unwrap(result, message = \"Error\") {\n  if (result.error) {\n    throw new Error(`${message}:\\n${JSON.stringify(result.error)}`);\n  }\n  return result.info;\n}\n\nfunction error(message) {\n  return {\n    success: false,\n    error: message,\n  };\n}\n\nfunction meta({ title, description } = {}) {\n  if (!(title || description)) return {};\n  const $metadata = {};\n  if (title) {\n    $metadata.title = title;\n  }\n  if (description) {\n    $metadata.description = description;\n  }\n  return { $metadata };\n}\n"
        },
        "append-to-doc": {
          "code": "import { connect, create, getDoc, query, unwrap, updateDoc } from \"./api\";\nimport { markdownToRequests } from \"./markdown-to-requests\";\n\nexport { invoke as default, describe };\n\nasync function invoke({ context, title }) {\n  const token = await connect({ title: \"Get API token\" });\n  const { id, end } = await getCollectorId(token, title);\n  const markdown = contextToMarkdown(context);\n  if (markdown) {\n    const requests = markdownToRequests(markdown, end);\n    // console.log(\"REQUESTS\", requests);\n    unwrap(\n      await updateDoc(token, id, { requests }, { title: \"Append to doc\" }),\n      \"Failed to update the doc.\"\n    );\n  }\n  return { id };\n}\n\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollectorId(token, title) {\n  const findFile = await query(\n    token,\n    `appProperties has { key = 'appendToDoc' and value = '${title.replace(\"'\", \"\\\\'\")}' } and trashed = false`,\n    { title: \"Find the doc to which to append\" }\n  );\n  const file = unwrap(\n    findFile,\n    \"Failed to call Drive API to find the file to append\"\n  ).files.at(0);\n  if (!file) {\n    const createdFile = await create(\n      token,\n      {\n        name: title,\n        mimeType: \"application/vnd.google-apps.document\",\n        appProperties: {\n          appendToDoc: title,\n        },\n      },\n      { title: \"Create new doc to which to append\" }\n    );\n\n    return {\n      id: unwrap(createdFile, \"Failed to call Drive API to create a new file\")\n        .id,\n      end: 1,\n    };\n  }\n  const id = file.id;\n  const end =\n    unwrap(\n      await getDoc(token, id, { title: \"Get current doc contents\" }),\n      \"Failed to get the Doc to append to\"\n    ).body.content.reduce(\n      (acc, element) => Math.max(acc, element.endIndex || 0),\n      1\n    ) - 1;\n  return { id, end };\n}\n\nfunction contextToMarkdown(context) {\n  if (!Array.isArray(context)) {\n    if (typeof context === \"string\") {\n      return context;\n    }\n    if (context === undefined || context === null) {\n      return \"\";\n    }\n    return JSON.stringify(context);\n  }\n  // For now, take the last item in context.\n  context = [context.at(-1)];\n  return context\n    .flatMap((item) => {\n      if (\"parts\" in item) return item.parts.map((part) => part.text);\n      return null;\n    })\n    .filter((item) => !!item)\n    .join(\"\\n\\n\");\n}\n\nasync function describe() {\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        title: { type: \"string\", title: \"Title\" },\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n        },\n      },\n    },\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        id: { type: \"string\", title: \"Document ID\" },\n      },\n    },\n  };\n}\n",
          "metadata": {
            "description": "",
            "url": "append-to-doc.js",
            "runnable": true
          }
        },
        "markdown-to-requests": {
          "metadata": {
            "description": "",
            "url": "markdown-to-requests.js"
          },
          "code": "import { marked } from \"./marked\";\nimport { unescape } from \"./unescape\";\n\nexport { markdownToRequests };\n\nfunction markdownToRequests(markdown, startIndex) {\n  const tokens = marked.lexer(markdown);\n  return tokensToRequests(tokens, startIndex);\n}\n\n/**\n * Converts markdown tokens to Google Doc Request array for the\n * `batchUpdate` call.\n */\nfunction tokensToRequests(tokens, startIndex) {\n  let current = startIndex;\n  // console.log(\"TOKENS\", tokens, startIndex);\n  return tokens.flatMap((token) => {\n    switch (token.type) {\n      case \"paragraph\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"space\":\n        return insertSpace(token);\n      case \"code\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"heading\":\n        return insertFormattedText(token, `HEADING_${token.depth}`);\n      case \"blockquote\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"list\":\n        return insertList(token.items, token.ordered, 0);\n    }\n    return [];\n  });\n\n  function insertFormattedText(token, namedStyleType) {\n    const { requests, text: withoutBreak } = new TextStyles(\n      current,\n      token\n    ).parse();\n    const text = `${withoutBreak}\\n`;\n    if (namedStyleType) {\n      requests.unshift({\n        updateParagraphStyle: {\n          range: range(text.length),\n          paragraphStyle: { namedStyleType },\n          fields: \"namedStyleType\",\n        },\n      });\n    }\n    requests.unshift({ insertText: { text, location: location() } });\n    current += text.length;\n    return requests;\n  }\n\n  function insertSpace(token) {\n    const text = token.raw.startsWith(\"\\n\") ? token.raw.slice(1) : token.raw;\n    const result = [\n      {\n        insertText: { text, location: location() },\n      },\n    ];\n    return advance(result, text.length);\n  }\n\n  function range(length) {\n    return { startIndex: current, endIndex: current + length };\n  }\n\n  function location() {\n    return { index: current };\n  }\n\n  function insertList(items, ordered, depth) {\n    const start = current;\n    // This is necessary to counteract a gnarly side-effect of creating a\n    // bullet list: the indent markers are being removed during that change,\n    // and change all of the ranges. So we have to make sure that the next\n    // request accounts for that.\n    let depthToRemove = 0;\n    const list = descendIntoList(items, ordered, depth).flat();\n    list.push({\n      createParagraphBullets: {\n        range: { startIndex: start, endIndex: current },\n        bulletPreset: \"BULLET_DISC_CIRCLE_SQUARE\",\n      },\n    });\n    current -= depthToRemove;\n    return list;\n\n    function descendIntoList(items, ordered, depth) {\n      const list = items.flatMap((item) => {\n        // For item, item.type === \"list_item\".\n        const indent = \"\\t\".repeat(depth);\n        depthToRemove += depth;\n        const result = [];\n        const subList = item.tokens?.find((token) => token.type === \"list\");\n        if (subList) {\n          // assume that the first token is actually the text token.\n          result.push(insertItemText(indent, item.tokens.at(0)));\n          result.push(...descendIntoList(subList.items, ordered, depth + 1));\n        } else {\n          result.push(insertItemText(indent, item.tokens.at(0)));\n        }\n        return result;\n      });\n      return list;\n    }\n\n    function insertItemText(indent, token) {\n      const offset = current + indent.length;\n      const { requests, text: withoutIndent } = new TextStyles(\n        offset,\n        token\n      ).parse();\n      const text = `${indent}${withoutIndent}\\n`;\n      requests.unshift({\n        updateParagraphStyle: {\n          range: range(text.length),\n          paragraphStyle: { namedStyleType: \"NORMAL_TEXT\" },\n          fields: \"namedStyleType\",\n        },\n      });\n      requests.unshift({ insertText: { text, location: location() } });\n      current += text.length;\n      return requests;\n    }\n  }\n\n  function advance(result, length) {\n    current += length;\n    return result;\n  }\n}\n\nclass TextStyles {\n  #offset;\n  #tokens;\n  #styles = [];\n\n  constructor(offset, token) {\n    this.#offset = offset;\n    this.#tokens = token.tokens || [];\n  }\n\n  range(startIndex, length) {\n    return { startIndex, endIndex: startIndex + length };\n  }\n\n  style(startIndex, length, textStyle) {\n    this.#styles.push({\n      updateTextStyle: {\n        range: this.range(startIndex, length),\n        textStyle,\n        fields: Object.keys(textStyle).join(\",\"),\n      },\n    });\n  }\n\n  parse() {\n    let current = this.#offset;\n    let text = \"\";\n    for (let token of this.#tokens) {\n      const length = token.text.length;\n      text += unescape(token.text);\n      switch (token.type) {\n        case \"strong\":\n          this.style(current, length, { bold: true });\n          break;\n        case \"em\":\n          this.style(current, length, { italic: true });\n          break;\n        case \"codespan\":\n          this.style(current, length, {\n            weightedFontFamily: {\n              fontFamily: \"Fira Code\",\n            },\n          });\n          break;\n        case \"del\":\n          this.style(current, length, { strikethrough: true });\n          break;\n        case \"link\":\n          this.style(current, length, { link: { url: token.href } });\n          break;\n        case \"escape\":\n          console.log(\"ESCAPE\", token);\n          break;\n      }\n      current += length;\n    }\n    return {\n      requests: this.#styles,\n      text,\n    };\n  }\n}\n"
        },
        "marked": {
          "metadata": {
            "description": "",
            "url": "marked.js"
          },
          "code": "/**\n * marked v14.1.3 - a markdown parser\n * Copyright (c) 2011-2024, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n/**\n * Gets the original marked default options.\n */\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\nlet _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n/**\n * Helpers\n */\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = new RegExp(escapeTest.source, \"g\");\nconst escapeTestNoEncode = /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/;\nconst escapeReplaceNoEncode = new RegExp(escapeTestNoEncode.source, \"g\");\nconst escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\",\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nfunction escape$1(html, encode) {\n  if (encode) {\n    if (escapeTest.test(html)) {\n      return html.replace(escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (escapeTestNoEncode.test(html)) {\n      return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html;\n}\nconst caret = /(^|[^\\[])\\^/g;\nfunction edit(regex, opt) {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  opt = opt || \"\";\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(/%25/g, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nconst noopTest = { exec: () => null };\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return \"|\";\n      } else {\n        // add space before unescaped |\n        return \" |\";\n      }\n    }),\n    cells = row.split(/ \\|/);\n  let i = 0;\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, \"|\");\n  }\n  return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  return -1;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n  const href = link.href;\n  const title = link.title ? escape$1(link.title) : null;\n  const text = cap[1].replace(/\\\\([\\[\\]])/g, \"$1\");\n  if (cap[0].charAt(0) !== \"!\") {\n    lexer.state.inLink = true;\n    const token = {\n      type: \"link\",\n      raw,\n      href,\n      title,\n      text,\n      tokens: lexer.inlineTokens(text),\n    };\n    lexer.state.inLink = false;\n    return token;\n  }\n  return {\n    type: \"image\",\n    raw,\n    href,\n    title,\n    text: escape$1(text),\n  };\n}\nfunction indentCodeCompensation(raw, text) {\n  const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text\n    .split(\"\\n\")\n    .map((node) => {\n      const matchIndentInNode = node.match(/^\\s+/);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n      const [indentInNode] = matchIndentInNode;\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n      return node;\n    })\n    .join(\"\\n\");\n}\n/**\n * Tokenizer\n */\nclass _Tokenizer {\n  options;\n  rules; // set by the lexer\n  lexer; // set by the lexer\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0],\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(/^(?: {1,4}| {0,3}\\t)/gm, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text,\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\");\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2]\n          ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\")\n          : cap[2],\n        text,\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      // remove trailing #s\n      if (/#$/.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || / $/.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\"),\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (/^ {0,3}>/.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(/\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g, \"\\n    $1\")\n          .replace(/^ {0,3}>[ \\t]?/gm, \"\");\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens[tokens.length - 1];\n        if (lastToken?.type === \"code\") {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          // include continuation in nested blockquote\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.text.length) +\n            newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          // include continuation in nested list\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText\n            .substring(tokens[tokens.length - 1].raw.length)\n            .split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: [],\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      // Get next list item\n      const itemRegex = new RegExp(\n        `^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`\n      );\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2]\n          .split(\"\\n\", 1)[0]\n          .replace(/^\\t+/, (t) => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(/[^ ]/); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && /^[ \\t]*$/.test(nextLine)) {\n          // Items begin with at most one blank line\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`\n          );\n          const hrRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`\n          );\n          const fencesBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`\n          );\n          const headingBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}#`\n          );\n          const htmlBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}<[a-z].*>`,\n            \"i\"\n          );\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(/^ {1,4}(?=( {4})*[^ ])/g, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(/\\t/g, \"    \");\n            }\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (\n              nextLineWithoutTabs.search(/[^ ]/) >= indent ||\n              !nextLine.trim()\n            ) {\n              // Dedent if possible\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(/\\t/g, \"    \").search(/[^ ]/) >= 4) {\n                // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              // Check if current line is blank\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (/\\n[ \\t]*\\n[ \\t]*$/.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = /^\\[[ xX]\\] /.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(/^\\[[ xX]\\] +/, \"\");\n          }\n        }\n        list.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n        list.raw += raw;\n      }\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      list.items[list.items.length - 1].raw =\n        list.items[list.items.length - 1].raw.trimEnd();\n      list.items[list.items.length - 1].text =\n        list.items[list.items.length - 1].text.trimEnd();\n      list.raw = list.raw.trimEnd();\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(\n            (t) => t.type === \"space\"\n          );\n          const hasMultipleLineBreaks =\n            spacers.length > 0 && spacers.some((t) => /\\n.*\\n/.test(t.raw));\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n      return list;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(/\\s+/g, \" \");\n      const href = cap[2]\n        ? cap[2]\n            .replace(/^<(.*)>$/, \"$1\")\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : \"\";\n      const title = cap[3]\n        ? cap[3]\n            .substring(1, cap[3].length - 1)\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : cap[3];\n      return {\n        type: \"def\",\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!/[:|]/.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(/^\\||\\| *$/g, \"\").split(\"|\");\n    const rows =\n      cap[3] && cap[3].trim()\n        ? cap[3].replace(/\\n[ \\t]*$/, \"\").split(\"\\n\")\n        : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n    for (const align of aligns) {\n      if (/^ *-+: *$/.test(align)) {\n        item.align.push(\"right\");\n      } else if (/^ *:-+: *$/.test(align)) {\n        item.align.push(\"center\");\n      } else if (/^ *:-+ *$/.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(\n        splitCells(row, item.header.length).map((cell, i) => {\n          return {\n            text: cell,\n            tokens: this.lexer.inline(cell),\n            header: false,\n            align: item.align[i],\n          };\n        })\n      );\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text =\n        cap[1].charAt(cap[1].length - 1) === \"\\n\"\n          ? cap[1].slice(0, -1)\n          : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: escape$1(cap[1]),\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (\n        !this.lexer.state.inRawBlock &&\n        /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = true;\n      } else if (\n        this.lexer.state.inRawBlock &&\n        /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!/>$/.test(trimmedUrl)) {\n          return;\n        }\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (/^</.test(href)) {\n        if (this.options.pedantic && !/>$/.test(trimmedUrl)) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(\n        cap,\n        {\n          href: href\n            ? href.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : href,\n          title: title\n            ? title.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : title,\n        },\n        cap[0],\n        this.lexer\n      );\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if (\n      (cap = this.rules.inline.reflink.exec(src)) ||\n      (cap = this.rules.inline.nolink.exec(src))\n    ) {\n      const linkString = (cap[2] || cap[1]).replace(/\\s+/g, \" \");\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (\n      !nextChar ||\n      !prevChar ||\n      this.rules.inline.punctuation.exec(prevChar)\n    ) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg =\n        match[0][0] === \"*\"\n          ? this.rules.inline.emStrongRDelimAst\n          : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim =\n          match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue; // skip single * in __abc*abc__\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(\n          0,\n          lLength + match.index + lastCharLength + rLength\n        );\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(/\\n/g, \" \");\n      const hasNonSpaceChars = /[^ ]/.test(text);\n      const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      text = escape$1(text, true);\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0],\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[1]);\n        href = \"mailto:\" + text;\n      } else {\n        text = escape$1(cap[1]);\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if ((cap = this.rules.inline.url.exec(src))) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[0]);\n        href = \"mailto:\" + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = escape$1(cap[0]);\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      let text;\n      if (this.lexer.state.inRawBlock) {\n        text = cap[0];\n      } else {\n        text = escape$1(cap[0]);\n      }\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n}\n\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences =\n  /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheading = edit(\n  /^(?!bull |blockCode|fences|blockquote|heading|html)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/\n)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .getRegex();\nconst _paragraph =\n  /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(\n  /^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/\n)\n  .replace(\"label\", _blockLabel)\n  .replace(\n    \"title\",\n    /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/\n  )\n  .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\nconst _tag =\n  \"address|article|aside|base|basefont|blockquote|body|caption\" +\n  \"|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption\" +\n  \"|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe\" +\n  \"|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option\" +\n  \"|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title\" +\n  \"|tr|track|ul\";\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  \"^ {0,3}(?:\" + // optional indentation\n    \"<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)\" + // (1)\n    \"|comment[^\\\\n]*(\\\\n+|$)\" + // (2)\n    \"|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)\" + // (3)\n    \"|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)\" + // (4)\n    \"|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)\" + // (5)\n    \"|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (6)\n    \"|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) open tag\n    \"|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) closing tag\n    \")\",\n  \"i\"\n)\n  .replace(\"comment\", _comment)\n  .replace(\"tag\", _tag)\n  .replace(\n    \"attribute\",\n    / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst paragraph = edit(_paragraph)\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n  .replace(\"|table\", \"\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace(\"paragraph\", paragraph)\n  .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit(\n  \"^ *([^\\\\n ].*)\\\\n\" + // Header\n    \" {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)\" + // Align\n    \"(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\"\n) // Cells\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"code\", \"(?: {4}| {0,3}\\t)[^\\\\n]\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockGfm = {\n  ...blockNormal,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n    .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n    .replace(\"table\", gfmTable) // interrupt paragraphs with table\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n    .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n    .replace(\n      \"html\",\n      \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n    )\n    .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n  ...blockNormal,\n  html: edit(\n    \"^ *(?:comment *(?:\\\\n|\\\\s*$)\" +\n      \"|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)\" + // closed tag\n      \"|<tag(?:\\\"[^\\\"]*\\\"|'[^']*'|\\\\s[^'\\\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))\"\n  )\n    .replace(\"comment\", _comment)\n    .replace(\n      /tag/g,\n      \"(?!(?:\" +\n        \"a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub\" +\n        \"|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\" +\n        \"\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\"\n    )\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" *#{1,6} *[^\\n]\")\n    .replace(\"lheading\", lheading)\n    .replace(\"|table\", \"\")\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"|fences\", \"\")\n    .replace(\"|list\", \"\")\n    .replace(\"|html\", \"\")\n    .replace(\"|tag\", \"\")\n    .getRegex(),\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText =\n  /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = \"\\\\p{P}\\\\p{S}\";\nconst punctuation = edit(/^((?![*_])[\\spunctuation])/, \"u\")\n  .replace(/punctuation/g, _punctuation)\n  .getRegex();\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip =\n  /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelim = edit(\n  /^(?:\\*+(?:((?!\\*)[punct])|[^\\s*]))|^_+(?:((?!_)[punct])|([^\\s_]))/,\n  \"u\"\n)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst emStrongRDelimAst = edit(\n  \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)\" + // Skip orphan inside strong\n    \"|[^*]+(?=[^*])\" + // Consume to delim\n    \"|(?!\\\\*)[punct](\\\\*+)(?=[\\\\s]|$)\" + // (1) #*** can only be a Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?!\\\\*)(?=[punct\\\\s]|$)\" + // (2) a***#, a*** can only be a Right Delimiter\n    \"|(?!\\\\*)[punct\\\\s](\\\\*+)(?=[^punct\\\\s])\" + // (3) #***a, ***a can only be Left Delimiter\n    \"|[\\\\s](\\\\*+)(?!\\\\*)(?=[punct])\" + // (4) ***# can only be Left Delimiter\n    \"|(?!\\\\*)[punct](\\\\*+)(?!\\\\*)(?=[punct])\" + // (5) #***# can be either Left or Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?=[^punct\\\\s])\",\n  \"gu\"\n) // (6) a***a can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  \"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)\" + // Skip orphan inside strong\n    \"|[^_]+(?=[^_])\" + // Consume to delim\n    \"|(?!_)[punct](_+)(?=[\\\\s]|$)\" + // (1) #___ can only be a Right Delimiter\n    \"|[^punct\\\\s](_+)(?!_)(?=[punct\\\\s]|$)\" + // (2) a___#, a___ can only be a Right Delimiter\n    \"|(?!_)[punct\\\\s](_+)(?=[^punct\\\\s])\" + // (3) #___a, ___a can only be Left Delimiter\n    \"|[\\\\s](_+)(?!_)(?=[punct])\" + // (4) ___# can only be Left Delimiter\n    \"|(?!_)[punct](_+)(?!_)(?=[punct])\",\n  \"gu\"\n) // (5) #___# can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst anyPunctuation = edit(/\\\\([punct])/, \"gu\")\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace(\n    \"email\",\n    /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/\n  )\n  .getRegex();\nconst _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nconst tag = edit(\n  \"^comment\" +\n    \"|^</[a-zA-Z][\\\\w:-]*\\\\s*>\" + // self-closing tag\n    \"|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>\" + // open tag\n    \"|^<\\\\?[\\\\s\\\\S]*?\\\\?>\" + // processing instruction, e.g. <?php ?>\n    \"|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>\" + // declaration, e.g. <!DOCTYPE html>\n    \"|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\"\n) // CDATA section\n  .replace(\"comment\", _inlineComment)\n  .replace(\n    \"attribute\",\n    /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n  .replace(\n    \"title\",\n    /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/\n  )\n  .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\")\n  .replace(\"reflink\", reflink)\n  .replace(\"nolink\", nolink)\n  .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n  ...inlineNormal,\n  escape: edit(escape).replace(\"])\", \"~|])\").getRegex(),\n  url: edit(\n    /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n    \"i\"\n  )\n    .replace(\n      \"email\",\n      /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/\n    )\n    .getRegex(),\n  _backpedal:\n    /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text)\n    .replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\")\n    .replace(/\\{2,\\}/g, \"*\")\n    .getRegex(),\n};\n/**\n * exports\n */\nconst block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\nconst inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\n/**\n * Block Lexer\n */\nclass _Lexer {\n  tokens;\n  options;\n  state;\n  tokenizer;\n  inlineQueue;\n  constructor(options) {\n    // TokenList cannot be created in one go\n    this.tokens = [];\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n    const rules = {\n      block: block.normal,\n      inline: inline.normal,\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(/\\r\\n|\\r/g, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(/\\t/g, \"    \").replace(/^ +$/gm, \"\");\n    }\n    let token;\n    let lastToken;\n    let cutSrc;\n    while (src) {\n      if (\n        this.options.extensions &&\n        this.options.extensions.block &&\n        this.options.extensions.block.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // newline\n      if ((token = this.tokenizer.space(src))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.length === 1 && tokens.length > 0) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          tokens[tokens.length - 1].raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.code(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        // An indented code block cannot interrupt a paragraph.\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // fences\n      if ((token = this.tokenizer.fences(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // heading\n      if ((token = this.tokenizer.heading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // hr\n      if ((token = this.tokenizer.hr(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // blockquote\n      if ((token = this.tokenizer.blockquote(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // list\n      if ((token = this.tokenizer.list(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // html\n      if ((token = this.tokenizer.html(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // def\n      if ((token = this.tokenizer.def(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n      // table (gfm)\n      if ((token = this.tokenizer.table(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // lheading\n      if ((token = this.tokenizer.lheading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        lastToken = tokens[tokens.length - 1];\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      // text\n      if ((token = this.tokenizer.text(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let token, lastToken, cutSrc;\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match;\n    let keepPrevChar, prevChar;\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while (\n          (match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) !=\n          null\n        ) {\n          if (\n            links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))\n          ) {\n            maskedSrc =\n              maskedSrc.slice(0, match.index) +\n              \"[\" +\n              \"a\".repeat(match[0].length - 2) +\n              \"]\" +\n              maskedSrc.slice(\n                this.tokenizer.rules.inline.reflinkSearch.lastIndex\n              );\n          }\n        }\n      }\n    }\n    // Mask out other blocks\n    while (\n      (match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"[\" +\n        \"a\".repeat(match[0].length - 2) +\n        \"]\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    // Mask out escaped characters\n    while (\n      (match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) !=\n      null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"++\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      // extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.inline &&\n        this.options.extensions.inline.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // escape\n      if ((token = this.tokenizer.escape(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // tag\n      if ((token = this.tokenizer.tag(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // link\n      if ((token = this.tokenizer.link(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // reflink, nolink\n      if ((token = this.tokenizer.reflink(src, this.tokens.links))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // em & strong\n      if ((token = this.tokenizer.emStrong(src, maskedSrc, prevChar))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.codespan(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // br\n      if ((token = this.tokenizer.br(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // del (gfm)\n      if ((token = this.tokenizer.del(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // autolink\n      if ((token = this.tokenizer.autolink(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if ((token = this.tokenizer.inlineText(cutSrc))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n}\n\n/**\n * Renderer\n */\nclass _Renderer {\n  options;\n  parser; // set by the parser\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({ text, lang, escaped }) {\n    const langString = (lang || \"\").match(/^\\S*/)?.[0];\n    const code = text.replace(/\\n$/, \"\") + \"\\n\";\n    if (!langString) {\n      return (\n        \"<pre><code>\" +\n        (escaped ? code : escape$1(code, true)) +\n        \"</code></pre>\\n\"\n      );\n    }\n    return (\n      '<pre><code class=\"language-' +\n      escape$1(langString) +\n      '\">' +\n      (escaped ? code : escape$1(code, true)) +\n      \"</code></pre>\\n\"\n    );\n  }\n  blockquote({ tokens }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n  html({ text }) {\n    return text;\n  }\n  heading({ tokens, depth }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens.length > 0 && item.tokens[0].type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (\n            item.tokens[0].tokens &&\n            item.tokens[0].tokens.length > 0 &&\n            item.tokens[0].tokens[0].type === \"text\"\n          ) {\n            item.tokens[0].tokens[0].text =\n              checkbox + \" \" + item.tokens[0].tokens[0].text;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\\n`;\n  }\n  checkbox({ checked }) {\n    return (\n      \"<input \" +\n      (checked ? 'checked=\"\" ' : \"\") +\n      'disabled=\"\" type=\"checkbox\">'\n    );\n  }\n  paragraph({ tokens }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n  table(token) {\n    let header = \"\";\n    // header\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return (\n      \"<table>\\n\" + \"<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\"\n    );\n  }\n  tablerow({ text }) {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({ tokens }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({ tokens }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({ text }) {\n    return `<code>${text}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({ tokens }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({ href, title, tokens }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({ href, title, text }) {\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${title}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : token.text;\n  }\n}\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nclass _TextRenderer {\n  // no need for block level renderers\n  strong({ text }) {\n    return text;\n  }\n  em({ text }) {\n    return text;\n  }\n  codespan({ text }) {\n    return text;\n  }\n  del({ text }) {\n    return text;\n  }\n  html({ text }) {\n    return text;\n  }\n  text({ text }) {\n    return text;\n  }\n  link({ text }) {\n    return \"\" + text;\n  }\n  image({ text }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n}\n\n/**\n * Parsing & Compiling\n */\nclass _Parser {\n  options;\n  renderer;\n  textRenderer;\n  constructor(options) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call(\n          { parser: this },\n          genericToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"space\",\n            \"hr\",\n            \"heading\",\n            \"code\",\n            \"table\",\n            \"blockquote\",\n            \"list\",\n            \"html\",\n            \"paragraph\",\n            \"text\",\n          ].includes(genericToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\": {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case \"hr\": {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case \"heading\": {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case \"code\": {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case \"table\": {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case \"blockquote\": {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case \"list\": {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case \"html\": {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case \"paragraph\": {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case \"text\": {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n            textToken = tokens[++i];\n            body += \"\\n\" + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: \"paragraph\",\n              raw: body,\n              text: body,\n              tokens: [{ type: \"text\", raw: body, text: body }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer) {\n    renderer = renderer || this.renderer;\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const ret = this.options.extensions.renderers[anyToken.type].call(\n          { parser: this },\n          anyToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"escape\",\n            \"html\",\n            \"link\",\n            \"image\",\n            \"strong\",\n            \"em\",\n            \"codespan\",\n            \"br\",\n            \"del\",\n            \"text\",\n          ].includes(anyToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\": {\n          out += renderer.text(token);\n          break;\n        }\n        case \"html\": {\n          out += renderer.html(token);\n          break;\n        }\n        case \"link\": {\n          out += renderer.link(token);\n          break;\n        }\n        case \"image\": {\n          out += renderer.image(token);\n          break;\n        }\n        case \"strong\": {\n          out += renderer.strong(token);\n          break;\n        }\n        case \"em\": {\n          out += renderer.em(token);\n          break;\n        }\n        case \"codespan\": {\n          out += renderer.codespan(token);\n          break;\n        }\n        case \"br\": {\n          out += renderer.br(token);\n          break;\n        }\n        case \"del\": {\n          out += renderer.del(token);\n          break;\n        }\n        case \"text\": {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n\nclass _Hooks {\n  options;\n  block;\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  static passThroughHooks = new Set([\n    \"preprocess\",\n    \"postprocess\",\n    \"processAllTokens\",\n  ]);\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html) {\n    return html;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n\nclass Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n  constructor(...args) {\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\": {\n          const tableToken = token;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case \"list\": {\n          const listToken = token;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach(\n              (childTokens) => {\n                const tokens = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens, callback));\n              }\n            );\n          } else if (genericToken.tokens) {\n            values = values.concat(\n              this.walkTokens(genericToken.tokens, callback)\n            );\n          }\n        }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {},\n    };\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack };\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function (...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            // Tokenizer Extensions\n            if (\n              !ext.level ||\n              (ext.level !== \"block\" && ext.level !== \"inline\")\n            ) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              // Function to check for start of token\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer =\n          this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(\n                  (ret) => {\n                    return prevHook.call(hooks, ret);\n                  }\n                );\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = { ...this.defaults, ...opts };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n  lexer(src, options) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n  parser(tokens, options) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse = (src, options) => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(\n          new Error(\n            \"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"\n          )\n        );\n      }\n      // throw error in case of non string input\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(\n          new Error(\"marked(): input parameter is undefined or null\")\n        );\n      }\n      if (typeof src !== \"string\") {\n        return throwError(\n          new Error(\n            \"marked(): input parameter is of type \" +\n              Object.prototype.toString.call(src) +\n              \", string expected\"\n          )\n        );\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer = opt.hooks\n        ? opt.hooks.provideLexer()\n        : blockType\n          ? _Lexer.lex\n          : _Lexer.lexInline;\n      const parser = opt.hooks\n        ? opt.hooks.provideParser()\n        : blockType\n          ? _Parser.parse\n          : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then((src) => lexer(src, opt))\n          .then((tokens) =>\n            opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens\n          )\n          .then((tokens) =>\n            opt.walkTokens\n              ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(\n                  () => tokens\n                )\n              : tokens\n          )\n          .then((tokens) => parser(tokens, opt))\n          .then((html) => (opt.hooks ? opt.hooks.postprocess(html) : html))\n          .catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html);\n        }\n        return html;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse;\n  }\n  onError(silent, async) {\n    return (e) => {\n      e.message +=\n        \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg =\n          \"<p>An error occurred:</p><pre>\" +\n          escape$1(e.message + \"\", true) +\n          \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n\nconst markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options = marked.setOptions = function (options) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = _Parser.parse;\nconst lexer = _Lexer.lex;\n\nexport {\n  _Hooks as Hooks,\n  _Lexer as Lexer,\n  Marked,\n  _Parser as Parser,\n  _Renderer as Renderer,\n  _TextRenderer as TextRenderer,\n  _Tokenizer as Tokenizer,\n  _defaults as defaults,\n  _getDefaults as getDefaults,\n  lexer,\n  marked,\n  options,\n  parse,\n  parseInline,\n  parser,\n  setOptions,\n  use,\n  walkTokens,\n};\n//# sourceMappingURL=marked.esm.js.map\n"
        },
        "unescape": {
          "metadata": {
            "description": "",
            "url": "unescape.js"
          },
          "code": "export { unescape };\n\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\n\nconst namedEntities = {\n  colon: \":\",\n  quot: '\"',\n  amp: \"&\",\n  lt: \"<\",\n  gt: \">\",\n  apos: \"'\",\n  // add more as needed\n};\n\nfunction unescape(html) {\n  return html.replace(unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n in namedEntities) return namedEntities[n];\n\n    if (n.charAt(0) === \"#\") {\n      const code =\n        n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n\n      return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n    }\n    return \"\";\n  });\n}\n"
        }
      },
      "metadata": {
        "tags": [],
        "icon": "google-drive"
      }
    },
    "readFromDoc": {
      "title": "Read From Doc",
      "description": "Loads a Google Drive document, converts it to Markdown, and returns it as a single-turn conversation context.",
      "version": "0.0.1",
      "nodes": [
        {
          "type": "input",
          "id": "input",
          "configuration": {
            "schema": {
              "properties": {
                "documentid": {
                  "type": "object",
                  "title": "Document",
                  "behavior": [
                    "google-drive-file-id",
                    "config"
                  ],
                  "description": "Pick the document to read from."
                }
              },
              "type": "object",
              "required": []
            }
          },
          "metadata": {
            "visual": {
              "x": -154,
              "y": -224,
              "collapsed": "expanded"
            },
            "logLevel": "debug"
          }
        },
        {
          "type": "output",
          "id": "output",
          "configuration": {
            "schema": {
              "properties": {
                "context": {
                  "type": "array",
                  "title": "Context",
                  "items": {
                    "type": "object",
                    "behavior": [
                      "llm-content"
                    ]
                  },
                  "default": "null"
                }
              },
              "type": "object",
              "required": []
            }
          },
          "metadata": {
            "visual": {
              "x": 490,
              "y": -218,
              "collapsed": "expanded"
            }
          }
        },
        {
          "id": "runModule-82b2b71c",
          "type": "runModule",
          "metadata": {
            "visual": {
              "x": 125,
              "y": -240,
              "collapsed": "expanded"
            },
            "title": "Read From Doc",
            "logLevel": "debug"
          },
          "configuration": {
            "$module": "main"
          }
        }
      ],
      "edges": [
        {
          "from": "input",
          "to": "runModule-82b2b71c",
          "out": "documentid",
          "in": "id"
        },
        {
          "from": "runModule-82b2b71c",
          "to": "output",
          "out": "context",
          "in": "context"
        }
      ],
      "modules": {
        "main": {
          "code": "import { connect, exportFile, unwrap } from \"./api\";\n\nexport { invoke as default, describe };\n\nasync function invoke({ id }) {\n  let { id: fileId, preview } = id || {};\n  if (!fileId) {\n    return error(\"Please provide Google Drive File ID\");\n  }\n  const token = await connect({\n    title: \"Get API Token\",\n    description: \"Requesting Google Drive API Auth token\",\n  });\n  const text = unwrap(\n    await exportFile(token, fileId, \"text/markdown\", {\n      title: `Convert ${preview} to Markdown`,\n      description: `Converting ${preview} to Markdown`,\n    }),\n    `Unable to export file \"${preview}\" and/or convert it to Markdown`\n  );\n  return { context: [{ parts: [{ text }], role: \"user\" }] };\n}\n\nasync function describe() {\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        id: {\n          type: \"string\",\n          title: \"File ID\",\n          behavior: [\"google-drive-file-id\"],\n        },\n      },\n    },\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n    },\n  };\n}\n\nfunction error($error) {\n  return { $error };\n}\n",
          "metadata": {
            "runnable": true
          }
        },
        "api": {
          "code": "import fetch from \"@fetch\";\nimport secrets from \"@secrets\";\n\nconst connectionId = \"connection:google-drive-limited\";\n\nexport {\n  connect,\n  get,\n  exportFile,\n  create,\n  del,\n  query,\n  createMultipart,\n  getDoc,\n  updateDoc,\n  unwrap,\n};\n\nasync function get(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply file id.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"GET\"\n  );\n}\n\nasync function exportFile(token, id, mimeType, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply file id.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}/export?mimeType=${encodeURIComponent(mimeType)}`,\n    \"GET\"\n  );\n}\n\nasync function create(token, body, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the file to create.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    \"https://www.googleapis.com/drive/v3/files\",\n    \"POST\",\n    body\n  );\n}\n\nasync function query(token, query, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!query) {\n    return error(\"Please supply the query.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`,\n    \"GET\"\n  );\n}\n\nasync function del(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the file to delete\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"DELETE\"\n  );\n}\n\nasync function getDoc(token, id, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the doc id to get.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}`,\n    \"GET\"\n  );\n}\n\nasync function updateDoc(token, id, body, metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the doc to update.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the doc update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function connect(metadata) {\n  const { [connectionId]: token } = await secrets({\n    ...meta(metadata),\n    keys: [connectionId],\n  });\n  return token;\n}\n\nasync function createMultipart(token, metadata, body, mimeType, $metadata) {\n  const boundary = \"BB-BB-BB-BB-BB-BB\";\n  const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n  const request = {\n    ...meta($metadata),\n    url,\n    method: \"POST\",\n    headers: {\n      Authorization: `Bearer ${token}`,\n      [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n    },\n    body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\n\n${body}\n--${boundary}--`,\n  };\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error };\n  }\n  return { success: true, info: response };\n}\n\nasync function api(metadata, token, url, method, body = null) {\n  const request = {\n    ...meta(metadata),\n    url,\n    method,\n    headers: {\n      Authorization: `Bearer ${token}`,\n    },\n  };\n  if (body) {\n    request.body = body;\n  }\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error };\n  }\n  return { success: true, info: response };\n}\n\nfunction unwrap(result, message = \"Error\") {\n  if (result.error) {\n    throw new Error(`${message}:\\n${JSON.stringify(result.error)}`);\n  }\n  return result.info;\n}\n\nfunction error(message) {\n  return {\n    success: false,\n    error: message,\n  };\n}\n\nfunction meta({ title, description } = {}) {\n  if (!(title || description)) return {};\n  const $metadata = {};\n  if (title) {\n    $metadata.title = title;\n  }\n  if (description) {\n    $metadata.description = description;\n  }\n  return { $metadata };\n}\n",
          "metadata": {
            "runnable": false
          }
        }
      },
      "metadata": {
        "tags": [],
        "icon": "google-drive"
      }
    },
    "contextToSlides": {
      "title": "Context to Slides v3",
      "description": "Turns LLM Conversation Context into a Google Slides presentation",
      "version": "2.0.0",
      "main": "main",
      "modules": {
        "main": {
          "code": "/**\n * @fileoverview Main module\n */\nimport { connect, createPresentation, updatePresentation, getPresentation, unwrap, query, create, createMultipart, del, createPermission, } from \"./api\";\nimport { ImageUploader } from \"./images\";\nimport { marked } from \"./marked\";\nimport { SlideBuilder } from \"./slides\";\nexport { invoke as default, describe };\nconst DEFAULT_TITLE = \"Untitled Presentation (Created with Breadboard)\";\nasync function invoke({ context, title = DEFAULT_TITLE }) {\n    const token = await connect({ title: \"Get API Token \" });\n    const { id, end, objectId } = await getCollectorId(token, title);\n    const slideBuilder = new SlideBuilder(end + 1, objectId);\n    readContext(context, {\n        text: (text) => slideBuilder.addMarkdown(text),\n        inlineData: (data) => slideBuilder.addInlineData(data),\n    });\n    const imageUploader = new ImageUploader(token);\n    const imageUrls = await imageUploader.upload(slideBuilder.images());\n    const requests = slideBuilder.build(imageUrls);\n    const update = unwrap(await updatePresentation(token, id, { requests }, { title: \"Update Presentation\" }), \"Failed to update presentation\");\n    await imageUploader.cleanup();\n    return { url: `https://drive.google.com/file/d/${id}` };\n}\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * presentation to which context is appended.\n */\nasync function getCollectorId(token, title) {\n    const file = unwrap(await query(token, `appProperties has { key = 'appendToSlides' and value = '${title}' } and trashed = false`, { title: \"Find the presentation file\" }), \"Failed to call Drive API to find the file to append\").files.at(0);\n    let id;\n    let deleteFirst = false;\n    if (!file) {\n        id = unwrap(await create(token, {\n            name: title,\n            mimeType: \"application/vnd.google-apps.presentation\",\n            appProperties: {\n                appendToSlides: title,\n            },\n        }, { title: \"Create a new presentation\" }), \"Failed to call Drive API to create a new file\").id;\n        deleteFirst = true;\n    }\n    else {\n        id = file.id;\n    }\n    const slides = unwrap(await getPresentation(token, id, { title: \"Get current doc contents\" }), \"Failed to get the Doc to append to\").slides;\n    let end = 0;\n    let objectId;\n    if (!slides) {\n        deleteFirst = false;\n    }\n    else if (deleteFirst) {\n        objectId = slides.at(0)?.objectId || undefined;\n    }\n    else {\n        end = slides.length;\n    }\n    return { id, end, objectId };\n}\nfunction readContext(context, handler) {\n    if (!Array.isArray(context)) {\n        if (typeof context === \"string\") {\n            handler.text(context);\n            return;\n        }\n        if (context === undefined || context === null) {\n            return;\n        }\n        handler.text(JSON.stringify(context));\n        return;\n    }\n    if (context.length === 0) {\n        return;\n    }\n    // For now, take the last item in context.\n    context = [context.at(-1)];\n    context.forEach((item) => {\n        if (\"parts\" in item) {\n            item.parts.forEach((part) => {\n                if (\"text\" in part) {\n                    return handler.text(part.text);\n                }\n                if (\"inlineData\" in part) {\n                    return handler.inlineData(part.inlineData);\n                }\n            });\n        }\n    });\n}\nasync function describe() {\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                title: {\n                    type: \"string\",\n                    behavior: [\"config\"],\n                    title: \"Name\",\n                    description: \"The title of the new Google Slide presentation.\",\n                    default: DEFAULT_TITLE,\n                },\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n            required: [\"context\"],\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                url: {\n                    type: \"string\",\n                    title: \"URL\",\n                    description: \"The URL of the newly created presentation\",\n                },\n            },\n        },\n    };\n}\n",
          "metadata": {
            "description": "Main module",
            "url": "main.js",
            "source": {
              "code": "/**\n * @fileoverview Main module\n */\n\nimport {\n  connect,\n  createPresentation,\n  updatePresentation,\n  getPresentation,\n  unwrap,\n  query,\n  create,\n  createMultipart,\n  del,\n  createPermission,\n  type SlidesRequest,\n} from \"./api\";\n\nimport { ImageUploader } from \"./images\";\n\nimport type { LLMContent, InlineDataCapabilityPart } from \"./types\";\nimport { marked } from \"./marked\";\nimport { SlideBuilder } from \"./slides\";\n\nexport { invoke as default, describe };\n\nexport type InvokeInputs = {\n  context: LLMContent[];\n  title: string;\n};\n\nconst DEFAULT_TITLE = \"Untitled Presentation (Created with Breadboard)\";\n\nasync function invoke({ context, title = DEFAULT_TITLE }: InvokeInputs) {\n  const token = await connect({ title: \"Get API Token \" });\n\n  const { id, end, objectId } = await getCollectorId(token, title);\n\n  const slideBuilder = new SlideBuilder(end + 1, objectId);\n  readContext(context, {\n    text: (text) => slideBuilder.addMarkdown(text),\n    inlineData: (data) => slideBuilder.addInlineData(data),\n  });\n  const imageUploader = new ImageUploader(token);\n  const imageUrls = await imageUploader.upload(slideBuilder.images());\n  const requests = slideBuilder.build(imageUrls);\n\n  const update = unwrap(\n    await updatePresentation(\n      token,\n      id,\n      { requests },\n      { title: \"Update Presentation\" }\n    ),\n    \"Failed to update presentation\"\n  );\n  await imageUploader.cleanup();\n  return { url: `https://drive.google.com/file/d/${id}` };\n}\n\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * presentation to which context is appended.\n */\nasync function getCollectorId(token: string, title: string) {\n  const file = unwrap(\n    await query(\n      token,\n      `appProperties has { key = 'appendToSlides' and value = '${title}' } and trashed = false`,\n      { title: \"Find the presentation file\" }\n    ),\n    \"Failed to call Drive API to find the file to append\"\n  ).files.at(0);\n  let id;\n  let deleteFirst = false;\n  if (!file) {\n    id = unwrap(\n      await create(\n        token,\n        {\n          name: title,\n          mimeType: \"application/vnd.google-apps.presentation\",\n          appProperties: {\n            appendToSlides: title,\n          },\n        },\n        { title: \"Create a new presentation\" }\n      ),\n      \"Failed to call Drive API to create a new file\"\n    ).id;\n    deleteFirst = true;\n  } else {\n    id = file.id;\n  }\n  const slides = unwrap(\n    await getPresentation(token, id, { title: \"Get current doc contents\" }),\n    \"Failed to get the Doc to append to\"\n  ).slides;\n\n  let end = 0;\n  let objectId: string | undefined;\n  if (!slides) {\n    deleteFirst = false;\n  } else if (deleteFirst) {\n    objectId = slides.at(0)?.objectId || undefined;\n  } else {\n    end = slides.length;\n  }\n\n  return { id, end, objectId };\n}\n\ntype ContextHandler = {\n  text: (text: string) => void;\n  inlineData: (inlineData: InlineDataCapabilityPart[\"inlineData\"]) => void;\n};\n\nfunction readContext(context: LLMContent[], handler: ContextHandler): void {\n  if (!Array.isArray(context)) {\n    if (typeof context === \"string\") {\n      handler.text(context);\n      return;\n    }\n    if (context === undefined || context === null) {\n      return;\n    }\n    handler.text(JSON.stringify(context));\n    return;\n  }\n  if (context.length === 0) {\n    return;\n  }\n  // For now, take the last item in context.\n  context = [context.at(-1)!];\n  context.forEach((item) => {\n    if (\"parts\" in item) {\n      item.parts.forEach((part) => {\n        if (\"text\" in part) {\n          return handler.text(part.text);\n        }\n        if (\"inlineData\" in part) {\n          return handler.inlineData(part.inlineData);\n        }\n      });\n    }\n  });\n}\n\nasync function describe() {\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        title: {\n          type: \"string\",\n          behavior: [\"config\"],\n          title: \"Name\",\n          description: \"The title of the new Google Slide presentation.\",\n          default: DEFAULT_TITLE,\n        },\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n        },\n      },\n      required: [\"context\"],\n    },\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        url: {\n          type: \"string\",\n          title: \"URL\",\n          description: \"The URL of the newly created presentation\",\n        },\n      },\n    },\n  };\n}\n",
              "language": "typescript"
            },
            "runnable": true
          }
        },
        "types": {
          "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n",
          "metadata": {
            "runnable": false,
            "source": {
              "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n/**\n * All Breadboard values must be JSON serializable, and this is the set of\n * JSON serializable types.\n */\nexport type JsonSerializable =\n  | string\n  | number\n  | boolean\n  | null\n  | Array<JsonSerializable>\n  | {\n      [K: string]: JsonSerializable;\n    };\n\nexport type FunctionCallCapabilityPart = {\n  functionCall: {\n    name: string;\n    args: object;\n  };\n};\n\nexport type FunctionResponseCapabilityPart = {\n  functionResponse: {\n    name: string;\n    response: object;\n  };\n};\n\nexport type TextCapabilityPart = {\n  text: string;\n};\n\nexport type DataStoreHandle = string;\n\n/**\n * Represents data that is stored by a DataStoreProvider.\n */\nexport type StoredDataCapabilityPart = {\n  storedData: {\n    handle: DataStoreHandle;\n    mimeType: string;\n  };\n};\n\nexport type DataPart =\n  | InlineDataCapabilityPart\n  | StoredDataCapabilityPart\n  | FunctionCallCapabilityPart\n  | FunctionResponseCapabilityPart\n  | TextCapabilityPart;\n\nexport type LLMContent = {\n  role?: string;\n  parts: DataPart[];\n};\n\n/**\n * Represents inline data, encoded as a base64 string.\n */\nexport type InlineDataCapabilityPart = {\n  inlineData: {\n    mimeType: string;\n    data: string;\n  };\n};\n",
              "language": "typescript"
            },
            "description": ""
          }
        },
        "marked": {
          "code": "/**\n * marked v14.1.3 - a markdown parser\n * Copyright (c) 2011-2024, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n/**\n * Gets the original marked default options.\n */\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\nlet _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n/**\n * Helpers\n */\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = new RegExp(escapeTest.source, \"g\");\nconst escapeTestNoEncode = /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/;\nconst escapeReplaceNoEncode = new RegExp(escapeTestNoEncode.source, \"g\");\nconst escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\",\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nfunction escape$1(html, encode) {\n  if (encode) {\n    if (escapeTest.test(html)) {\n      return html.replace(escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (escapeTestNoEncode.test(html)) {\n      return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html;\n}\nconst caret = /(^|[^\\[])\\^/g;\nfunction edit(regex, opt) {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  opt = opt || \"\";\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(/%25/g, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nconst noopTest = { exec: () => null };\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return \"|\";\n      } else {\n        // add space before unescaped |\n        return \" |\";\n      }\n    }),\n    cells = row.split(/ \\|/);\n  let i = 0;\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, \"|\");\n  }\n  return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  return -1;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n  const href = link.href;\n  const title = link.title ? escape$1(link.title) : null;\n  const text = cap[1].replace(/\\\\([\\[\\]])/g, \"$1\");\n  if (cap[0].charAt(0) !== \"!\") {\n    lexer.state.inLink = true;\n    const token = {\n      type: \"link\",\n      raw,\n      href,\n      title,\n      text,\n      tokens: lexer.inlineTokens(text),\n    };\n    lexer.state.inLink = false;\n    return token;\n  }\n  return {\n    type: \"image\",\n    raw,\n    href,\n    title,\n    text: escape$1(text),\n  };\n}\nfunction indentCodeCompensation(raw, text) {\n  const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text\n    .split(\"\\n\")\n    .map((node) => {\n      const matchIndentInNode = node.match(/^\\s+/);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n      const [indentInNode] = matchIndentInNode;\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n      return node;\n    })\n    .join(\"\\n\");\n}\n/**\n * Tokenizer\n */\nclass _Tokenizer {\n  options;\n  rules; // set by the lexer\n  lexer; // set by the lexer\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0],\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(/^(?: {1,4}| {0,3}\\t)/gm, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text,\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\");\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2]\n          ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\")\n          : cap[2],\n        text,\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      // remove trailing #s\n      if (/#$/.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || / $/.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\"),\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (/^ {0,3}>/.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(/\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g, \"\\n    $1\")\n          .replace(/^ {0,3}>[ \\t]?/gm, \"\");\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens[tokens.length - 1];\n        if (lastToken?.type === \"code\") {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          // include continuation in nested blockquote\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.text.length) +\n            newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          // include continuation in nested list\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText\n            .substring(tokens[tokens.length - 1].raw.length)\n            .split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: [],\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      // Get next list item\n      const itemRegex = new RegExp(\n        `^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`\n      );\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2]\n          .split(\"\\n\", 1)[0]\n          .replace(/^\\t+/, (t) => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(/[^ ]/); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && /^[ \\t]*$/.test(nextLine)) {\n          // Items begin with at most one blank line\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`\n          );\n          const hrRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`\n          );\n          const fencesBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`\n          );\n          const headingBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}#`\n          );\n          const htmlBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}<[a-z].*>`,\n            \"i\"\n          );\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(/^ {1,4}(?=( {4})*[^ ])/g, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(/\\t/g, \"    \");\n            }\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (\n              nextLineWithoutTabs.search(/[^ ]/) >= indent ||\n              !nextLine.trim()\n            ) {\n              // Dedent if possible\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(/\\t/g, \"    \").search(/[^ ]/) >= 4) {\n                // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              // Check if current line is blank\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (/\\n[ \\t]*\\n[ \\t]*$/.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = /^\\[[ xX]\\] /.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(/^\\[[ xX]\\] +/, \"\");\n          }\n        }\n        list.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n        list.raw += raw;\n      }\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      list.items[list.items.length - 1].raw =\n        list.items[list.items.length - 1].raw.trimEnd();\n      list.items[list.items.length - 1].text =\n        list.items[list.items.length - 1].text.trimEnd();\n      list.raw = list.raw.trimEnd();\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(\n            (t) => t.type === \"space\"\n          );\n          const hasMultipleLineBreaks =\n            spacers.length > 0 && spacers.some((t) => /\\n.*\\n/.test(t.raw));\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n      return list;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(/\\s+/g, \" \");\n      const href = cap[2]\n        ? cap[2]\n            .replace(/^<(.*)>$/, \"$1\")\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : \"\";\n      const title = cap[3]\n        ? cap[3]\n            .substring(1, cap[3].length - 1)\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : cap[3];\n      return {\n        type: \"def\",\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!/[:|]/.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(/^\\||\\| *$/g, \"\").split(\"|\");\n    const rows =\n      cap[3] && cap[3].trim()\n        ? cap[3].replace(/\\n[ \\t]*$/, \"\").split(\"\\n\")\n        : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n    for (const align of aligns) {\n      if (/^ *-+: *$/.test(align)) {\n        item.align.push(\"right\");\n      } else if (/^ *:-+: *$/.test(align)) {\n        item.align.push(\"center\");\n      } else if (/^ *:-+ *$/.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(\n        splitCells(row, item.header.length).map((cell, i) => {\n          return {\n            text: cell,\n            tokens: this.lexer.inline(cell),\n            header: false,\n            align: item.align[i],\n          };\n        })\n      );\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text =\n        cap[1].charAt(cap[1].length - 1) === \"\\n\"\n          ? cap[1].slice(0, -1)\n          : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: escape$1(cap[1]),\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (\n        !this.lexer.state.inRawBlock &&\n        /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = true;\n      } else if (\n        this.lexer.state.inRawBlock &&\n        /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!/>$/.test(trimmedUrl)) {\n          return;\n        }\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (/^</.test(href)) {\n        if (this.options.pedantic && !/>$/.test(trimmedUrl)) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(\n        cap,\n        {\n          href: href\n            ? href.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : href,\n          title: title\n            ? title.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : title,\n        },\n        cap[0],\n        this.lexer\n      );\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if (\n      (cap = this.rules.inline.reflink.exec(src)) ||\n      (cap = this.rules.inline.nolink.exec(src))\n    ) {\n      const linkString = (cap[2] || cap[1]).replace(/\\s+/g, \" \");\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (\n      !nextChar ||\n      !prevChar ||\n      this.rules.inline.punctuation.exec(prevChar)\n    ) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg =\n        match[0][0] === \"*\"\n          ? this.rules.inline.emStrongRDelimAst\n          : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim =\n          match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue; // skip single * in __abc*abc__\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(\n          0,\n          lLength + match.index + lastCharLength + rLength\n        );\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(/\\n/g, \" \");\n      const hasNonSpaceChars = /[^ ]/.test(text);\n      const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      text = escape$1(text, true);\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0],\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[1]);\n        href = \"mailto:\" + text;\n      } else {\n        text = escape$1(cap[1]);\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if ((cap = this.rules.inline.url.exec(src))) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[0]);\n        href = \"mailto:\" + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = escape$1(cap[0]);\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      let text;\n      if (this.lexer.state.inRawBlock) {\n        text = cap[0];\n      } else {\n        text = escape$1(cap[0]);\n      }\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n}\n\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences =\n  /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheading = edit(\n  /^(?!bull |blockCode|fences|blockquote|heading|html)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/\n)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .getRegex();\nconst _paragraph =\n  /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(\n  /^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/\n)\n  .replace(\"label\", _blockLabel)\n  .replace(\n    \"title\",\n    /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/\n  )\n  .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\nconst _tag =\n  \"address|article|aside|base|basefont|blockquote|body|caption\" +\n  \"|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption\" +\n  \"|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe\" +\n  \"|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option\" +\n  \"|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title\" +\n  \"|tr|track|ul\";\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  \"^ {0,3}(?:\" + // optional indentation\n    \"<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)\" + // (1)\n    \"|comment[^\\\\n]*(\\\\n+|$)\" + // (2)\n    \"|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)\" + // (3)\n    \"|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)\" + // (4)\n    \"|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)\" + // (5)\n    \"|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (6)\n    \"|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) open tag\n    \"|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) closing tag\n    \")\",\n  \"i\"\n)\n  .replace(\"comment\", _comment)\n  .replace(\"tag\", _tag)\n  .replace(\n    \"attribute\",\n    / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst paragraph = edit(_paragraph)\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n  .replace(\"|table\", \"\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace(\"paragraph\", paragraph)\n  .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit(\n  \"^ *([^\\\\n ].*)\\\\n\" + // Header\n    \" {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)\" + // Align\n    \"(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\"\n) // Cells\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"code\", \"(?: {4}| {0,3}\\t)[^\\\\n]\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockGfm = {\n  ...blockNormal,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n    .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n    .replace(\"table\", gfmTable) // interrupt paragraphs with table\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n    .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n    .replace(\n      \"html\",\n      \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n    )\n    .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n  ...blockNormal,\n  html: edit(\n    \"^ *(?:comment *(?:\\\\n|\\\\s*$)\" +\n      \"|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)\" + // closed tag\n      \"|<tag(?:\\\"[^\\\"]*\\\"|'[^']*'|\\\\s[^'\\\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))\"\n  )\n    .replace(\"comment\", _comment)\n    .replace(\n      /tag/g,\n      \"(?!(?:\" +\n        \"a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub\" +\n        \"|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\" +\n        \"\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\"\n    )\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" *#{1,6} *[^\\n]\")\n    .replace(\"lheading\", lheading)\n    .replace(\"|table\", \"\")\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"|fences\", \"\")\n    .replace(\"|list\", \"\")\n    .replace(\"|html\", \"\")\n    .replace(\"|tag\", \"\")\n    .getRegex(),\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText =\n  /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = \"\\\\p{P}\\\\p{S}\";\nconst punctuation = edit(/^((?![*_])[\\spunctuation])/, \"u\")\n  .replace(/punctuation/g, _punctuation)\n  .getRegex();\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip =\n  /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelim = edit(\n  /^(?:\\*+(?:((?!\\*)[punct])|[^\\s*]))|^_+(?:((?!_)[punct])|([^\\s_]))/,\n  \"u\"\n)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst emStrongRDelimAst = edit(\n  \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)\" + // Skip orphan inside strong\n    \"|[^*]+(?=[^*])\" + // Consume to delim\n    \"|(?!\\\\*)[punct](\\\\*+)(?=[\\\\s]|$)\" + // (1) #*** can only be a Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?!\\\\*)(?=[punct\\\\s]|$)\" + // (2) a***#, a*** can only be a Right Delimiter\n    \"|(?!\\\\*)[punct\\\\s](\\\\*+)(?=[^punct\\\\s])\" + // (3) #***a, ***a can only be Left Delimiter\n    \"|[\\\\s](\\\\*+)(?!\\\\*)(?=[punct])\" + // (4) ***# can only be Left Delimiter\n    \"|(?!\\\\*)[punct](\\\\*+)(?!\\\\*)(?=[punct])\" + // (5) #***# can be either Left or Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?=[^punct\\\\s])\",\n  \"gu\"\n) // (6) a***a can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  \"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)\" + // Skip orphan inside strong\n    \"|[^_]+(?=[^_])\" + // Consume to delim\n    \"|(?!_)[punct](_+)(?=[\\\\s]|$)\" + // (1) #___ can only be a Right Delimiter\n    \"|[^punct\\\\s](_+)(?!_)(?=[punct\\\\s]|$)\" + // (2) a___#, a___ can only be a Right Delimiter\n    \"|(?!_)[punct\\\\s](_+)(?=[^punct\\\\s])\" + // (3) #___a, ___a can only be Left Delimiter\n    \"|[\\\\s](_+)(?!_)(?=[punct])\" + // (4) ___# can only be Left Delimiter\n    \"|(?!_)[punct](_+)(?!_)(?=[punct])\",\n  \"gu\"\n) // (5) #___# can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst anyPunctuation = edit(/\\\\([punct])/, \"gu\")\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace(\n    \"email\",\n    /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/\n  )\n  .getRegex();\nconst _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nconst tag = edit(\n  \"^comment\" +\n    \"|^</[a-zA-Z][\\\\w:-]*\\\\s*>\" + // self-closing tag\n    \"|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>\" + // open tag\n    \"|^<\\\\?[\\\\s\\\\S]*?\\\\?>\" + // processing instruction, e.g. <?php ?>\n    \"|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>\" + // declaration, e.g. <!DOCTYPE html>\n    \"|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\"\n) // CDATA section\n  .replace(\"comment\", _inlineComment)\n  .replace(\n    \"attribute\",\n    /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n  .replace(\n    \"title\",\n    /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/\n  )\n  .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\")\n  .replace(\"reflink\", reflink)\n  .replace(\"nolink\", nolink)\n  .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n  ...inlineNormal,\n  escape: edit(escape).replace(\"])\", \"~|])\").getRegex(),\n  url: edit(\n    /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n    \"i\"\n  )\n    .replace(\n      \"email\",\n      /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/\n    )\n    .getRegex(),\n  _backpedal:\n    /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text)\n    .replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\")\n    .replace(/\\{2,\\}/g, \"*\")\n    .getRegex(),\n};\n/**\n * exports\n */\nconst block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\nconst inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\n/**\n * Block Lexer\n */\nclass _Lexer {\n  tokens;\n  options;\n  state;\n  tokenizer;\n  inlineQueue;\n  constructor(options) {\n    // TokenList cannot be created in one go\n    this.tokens = [];\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n    const rules = {\n      block: block.normal,\n      inline: inline.normal,\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(/\\r\\n|\\r/g, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(/\\t/g, \"    \").replace(/^ +$/gm, \"\");\n    }\n    let token;\n    let lastToken;\n    let cutSrc;\n    while (src) {\n      if (\n        this.options.extensions &&\n        this.options.extensions.block &&\n        this.options.extensions.block.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // newline\n      if ((token = this.tokenizer.space(src))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.length === 1 && tokens.length > 0) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          tokens[tokens.length - 1].raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.code(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        // An indented code block cannot interrupt a paragraph.\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // fences\n      if ((token = this.tokenizer.fences(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // heading\n      if ((token = this.tokenizer.heading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // hr\n      if ((token = this.tokenizer.hr(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // blockquote\n      if ((token = this.tokenizer.blockquote(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // list\n      if ((token = this.tokenizer.list(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // html\n      if ((token = this.tokenizer.html(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // def\n      if ((token = this.tokenizer.def(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n      // table (gfm)\n      if ((token = this.tokenizer.table(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // lheading\n      if ((token = this.tokenizer.lheading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        lastToken = tokens[tokens.length - 1];\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      // text\n      if ((token = this.tokenizer.text(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let token, lastToken, cutSrc;\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match;\n    let keepPrevChar, prevChar;\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while (\n          (match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) !=\n          null\n        ) {\n          if (\n            links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))\n          ) {\n            maskedSrc =\n              maskedSrc.slice(0, match.index) +\n              \"[\" +\n              \"a\".repeat(match[0].length - 2) +\n              \"]\" +\n              maskedSrc.slice(\n                this.tokenizer.rules.inline.reflinkSearch.lastIndex\n              );\n          }\n        }\n      }\n    }\n    // Mask out other blocks\n    while (\n      (match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"[\" +\n        \"a\".repeat(match[0].length - 2) +\n        \"]\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    // Mask out escaped characters\n    while (\n      (match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) !=\n      null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"++\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      // extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.inline &&\n        this.options.extensions.inline.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // escape\n      if ((token = this.tokenizer.escape(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // tag\n      if ((token = this.tokenizer.tag(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // link\n      if ((token = this.tokenizer.link(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // reflink, nolink\n      if ((token = this.tokenizer.reflink(src, this.tokens.links))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // em & strong\n      if ((token = this.tokenizer.emStrong(src, maskedSrc, prevChar))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.codespan(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // br\n      if ((token = this.tokenizer.br(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // del (gfm)\n      if ((token = this.tokenizer.del(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // autolink\n      if ((token = this.tokenizer.autolink(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if ((token = this.tokenizer.inlineText(cutSrc))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n}\n\n/**\n * Renderer\n */\nclass _Renderer {\n  options;\n  parser; // set by the parser\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({ text, lang, escaped }) {\n    const langString = (lang || \"\").match(/^\\S*/)?.[0];\n    const code = text.replace(/\\n$/, \"\") + \"\\n\";\n    if (!langString) {\n      return (\n        \"<pre><code>\" +\n        (escaped ? code : escape$1(code, true)) +\n        \"</code></pre>\\n\"\n      );\n    }\n    return (\n      '<pre><code class=\"language-' +\n      escape$1(langString) +\n      '\">' +\n      (escaped ? code : escape$1(code, true)) +\n      \"</code></pre>\\n\"\n    );\n  }\n  blockquote({ tokens }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n  html({ text }) {\n    return text;\n  }\n  heading({ tokens, depth }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens.length > 0 && item.tokens[0].type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (\n            item.tokens[0].tokens &&\n            item.tokens[0].tokens.length > 0 &&\n            item.tokens[0].tokens[0].type === \"text\"\n          ) {\n            item.tokens[0].tokens[0].text =\n              checkbox + \" \" + item.tokens[0].tokens[0].text;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\\n`;\n  }\n  checkbox({ checked }) {\n    return (\n      \"<input \" +\n      (checked ? 'checked=\"\" ' : \"\") +\n      'disabled=\"\" type=\"checkbox\">'\n    );\n  }\n  paragraph({ tokens }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n  table(token) {\n    let header = \"\";\n    // header\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return (\n      \"<table>\\n\" + \"<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\"\n    );\n  }\n  tablerow({ text }) {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({ tokens }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({ tokens }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({ text }) {\n    return `<code>${text}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({ tokens }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({ href, title, tokens }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({ href, title, text }) {\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${title}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : token.text;\n  }\n}\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nclass _TextRenderer {\n  // no need for block level renderers\n  strong({ text }) {\n    return text;\n  }\n  em({ text }) {\n    return text;\n  }\n  codespan({ text }) {\n    return text;\n  }\n  del({ text }) {\n    return text;\n  }\n  html({ text }) {\n    return text;\n  }\n  text({ text }) {\n    return text;\n  }\n  link({ text }) {\n    return \"\" + text;\n  }\n  image({ text }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n}\n\n/**\n * Parsing & Compiling\n */\nclass _Parser {\n  options;\n  renderer;\n  textRenderer;\n  constructor(options) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call(\n          { parser: this },\n          genericToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"space\",\n            \"hr\",\n            \"heading\",\n            \"code\",\n            \"table\",\n            \"blockquote\",\n            \"list\",\n            \"html\",\n            \"paragraph\",\n            \"text\",\n          ].includes(genericToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\": {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case \"hr\": {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case \"heading\": {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case \"code\": {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case \"table\": {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case \"blockquote\": {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case \"list\": {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case \"html\": {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case \"paragraph\": {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case \"text\": {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n            textToken = tokens[++i];\n            body += \"\\n\" + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: \"paragraph\",\n              raw: body,\n              text: body,\n              tokens: [{ type: \"text\", raw: body, text: body }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer) {\n    renderer = renderer || this.renderer;\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const ret = this.options.extensions.renderers[anyToken.type].call(\n          { parser: this },\n          anyToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"escape\",\n            \"html\",\n            \"link\",\n            \"image\",\n            \"strong\",\n            \"em\",\n            \"codespan\",\n            \"br\",\n            \"del\",\n            \"text\",\n          ].includes(anyToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\": {\n          out += renderer.text(token);\n          break;\n        }\n        case \"html\": {\n          out += renderer.html(token);\n          break;\n        }\n        case \"link\": {\n          out += renderer.link(token);\n          break;\n        }\n        case \"image\": {\n          out += renderer.image(token);\n          break;\n        }\n        case \"strong\": {\n          out += renderer.strong(token);\n          break;\n        }\n        case \"em\": {\n          out += renderer.em(token);\n          break;\n        }\n        case \"codespan\": {\n          out += renderer.codespan(token);\n          break;\n        }\n        case \"br\": {\n          out += renderer.br(token);\n          break;\n        }\n        case \"del\": {\n          out += renderer.del(token);\n          break;\n        }\n        case \"text\": {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n\nclass _Hooks {\n  options;\n  block;\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  static passThroughHooks = new Set([\n    \"preprocess\",\n    \"postprocess\",\n    \"processAllTokens\",\n  ]);\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html) {\n    return html;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n\nclass Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n  constructor(...args) {\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\": {\n          const tableToken = token;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case \"list\": {\n          const listToken = token;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach(\n              (childTokens) => {\n                const tokens = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens, callback));\n              }\n            );\n          } else if (genericToken.tokens) {\n            values = values.concat(\n              this.walkTokens(genericToken.tokens, callback)\n            );\n          }\n        }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {},\n    };\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack };\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function (...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            // Tokenizer Extensions\n            if (\n              !ext.level ||\n              (ext.level !== \"block\" && ext.level !== \"inline\")\n            ) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              // Function to check for start of token\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer =\n          this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(\n                  (ret) => {\n                    return prevHook.call(hooks, ret);\n                  }\n                );\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = { ...this.defaults, ...opts };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n  lexer(src, options) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n  parser(tokens, options) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse = (src, options) => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(\n          new Error(\n            \"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"\n          )\n        );\n      }\n      // throw error in case of non string input\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(\n          new Error(\"marked(): input parameter is undefined or null\")\n        );\n      }\n      if (typeof src !== \"string\") {\n        return throwError(\n          new Error(\n            \"marked(): input parameter is of type \" +\n              Object.prototype.toString.call(src) +\n              \", string expected\"\n          )\n        );\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer = opt.hooks\n        ? opt.hooks.provideLexer()\n        : blockType\n          ? _Lexer.lex\n          : _Lexer.lexInline;\n      const parser = opt.hooks\n        ? opt.hooks.provideParser()\n        : blockType\n          ? _Parser.parse\n          : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then((src) => lexer(src, opt))\n          .then((tokens) =>\n            opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens\n          )\n          .then((tokens) =>\n            opt.walkTokens\n              ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(\n                  () => tokens\n                )\n              : tokens\n          )\n          .then((tokens) => parser(tokens, opt))\n          .then((html) => (opt.hooks ? opt.hooks.postprocess(html) : html))\n          .catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html);\n        }\n        return html;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse;\n  }\n  onError(silent, async) {\n    return (e) => {\n      e.message +=\n        \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg =\n          \"<p>An error occurred:</p><pre>\" +\n          escape$1(e.message + \"\", true) +\n          \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n\nconst markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options = marked.setOptions = function (options) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = _Parser.parse;\nconst lexer = _Lexer.lex;\n\nexport {\n  _Hooks as Hooks,\n  _Lexer as Lexer,\n  Marked,\n  _Parser as Parser,\n  _Renderer as Renderer,\n  _TextRenderer as TextRenderer,\n  _Tokenizer as Tokenizer,\n  _defaults as defaults,\n  _getDefaults as getDefaults,\n  lexer,\n  marked,\n  options,\n  parse,\n  parseInline,\n  parser,\n  setOptions,\n  use,\n  walkTokens,\n};\n//# sourceMappingURL=marked.esm.js.map\n",
          "metadata": {
            "runnable": false,
            "description": ""
          }
        },
        "api": {
          "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\nimport fetch, {} from \"@fetch\";\nimport secrets from \"@secrets\";\nconst connectionId = \"connection:google-drive-limited\";\nexport { connect, get, create, del, query, createMultipart, getDoc, updateDoc, unwrap, createPresentation, getPresentation, updatePresentation, createPermission, };\nasync function get(token, id, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return error(\"Please supply file id.\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"GET\");\n}\nasync function create(token, body, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!body) {\n        return error(\"Please supply the body of the file to create.\");\n    }\n    return api(metadata, token, \"https://www.googleapis.com/drive/v3/files\", \"POST\", body);\n}\nasync function query(token, query, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!query) {\n        return error(\"Please supply the query.\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`, \"GET\");\n}\nasync function del(token, id, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return error(\"Please supply the id of the file to delete\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"DELETE\");\n}\nasync function getDoc(token, id, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return error(\"Please supply the doc id to get.\");\n    }\n    return api(metadata, token, `https://docs.googleapis.com/v1/documents/${id}`, \"GET\");\n}\nasync function updateDoc(token, id, body, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return error(\"Please supply the id of the doc to update.\");\n    }\n    if (!body) {\n        return error(\"Please supply the body of the doc update request.\");\n    }\n    return api(metadata, token, `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`, \"POST\", body);\n}\nasync function getPresentation(token, id, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    return api(metadata, token, `https://slides.googleapis.com/v1/presentations/${id}`, \"GET\");\n}\nasync function createPresentation(token, title, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    return api(metadata, token, \"https://slides.googleapis.com/v1/presentations\", \"POST\", { title });\n}\nasync function updatePresentation(token, id, body, metadata) {\n    if (!token) {\n        return error(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return error(\"Please supply the id of the presentation to update.\");\n    }\n    if (!body) {\n        return error(\"Please supply the body of the presentation update request.\");\n    }\n    return api(metadata, token, `https://slides.googleapis.com/v1/presentations/${id}:batchUpdate`, \"POST\", body);\n}\nasync function connect(metadata) {\n    const { [connectionId]: token } = await secrets({\n        ...meta(metadata),\n        keys: [connectionId],\n    });\n    return token;\n}\nasync function createMultipart(token, metadata, body, mimeType, $metadata) {\n    const boundary = \"BB-BB-BB-BB-BB-BB\";\n    const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n    const request = {\n        ...meta($metadata),\n        url,\n        method: \"POST\",\n        headers: {\n            Authorization: `Bearer ${token}`,\n            [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n        },\n        body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\nContent-Transfer-Encoding: base64\n\n${body}\n--${boundary}--`,\n    };\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return { success: false, error: $error };\n    }\n    return { success: true, info: response };\n}\nasync function createPermission(token, fileId, permission, metadata) {\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${fileId}/permissions`, \"POST\", permission);\n}\nasync function api(metadata, token, url, method, body = null) {\n    const request = {\n        ...meta(metadata),\n        url,\n        method,\n        headers: {\n            Authorization: `Bearer ${token}`,\n        },\n    };\n    if (body) {\n        request.body = body;\n    }\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return { success: false, error: $error };\n    }\n    return { success: true, info: response };\n}\nfunction unwrap(result, message = \"Error\") {\n    if (\"error\" in result) {\n        throw new Error(`${message}:\\n${JSON.stringify(result.error)}`);\n    }\n    return result.info;\n}\nfunction error(message) {\n    return {\n        success: false,\n        error: message,\n    };\n}\nfunction meta({ title, description } = {}) {\n    if (!(title || description))\n        return {};\n    const $metadata = {};\n    if (title) {\n        $metadata.title = title;\n    }\n    if (description) {\n        $metadata.description = description;\n    }\n    return { $metadata };\n}\n",
          "metadata": {
            "runnable": false,
            "source": {
              "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// These are various Google Drive-specific types.\n\nexport type CreateFileResponse = {\n  id: string;\n};\n\nexport type FileQueryResponse = {\n  files: FileInfo[];\n};\n\nexport type FileInfo = {\n  id: string;\n};\n\n/**\n * A Google Slides presentation.\n */\nexport interface SlidesPresentation {\n  /**\n   * The layouts in the presentation. A layout is a template that determines how content is arranged and styled on the slides that inherit from that layout.\n   */\n  layouts?: SlidesPage[];\n  /**\n   * The locale of the presentation, as an IETF BCP 47 language tag.\n   */\n  locale?: string | null;\n  /**\n   * The slide masters in the presentation. A slide master contains all common page elements and the common properties for a set of layouts. They serve three purposes: - Placeholder shapes on a master contain the default text styles and shape properties of all placeholder shapes on pages that use that master. - The master page properties define the common page properties inherited by its layouts. - Any other shapes on the master slide appear on all slides using that master, regardless of their layout.\n   */\n  masters?: SlidesPage[];\n  /**\n   * The notes master in the presentation. It serves three purposes: - Placeholder shapes on a notes master contain the default text styles and shape properties of all placeholder shapes on notes pages. Specifically, a `SLIDE_IMAGE` placeholder shape contains the slide thumbnail, and a `BODY` placeholder shape contains the speaker notes. - The notes master page properties define the common page properties inherited by all notes pages. - Any other shapes on the notes master appear on all notes pages. The notes master is read-only.\n   */\n  notesMaster?: SlidesPage;\n  /**\n   * The size of pages in the presentation.\n   */\n  pageSize?: SlidesSize;\n  /**\n   * The ID of the presentation.\n   */\n  presentationId?: string | null;\n  /**\n   * Output only. The revision ID of the presentation. Can be used in update requests to assert the presentation revision hasn't changed since the last read operation. Only populated if the user has edit access to the presentation. The revision ID is not a sequential number but a nebulous string. The format of the revision ID may change over time, so it should be treated opaquely. A returned revision ID is only guaranteed to be valid for 24 hours after it has been returned and cannot be shared across users. If the revision ID is unchanged between calls, then the presentation has not changed. Conversely, a changed ID (for the same presentation and user) usually means the presentation has been updated. However, a changed ID can also be due to internal factors such as ID format changes.\n   */\n  revisionId?: string | null;\n  /**\n   * The slides in the presentation. A slide inherits properties from a slide layout.\n   */\n  slides?: SlidesPage[];\n  /**\n   * The title of the presentation.\n   */\n  title?: string | null;\n}\n\n/**\n * A width and height.\n */\nexport interface SlidesSize {\n  /**\n   * The height of the object.\n   */\n  height?: SlidesDimension;\n  /**\n   * The width of the object.\n   */\n  width?: SlidesDimension;\n}\n\n/**\n * A page in a presentation.\n */\nexport interface SlidesPage {\n  /**\n   * Layout specific properties. Only set if page_type = LAYOUT.\n   */\n  layoutProperties?: unknown; // Schema$LayoutProperties;\n  /**\n   * Master specific properties. Only set if page_type = MASTER.\n   */\n  masterProperties?: unknown; // Schema$MasterProperties;\n  /**\n   * Notes specific properties. Only set if page_type = NOTES.\n   */\n  notesProperties?: unknown; // Schema$NotesProperties;\n  /**\n   * The object ID for this page. Object IDs used by Page and PageElement share the same namespace.\n   */\n  objectId?: string | null;\n  /**\n   * The page elements rendered on the page.\n   */\n  pageElements?: unknown[]; // Schema$PageElement[];\n  /**\n   * The properties of the page.\n   */\n  pageProperties?: unknown; // Schema$PageProperties;\n  /**\n   * The type of the page.\n   */\n  pageType?: string | null;\n  /**\n   * Output only. The revision ID of the presentation. Can be used in update requests to assert the presentation revision hasn't changed since the last read operation. Only populated if the user has edit access to the presentation. The revision ID is not a sequential number but an opaque string. The format of the revision ID might change over time. A returned revision ID is only guaranteed to be valid for 24 hours after it has been returned and cannot be shared across users. If the revision ID is unchanged between calls, then the presentation has not changed. Conversely, a changed ID (for the same presentation and user) usually means the presentation has been updated. However, a changed ID can also be due to internal factors such as ID format changes.\n   */\n  revisionId?: string | null;\n  /**\n   * Slide specific properties. Only set if page_type = SLIDE.\n   */\n  slideProperties?: unknown; // Schema$SlideProperties;\n}\n\nexport type TextToSlideRequestsResult = {\n  requests: SlidesRequest[];\n  prevSlideId: number;\n};\n\nexport type SlidesDeleteObjectRequest = {\n  objectId: string;\n};\n\n/**\n * The placeholder information that uniquely identifies a placeholder shape.\n */\nexport type SlidesPlaceholder = {\n  /**\n   * The index of the placeholder. If the same placeholder types are present in the same page, they would have different index values.\n   */\n  index?: number | null;\n  /**\n   * The object ID of this shape's parent placeholder. If unset, the parent placeholder shape does not exist, so the shape does not inherit properties from any other shape.\n   */\n  parentObjectId?: string | null;\n  /**\n   * The type of the placeholder.\n   */\n  type?: string | null;\n};\n\nexport type SlidesTextRangeType =\n  // A fixed range. Both the startIndex and endIndex must be specified.\n  | \"FIXED_RANGE\"\n  // Starts the range at startIndex and continues until the end of the\n  // collection. The endIndex must not be specified.\n  | \"FROM_START_INDEX\"\n  | \"ALL\";\n\nexport type SlidesTextRange = {\n  startIndex?: number;\n  endIndex?: number;\n  type: SlidesTextRangeType;\n};\n\nexport type SlidesLayoutPlaceholderIdMapping = {\n  /**\n   * The placeholder on a layout that will be applied to a slide. Only type and index are needed. For example, a predefined `TITLE_AND_BODY` layout may usually have a TITLE placeholder with index 0 and a BODY placeholder with index 0.\n   */\n  layoutPlaceholder?: SlidesPlaceholder;\n  /**\n   * The object ID of the placeholder on a layout that will be applied to a slide.\n   */\n  layoutPlaceholderObjectId?: string | null;\n  /**\n   * A user-supplied object ID for the placeholder identified above that to be created onto a slide. If you specify an ID, it must be unique among all pages and page elements in the presentation. The ID must start with an alphanumeric character or an underscore (matches regex `[a-zA-Z0-9_]`); remaining characters may include those as well as a hyphen or colon (matches regex `[a-zA-Z0-9_-:]`). The length of the ID must not be less than 5 or greater than 50. If you don't specify an ID, a unique one is generated.\n   */\n  objectId?: string | null;\n};\n\n/**\n * A location of a single table cell within a table.\n */\nexport interface SlidesTableCellLocation {\n  /**\n   * The 0-based column index.\n   */\n  columnIndex?: number | null;\n  /**\n   * The 0-based row index.\n   */\n  rowIndex?: number | null;\n}\n\n/**\n * Inserts text into a shape or a table cell.\n */\nexport type SlidesInsertTextRequest = {\n  /**\n   * The optional table cell location if the text is to be inserted into a table cell. If present, the object_id must refer to a table.\n   */\n  cellLocation?: SlidesTableCellLocation;\n  /**\n   * The index where the text will be inserted, in Unicode code units, based on TextElement indexes. The index is zero-based and is computed from the start of the string. The index may be adjusted to prevent insertions inside Unicode grapheme clusters. In these cases, the text will be inserted immediately after the grapheme cluster.\n   */\n  insertionIndex?: number | null;\n  /**\n   * The object ID of the shape or table where the text will be inserted.\n   */\n  objectId?: string | null;\n  /**\n   * The text to be inserted. Inserting a newline character will implicitly create a new ParagraphMarker at that index. The paragraph style of the new paragraph will be copied from the paragraph at the current insertion index, including lists and bullets. Text styles for inserted text will be determined automatically, generally preserving the styling of neighboring text. In most cases, the text will be added to the TextRun that exists at the insertion index. Some control characters (U+0000-U+0008, U+000C-U+001F) and characters from the Unicode Basic Multilingual Plane Private Use Area (U+E000-U+F8FF) will be stripped out of the inserted text.\n   */\n  text?: string | null;\n};\n\nexport type SlidesCreateParagraphBulletsRequest = {\n  objectId: string | null;\n  textRange?: SlidesTextRange;\n};\n\n/**\n * Creates an image.\n */\nexport interface SlidesCreateImageRequest {\n  /**\n   * The element properties for the image. When the aspect ratio of the provided size does not match the image aspect ratio, the image is scaled and centered with respect to the size in order to maintain the aspect ratio. The provided transform is applied after this operation. The PageElementProperties.size property is optional. If you don't specify the size, the default size of the image is used. The PageElementProperties.transform property is optional. If you don't specify a transform, the image will be placed at the top-left corner of the page.\n   */\n  elementProperties?: SlidesPageElementProperties;\n  /**\n   * A user-supplied object ID. If you specify an ID, it must be unique among all pages and page elements in the presentation. The ID must start with an alphanumeric character or an underscore (matches regex `[a-zA-Z0-9_]`); remaining characters may include those as well as a hyphen or colon (matches regex `[a-zA-Z0-9_-:]`). The length of the ID must not be less than 5 or greater than 50. If you don't specify an ID, a unique one is generated.\n   */\n  objectId?: string | null;\n  /**\n   * The image URL. The image is fetched once at insertion time and a copy is stored for display inside the presentation. Images must be less than 50 MB in size, can't exceed 25 megapixels, and must be in one of PNG, JPEG, or GIF formats. The provided URL must be publicly accessible and up to 2 KB in length. The URL is saved with the image, and exposed through the Image.source_url field.\n   */\n  url?: string | null;\n}\n\n/**\n * Common properties for a page element. Note: When you initially create a PageElement, the API may modify the values of both `size` and `transform`, but the visual size will be unchanged.\n */\nexport interface SlidesPageElementProperties {\n  /**\n   * The object ID of the page where the element is located.\n   */\n  pageObjectId?: string | null;\n  /**\n   * The size of the element.\n   */\n  size?: SlidesSide;\n  /**\n   * The transform for the element.\n   */\n  transform?: SlidesAffineTransform;\n}\n\n/**\n * A width and height.\n */\nexport interface SlidesSide {\n  /**\n   * The height of the object.\n   */\n  height?: SlidesDimension;\n  /**\n   * The width of the object.\n   */\n  width?: SlidesDimension;\n}\n\n/**\n * A magnitude in a single direction in the specified units.\n */\nexport interface SlidesDimension {\n  /**\n   * The magnitude.\n   */\n  magnitude?: number | null;\n  /**\n   * The units for magnitude.\n   */\n  unit?: string | null;\n}\n\n/**\n * AffineTransform uses a 3x3 matrix with an implied last row of [ 0 0 1 ] to transform source coordinates (x,y) into destination coordinates (x', y') according to: x' x = shear_y scale_y translate_y 1 [ 1 ] After transformation, x' = scale_x * x + shear_x * y + translate_x; y' = scale_y * y + shear_y * x + translate_y; This message is therefore composed of these six matrix elements.\n */\nexport interface SlidesAffineTransform {\n  /**\n   * The X coordinate scaling element.\n   */\n  scaleX?: number | null;\n  /**\n   * The Y coordinate scaling element.\n   */\n  scaleY?: number | null;\n  /**\n   * The X coordinate shearing element.\n   */\n  shearX?: number | null;\n  /**\n   * The Y coordinate shearing element.\n   */\n  shearY?: number | null;\n  /**\n   * The X coordinate translation element.\n   */\n  translateX?: number | null;\n  /**\n   * The Y coordinate translation element.\n   */\n  translateY?: number | null;\n  /**\n   * The units for translate elements.\n   */\n  unit?: string | null;\n}\n\nexport type SlidesCreateSlideRequest = {\n  insertionIndex?: number;\n  objectId?: string;\n  slideLayoutReference: {\n    layoutId?: string;\n    predefinedLayout?: SlidesPredefinedLayout;\n  };\n  placeholderIdMappings: SlidesLayoutPlaceholderIdMapping[];\n};\n\n/**\n * The predefined layouts of a slide.\n */\nexport type SlidesPredefinedLayout =\n  /*\n   *\tUnspecified layout.\n   */\n  | \"PREDEFINED_LAYOUT_UNSPECIFIED\"\n\n  /*\n   * Blank layout with no placeholders.\n   */\n  | \"BLANK\"\n  /*\n   * Layout with a caption at the bottom.\n   */\n  | \"CAPTION_ONLY\"\n  /*\n   * Layout with a title and a subtitle.\n   */\n  | \"TITLE\"\n  /*\n   * Layout with a title and body.\n   */\n  | \"TITLE_AND_BODY\"\n  /*\n   * Layout with a title and two columns.\n   */\n  | \"TITLE_AND_TWO_COLUMNS\"\n  /*\n   * Layout with only a title\n   */\n  | \"TITLE_ONLY\"\n  /*\n   * Layout with a section title.\n   */\n  | \"SECTION_HEADER\"\n  /*\n   * Layout with a title and subtitle on one side and description on the other.\n   */\n  | \"SECTION_TITLE_AND_DESCRIPTION\"\n  /*\n   * Layout with one title and one body, arranged in a single column.\n   */\n  | \"ONE_COLUMN_TEXT\"\n  /*\n   * Layout with a main point.\n   */\n  | \"MAIN_POINT\"\n  /*\n   * Layout with a big number.\n   */\n  | \"BIG_NUMBER\";\n\n/**\n * Update the styling of text in a Shape or Table.\n */\nexport interface SlidesUpdateTextStyleRequest {\n  /**\n   * The location of the cell in the table containing the text to style. If `object_id` refers to a table, `cell_location` must have a value. Otherwise, it must not.\n   */\n  cellLocation?: SlidesTableCellLocation;\n  /**\n   * The fields that should be updated. At least one field must be specified. The root `style` is implied and should not be specified. A single `\"*\"` can be used as short-hand for listing every field. For example, to update the text style to bold, set `fields` to `\"bold\"`. To reset a property to its default value, include its field name in the field mask but leave the field itself unset.\n   */\n  fields?: string | null;\n  /**\n   * The object ID of the shape or table with the text to be styled.\n   */\n  objectId?: string | null;\n  /**\n   * The style(s) to set on the text. If the value for a particular style matches that of the parent, that style will be set to inherit. Certain text style changes may cause other changes meant to mirror the behavior of the Slides editor. See the documentation of TextStyle for more information.\n   */\n  style?: SlidesTextStyle;\n  /**\n   * The range of text to style. The range may be extended to include adjacent newlines. If the range fully contains a paragraph belonging to a list, the paragraph's bullet is also updated with the matching text style.\n   */\n  textRange?: SlidesRange;\n}\n\n/**\n * Represents the styling that can be applied to a TextRun. If this text is contained in a shape with a parent placeholder, then these text styles may be inherited from the parent. Which text styles are inherited depend on the nesting level of lists: * A text run in a paragraph that is not in a list will inherit its text style from the the newline character in the paragraph at the 0 nesting level of the list inside the parent placeholder. * A text run in a paragraph that is in a list will inherit its text style from the newline character in the paragraph at its corresponding nesting level of the list inside the parent placeholder. Inherited text styles are represented as unset fields in this message. If text is contained in a shape without a parent placeholder, unsetting these fields will revert the style to a value matching the defaults in the Slides editor.\n */\nexport interface SlidesTextStyle {\n  /**\n   * The background color of the text. If set, the color is either opaque or transparent, depending on if the `opaque_color` field in it is set.\n   */\n  backgroundColor?: SlidesOptionalColor;\n  /**\n   * The text's vertical offset from its normal position. Text with `SUPERSCRIPT` or `SUBSCRIPT` baseline offsets is automatically rendered in a smaller font size, computed based on the `font_size` field. The `font_size` itself is not affected by changes in this field.\n   */\n  baselineOffset?: string | null;\n  /**\n   * Whether or not the text is rendered as bold.\n   */\n  bold?: boolean | null;\n  /**\n   * The font family of the text. The font family can be any font from the Font menu in Slides or from [Google Fonts] (https://fonts.google.com/). If the font name is unrecognized, the text is rendered in `Arial`. Some fonts can affect the weight of the text. If an update request specifies values for both `font_family` and `bold`, the explicitly-set `bold` value is used.\n   */\n  fontFamily?: string | null;\n  /**\n   * The size of the text's font. When read, the `font_size` will specified in points.\n   */\n  fontSize?: SlidesDimension;\n  /**\n   * The color of the text itself. If set, the color is either opaque or transparent, depending on if the `opaque_color` field in it is set.\n   */\n  foregroundColor?: SlidesOptionalColor;\n  /**\n   * Whether or not the text is italicized.\n   */\n  italic?: boolean | null;\n  /**\n   * The hyperlink destination of the text. If unset, there is no link. Links are not inherited from parent text. Changing the link in an update request causes some other changes to the text style of the range: * When setting a link, the text foreground color will be set to ThemeColorType.HYPERLINK and the text will be underlined. If these fields are modified in the same request, those values will be used instead of the link defaults. * Setting a link on a text range that overlaps with an existing link will also update the existing link to point to the new URL. * Links are not settable on newline characters. As a result, setting a link on a text range that crosses a paragraph boundary, such as `\"ABC\\n123\"`, will separate the newline character(s) into their own text runs. The link will be applied separately to the runs before and after the newline. * Removing a link will update the text style of the range to match the style of the preceding text (or the default text styles if the preceding text is another link) unless different styles are being set in the same request.\n   */\n  link?: SlidesLink;\n  /**\n   * Whether or not the text is in small capital letters.\n   */\n  smallCaps?: boolean | null;\n  /**\n   * Whether or not the text is struck through.\n   */\n  strikethrough?: boolean | null;\n  /**\n   * Whether or not the text is underlined.\n   */\n  underline?: boolean | null;\n  /**\n   * The font family and rendered weight of the text. This field is an extension of `font_family` meant to support explicit font weights without breaking backwards compatibility. As such, when reading the style of a range of text, the value of `weighted_font_family#font_family` will always be equal to that of `font_family`. However, when writing, if both fields are included in the field mask (either explicitly or through the wildcard `\"*\"`), their values are reconciled as follows: * If `font_family` is set and `weighted_font_family` is not, the value of `font_family` is applied with weight `400` (\"normal\"). * If both fields are set, the value of `font_family` must match that of `weighted_font_family#font_family`. If so, the font family and weight of `weighted_font_family` is applied. Otherwise, a 400 bad request error is returned. * If `weighted_font_family` is set and `font_family` is not, the font family and weight of `weighted_font_family` is applied. * If neither field is set, the font family and weight of the text inherit from the parent. Note that these properties cannot inherit separately from each other. If an update request specifies values for both `weighted_font_family` and `bold`, the `weighted_font_family` is applied first, then `bold`. If `weighted_font_family#weight` is not set, it defaults to `400`. If `weighted_font_family` is set, then `weighted_font_family#font_family` must also be set with a non-empty value. Otherwise, a 400 bad request error is returned.\n   */\n  weightedFontFamily?: SlidesWeightedFontFamily;\n}\n\n/**\n * Represents a font family and weight used to style a TextRun.\n */\nexport interface SlidesWeightedFontFamily {\n  /**\n   * The font family of the text. The font family can be any font from the Font menu in Slides or from [Google Fonts] (https://fonts.google.com/). If the font name is unrecognized, the text is rendered in `Arial`.\n   */\n  fontFamily?: string | null;\n  /**\n   * The rendered weight of the text. This field can have any value that is a multiple of `100` between `100` and `900`, inclusive. This range corresponds to the numerical values described in the CSS 2.1 Specification, [section 15.6](https://www.w3.org/TR/CSS21/fonts.html#font-boldness), with non-numerical values disallowed. Weights greater than or equal to `700` are considered bold, and weights less than `700`are not bold. The default value is `400` (\"normal\").\n   */\n  weight?: number | null;\n}\n\n/**\n * A hypertext link.\n */\nexport interface SlidesLink {\n  /**\n   * If set, indicates this is a link to the specific page in this presentation with this ID. A page with this ID may not exist.\n   */\n  pageObjectId?: string | null;\n  /**\n   * If set, indicates this is a link to a slide in this presentation, addressed by its position.\n   */\n  relativeLink?: string | null;\n  /**\n   * If set, indicates this is a link to the slide at this zero-based index in the presentation. There may not be a slide at this index.\n   */\n  slideIndex?: number | null;\n  /**\n   * If set, indicates this is a link to the external web page at this URL.\n   */\n  url?: string | null;\n}\n/**\n * A color that can either be fully opaque or fully transparent.\n */\nexport interface SlidesOptionalColor {\n  /**\n   * If set, this will be used as an opaque color. If unset, this represents a transparent color.\n   */\n  opaqueColor?: SlidesOpaqueColor;\n}\n/**\n * The outline of a PageElement. If these fields are unset, they may be inherited from a parent placeholder if it exists. If there is no parent, the fields will default to the value used for new page elements created in the Slides editor, which may depend on the page element kind.\n */\nexport interface Schema$Outline {\n  /**\n   * The dash style of the outline.\n   */\n  dashStyle?: string | null;\n  /**\n   * The fill of the outline.\n   */\n  outlineFill?: SlidesOutlineFill;\n  /**\n   * The outline property state. Updating the outline on a page element will implicitly update this field to `RENDERED`, unless another value is specified in the same request. To have no outline on a page element, set this field to `NOT_RENDERED`. In this case, any other outline fields set in the same request will be ignored.\n   */\n  propertyState?: string | null;\n  /**\n   * The thickness of the outline.\n   */\n  weight?: SlidesDimension;\n}\n\n/**\n * The fill of the outline.\n */\nexport interface SlidesOutlineFill {\n  /**\n   * Solid color fill.\n   */\n  solidFill?: SlidesSolidFill;\n}\n\n/**\n * A solid color fill. The page or page element is filled entirely with the specified color value. If any field is unset, its value may be inherited from a parent placeholder if it exists.\n */\nexport interface SlidesSolidFill {\n  /**\n   * The fraction of this `color` that should be applied to the pixel. That is, the final pixel color is defined by the equation: pixel color = alpha * (color) + (1.0 - alpha) * (background color) This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a completely transparent color.\n   */\n  alpha?: number | null;\n  /**\n   * The color value of the solid fill.\n   */\n  color?: SlidesOpaqueColor;\n}\n\n/**\n * A themeable solid color value.\n */\nexport interface SlidesOpaqueColor {\n  /**\n   * An opaque RGB color.\n   */\n  rgbColor?: SlidesRgbColor;\n  /**\n   * An opaque theme color.\n   */\n  themeColor?: string | null;\n}\n\n/**\n * An RGB color.\n */\nexport interface SlidesRgbColor {\n  /**\n   * The blue component of the color, from 0.0 to 1.0.\n   */\n  blue?: number | null;\n  /**\n   * The green component of the color, from 0.0 to 1.0.\n   */\n  green?: number | null;\n  /**\n   * The red component of the color, from 0.0 to 1.0.\n   */\n  red?: number | null;\n}\n/**\n * Specifies a contiguous range of an indexed collection, such as characters in text.\n */\nexport interface SlidesRange {\n  /**\n   * The optional zero-based index of the end of the collection. Required for `FIXED_RANGE` ranges.\n   */\n  endIndex?: number | null;\n  /**\n   * The optional zero-based index of the beginning of the collection. Required for `FIXED_RANGE` and `FROM_START_INDEX` ranges.\n   */\n  startIndex?: number | null;\n  /**\n   * The type of range.\n   */\n  type?: string | null;\n}\n\nexport type SlidesRequest =\n  | { deleteObject: SlidesDeleteObjectRequest }\n  | { createSlide: SlidesCreateSlideRequest }\n  | { insertText: SlidesInsertTextRequest }\n  | { createParagraphBullets: SlidesCreateParagraphBulletsRequest }\n  | { createImage: SlidesCreateImageRequest }\n  | { updateTextStyle: SlidesUpdateTextStyleRequest };\n\nimport fetch, { type FetchInputs } from \"@fetch\";\nimport secrets from \"@secrets\";\n\nconst connectionId = \"connection:google-drive-limited\";\n\nexport type Metadata = {\n  title?: string;\n  description?: string;\n};\n\nexport type Method = \"GET\" | \"POST\" | \"PUT\" | \"DELETE\";\n\nexport type Result<T> =\n  | {\n      success: true;\n      info: T;\n    }\n  | {\n      success: false;\n      error: string;\n    };\n\nexport {\n  connect,\n  get,\n  create,\n  del,\n  query,\n  createMultipart,\n  getDoc,\n  updateDoc,\n  unwrap,\n  createPresentation,\n  getPresentation,\n  updatePresentation,\n  createPermission,\n};\n\nasync function get(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply file id.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"GET\"\n  );\n}\n\nasync function create(\n  token: string,\n  body: unknown,\n  metadata: Metadata\n): Promise<Result<CreateFileResponse>> {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the file to create.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    \"https://www.googleapis.com/drive/v3/files\",\n    \"POST\",\n    body\n  );\n}\n\nasync function query(\n  token: string,\n  query: string,\n  metadata: Metadata\n): Promise<Result<FileQueryResponse>> {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!query) {\n    return error(\"Please supply the query.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`,\n    \"GET\"\n  );\n}\n\nasync function del(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the file to delete\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"DELETE\"\n  );\n}\n\nasync function getDoc(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the doc id to get.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}`,\n    \"GET\"\n  );\n}\n\nasync function updateDoc(\n  token: string,\n  id: string,\n  body: unknown,\n  metadata: Metadata\n) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the doc to update.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the doc update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function getPresentation(\n  token: string,\n  id: string,\n  metadata: Metadata\n): Promise<Result<SlidesPresentation>> {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://slides.googleapis.com/v1/presentations/${id}`,\n    \"GET\"\n  );\n}\n\nasync function createPresentation(\n  token: string,\n  title: string,\n  metadata: Metadata\n): Promise<Result<{ presentationId: string }>> {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  return api(\n    metadata,\n    token,\n    \"https://slides.googleapis.com/v1/presentations\",\n    \"POST\",\n    { title }\n  );\n}\n\nasync function updatePresentation(\n  token: string,\n  id: string,\n  body: { requests: SlidesRequest[] },\n  metadata: Metadata\n) {\n  if (!token) {\n    return error(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return error(\"Please supply the id of the presentation to update.\");\n  }\n  if (!body) {\n    return error(\"Please supply the body of the presentation update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://slides.googleapis.com/v1/presentations/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function connect(metadata: Metadata) {\n  const { [connectionId]: token } = await secrets({\n    ...meta(metadata),\n    keys: [connectionId],\n  });\n  return token;\n}\n\nasync function createMultipart(\n  token: string,\n  metadata: unknown,\n  body: unknown,\n  mimeType: string,\n  $metadata: Metadata\n): Promise<Result<{ id: string }>> {\n  const boundary = \"BB-BB-BB-BB-BB-BB\";\n  const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n  const request: FetchInputs = {\n    ...meta($metadata),\n    url,\n    method: \"POST\",\n    headers: {\n      Authorization: `Bearer ${token}`,\n      [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n    },\n    body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\nContent-Transfer-Encoding: base64\n\n${body}\n--${boundary}--`,\n  };\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error as string };\n  }\n  return { success: true, info: response as { id: string } };\n}\n\nexport type Permission = {\n  id?: string;\n  displayName?: string;\n  type?: string;\n  kind?: string;\n  permissionDetails?: [\n    {\n      permissionType?: string;\n      inheritedFrom?: string;\n      role?: string;\n      inherited?: boolean;\n    },\n  ];\n  photoLink?: string;\n  emailAddress?: string;\n  role?: string;\n  allowFileDiscovery?: boolean;\n  domain?: string;\n  expirationTime?: string;\n  teamDrivePermissionDetails?: [\n    {\n      teamDrivePermissionType: string;\n      inheritedFrom: string;\n      role: string;\n      inherited: boolean;\n    },\n  ];\n  deleted?: boolean;\n  view?: string;\n  pendingOwner?: boolean;\n};\n\nasync function createPermission(\n  token: string,\n  fileId: string,\n  permission: Permission,\n  metadata: Metadata\n): Promise<Result<Permission>> {\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${fileId}/permissions`,\n    \"POST\",\n    permission\n  );\n}\n\nasync function api<T>(\n  metadata: Metadata,\n  token: string,\n  url: string,\n  method: Method,\n  body: unknown | null = null\n): Promise<Result<T>> {\n  const request: FetchInputs = {\n    ...meta(metadata),\n    url,\n    method,\n    headers: {\n      Authorization: `Bearer ${token}`,\n    },\n  };\n  if (body) {\n    request.body = body;\n  }\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return { success: false, error: $error as string };\n  }\n  return { success: true, info: response as T };\n}\n\nfunction unwrap<T>(result: Result<T>, message = \"Error\") {\n  if (\"error\" in result) {\n    throw new Error(`${message}:\\n${JSON.stringify(result.error)}`);\n  }\n  return result.info;\n}\n\nfunction error<T>(message: string): Result<T> {\n  return {\n    success: false,\n    error: message,\n  };\n}\n\nfunction meta({ title, description }: Metadata = {}) {\n  if (!(title || description)) return {};\n  const $metadata: Metadata = {};\n  if (title) {\n    $metadata.title = title;\n  }\n  if (description) {\n    $metadata.description = description;\n  }\n  return { $metadata };\n}\n",
              "language": "typescript"
            },
            "description": ""
          }
        },
        "slides": {
          "code": "/**\n * @fileoverview Slides bits.\n */\nimport { unescape } from \"./unescape\";\nimport { marked } from \"./marked\";\nexport { SlideBuilder, slidesToRequests };\nclass SlideBuilder {\n    #slides = [];\n    #images = [];\n    #startIndex;\n    #objectToDelete;\n    #depthAdjustment = 0;\n    constructor(startIndex = 0, objectId) {\n        this.#startIndex = startIndex;\n        this.#objectToDelete = objectId;\n        this.#newSlide();\n    }\n    addMarkdown(markdown) {\n        let bodyText = this.#getBodyText();\n        if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n            this.#newSlide();\n        }\n        const tokens = marked.lexer(markdown);\n        tokens.forEach((token) => this.#addToken(token));\n    }\n    #hasContent() { }\n    addInlineData(data) {\n        let bodyText = this.#getBodyText();\n        if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n            this.#newSlide();\n            bodyText = this.#getBodyText();\n        }\n        bodyText.images ??= [];\n        bodyText.images.push(this.#addImage({\n            type: \"image\",\n            href: `data:${data.mimeType};base64,${data.data}`,\n        }));\n    }\n    #addToken(token) {\n        const { type } = token;\n        switch (type) {\n            case \"hr\":\n                this.#newSlide();\n                break;\n            case \"paragraph\":\n                this.#newParagraph(token.tokens);\n                break;\n            case \"heading\":\n                this.#newHeading(token);\n                break;\n            case \"list\":\n                this.#addListToBody(token);\n                break;\n        }\n    }\n    images() {\n        return this.#images;\n    }\n    build(imageUrls) {\n        this.#finalizeSlide();\n        console.log(\"SLIDES\", this.#slides);\n        const requests = slidesToRequests(this.#slides, imageUrls);\n        if (this.#objectToDelete) {\n            requests.unshift({\n                deleteObject: {\n                    objectId: this.#objectToDelete,\n                },\n            });\n        }\n        return requests;\n    }\n    get #slide() {\n        return this.#slides.at(-1);\n    }\n    #newHeading(token) {\n        if (token.depth === 1) {\n            this.#slide.title = this.#parseText(token.tokens);\n        }\n        else {\n            this.#slide.subtitle = this.#parseText(token.tokens);\n        }\n    }\n    #newParagraph(tokens) {\n        const bodyText = this.#getBodyText();\n        const offset = bodyText.text.length - this.#depthAdjustment;\n        const { text, styles, lists, images = [], } = this.#parseText(tokens, offset);\n        bodyText.text += text;\n        bodyText.styles.push(...styles);\n        bodyText.lists.push(...lists);\n        bodyText.images ??= [];\n        bodyText.images.push(...images);\n    }\n    #getBodyText() {\n        const slide = this.#slide;\n        if (!slide.body.length) {\n            slide.body.push({\n                text: { text: \"\", styles: [], lists: [] },\n            });\n        }\n        const body = slide.body.at(-1);\n        if (!body.text) {\n            body.text = { text: \"\", styles: [], lists: [] };\n        }\n        return body.text;\n    }\n    #addListToBody(token) {\n        const slide = this.#slide;\n        const { ordered, items } = token;\n        let bulletedText = \"\";\n        const bodyText = this.#getBodyText();\n        let listOffset = bodyText.text.length;\n        let length = 0;\n        let localOffset = listOffset;\n        const addListItems = (depth, items) => {\n            items.forEach((item) => {\n                const [textToken, listToken] = item.tokens;\n                const { text, styles } = this.#parseText(textToken.tokens, localOffset);\n                bodyText.text += `${\"\\t\".repeat(depth)}${text}`;\n                this.#depthAdjustment += depth;\n                localOffset += text.length;\n                length += text.length;\n                bodyText.styles.push(...styles);\n                if (listToken) {\n                    addListItems(depth + 1, listToken.items);\n                }\n            });\n        };\n        addListItems(0, items);\n        bodyText.lists.push({ start: listOffset, end: listOffset + length });\n    }\n    #parseText(tokens, current = 0) {\n        let text = \"\";\n        const styles = [];\n        const images = [];\n        tokens.forEach((token) => {\n            if (token.type === \"image\") {\n                images.push(this.#addImage(token));\n                return;\n            }\n            const { type, text: t } = token;\n            const length = t.length;\n            text += unescape(t);\n            const range = { start: current, end: current + length };\n            switch (type) {\n                case \"strong\":\n                    styles.push({ range, bold: true });\n                    break;\n                case \"em\":\n                    styles.push({ range, italic: true });\n                    break;\n                case \"del\":\n                    styles.push({ range, strikethrough: true });\n                    break;\n                case \"link\":\n                    styles.push({ range, link: token.href });\n                    break;\n            }\n            current += length;\n        });\n        return { text: `${text}\\n`, styles, lists: [], images };\n    }\n    #finalizeSlide() {\n        const slide = this.#slide;\n        if (!slide)\n            return;\n        const hasText = !!slide.body?.at(0)?.text?.text;\n        const hasImages = !!slide.body?.at(0)?.text?.images?.length;\n        if (slide.subtitle && !hasText) {\n            slide.layout = \"TITLE\";\n        }\n        else if (hasText) {\n            slide.layout = \"TITLE_AND_BODY\";\n            delete slide.subtitle;\n        }\n        else if (!hasImages) {\n            slide.layout = \"MAIN_POINT\";\n            slide.body = [];\n        }\n        this.#depthAdjustment = 0;\n    }\n    #newSlide() {\n        this.#finalizeSlide();\n        this.#slides.push({\n            objectId: `Slide-${this.#startIndex + this.#slides.length}`,\n            layout: \"BLANK\",\n            body: [],\n        });\n    }\n    #addImage(token) {\n        const id = this.#images.length;\n        this.#images.push(token);\n        return id;\n    }\n}\nfunction slidesToRequests(slides, imageUrls) {\n    const requests = [];\n    slides.forEach((slide) => {\n        const request = {\n            objectId: slide.objectId,\n            slideLayoutReference: { predefinedLayout: slide.layout },\n            placeholderIdMappings: mapPlaceholders(slide.objectId, slide.layout),\n        };\n        requests.push({ createSlide: request });\n        if (slide.title) {\n            requests.push({\n                insertText: {\n                    text: slide.title.text,\n                    objectId: `${slide.objectId}-title`,\n                },\n            });\n        }\n        if (slide.subtitle) {\n            requests.push({\n                insertText: {\n                    text: slide.subtitle.text,\n                    objectId: `${slide.objectId}-subtitle`,\n                },\n            });\n        }\n        slide.body.forEach((body) => {\n            const bodyText = body.text;\n            if (!bodyText)\n                return;\n            if (bodyText.images?.length) {\n                requests.push({\n                    createImage: {\n                        url: imageUrls[bodyText.images[0]],\n                        elementProperties: {\n                            pageObjectId: slide.objectId,\n                        },\n                    },\n                });\n            }\n            else if (bodyText.text) {\n                const objectId = `${slide.objectId}-body`;\n                requests.push({\n                    insertText: { text: bodyText.text, objectId },\n                });\n                bodyText.lists.forEach((list) => {\n                    requests.push({\n                        createParagraphBullets: {\n                            objectId,\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: list.start,\n                                endIndex: list.end,\n                            },\n                        },\n                    });\n                });\n                bodyText.styles.forEach((style) => {\n                    requests.push({\n                        updateTextStyle: {\n                            objectId,\n                            ...getTextStyle(style),\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: style.range.start,\n                                endIndex: style.range.end,\n                            },\n                        },\n                    });\n                });\n            }\n        });\n    });\n    return requests;\n}\nfunction getTextStyle(style) {\n    const { link: url, range: _, ...rest } = style;\n    const linkStyle = url ? { link: { url } } : {};\n    const fields = Object.keys(rest);\n    if (url)\n        fields.push(\"link\");\n    return { style: { ...linkStyle, ...rest }, fields: fields.join(\",\") };\n}\nfunction mapPlaceholders(slideId, layout) {\n    const mappings = [];\n    switch (layout) {\n        case \"TITLE\":\n            mappings.push({\n                layoutPlaceholder: { type: \"CENTERED_TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"SUBTITLE\", index: 0 },\n                objectId: `${slideId}-subtitle`,\n            });\n            break;\n        case \"TITLE_AND_BODY\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"BODY\", index: 0 },\n                objectId: `${slideId}-body`,\n            });\n            break;\n        case \"MAIN_POINT\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            break;\n    }\n    return mappings;\n}\n",
          "metadata": {
            "runnable": false,
            "source": {
              "code": "/**\n * @fileoverview Slides bits.\n */\n\nimport type {\n  SlidesRequest,\n  SlidesPredefinedLayout,\n  SlidesCreateSlideRequest,\n  SlidesInsertTextRequest,\n  SlidesUpdateTextStyleRequest,\n  SlidesLayoutPlaceholderIdMapping,\n  SlidesTextStyle,\n} from \"./api\";\nimport { unescape } from \"./unescape\";\nimport { marked } from \"./marked\";\nimport type { InlineDataCapabilityPart } from \"./types\";\n\nexport { SlideBuilder, slidesToRequests };\n\nexport type Token =\n  | ParagraphToken\n  | HeadingToken\n  | ListToken\n  | ListItemToken\n  | HrToken;\n\nexport type FormattingToken =\n  | ImageToken\n  | TextToken\n  | LinkToken\n  | EmToken\n  | StrongToken\n  | DelToken;\n\nexport type ImageToken = {\n  type: \"image\";\n  href: string;\n  title?: string;\n};\n\nexport type TextToken = {\n  type: \"text\";\n  text: string;\n  tokens: FormattingToken[];\n};\n\nexport type LinkToken = {\n  type: \"link\";\n  href: string;\n  text: string;\n};\n\nexport type EmToken = {\n  type: \"em\";\n  text: string;\n};\n\nexport type DelToken = {\n  type: \"del\";\n  text: string;\n};\n\nexport type StrongToken = {\n  type: \"strong\";\n  text: string;\n};\n\nexport type HeadingToken = {\n  type: \"heading\";\n  depth: number;\n  text: string;\n  tokens: FormattingToken[];\n};\n\nexport type HrToken = {\n  type: \"hr\";\n  text: string;\n};\n\nexport type ParagraphToken = {\n  type: \"paragraph\";\n  text: string;\n  tokens: FormattingToken[];\n};\n\nexport type ListToken = {\n  type: \"list\";\n  ordered: boolean;\n  items: ListItemToken[];\n};\n\nexport type ListItemToken = {\n  type: \"list_item\";\n  text: string;\n  tokens: [TextToken, ListToken?];\n};\n\n// Slide Structure:\n// - Slide contains optional title, bodies, and text\n// - Text is string with styles and lists\n// - Style is various style flags + range\n// - Body is text and or images\n\nexport type Slide = {\n  objectId: string;\n  layout: SlidesPredefinedLayout;\n  title?: SlideText;\n  subtitle?: SlideText;\n  body: SlideBody[];\n};\n\nexport type SlideText = {\n  text: string;\n  styles: SlideStyle[];\n  lists: SlideRange[];\n  images?: number[];\n};\n\nexport type SlideRange = {\n  start: number;\n  end: number;\n};\n\nexport type SlideStyle = {\n  range: SlideRange;\n  bold?: boolean;\n  italic?: boolean;\n  link?: string;\n  underline?: boolean;\n  strikethrough?: boolean;\n};\n\nexport type SlideBody = {\n  text?: SlideText;\n};\n\nclass SlideBuilder {\n  #slides: Slide[] = [];\n  #images: ImageToken[] = [];\n\n  readonly #startIndex: number;\n  readonly #objectToDelete: string | undefined;\n  #depthAdjustment: number = 0;\n\n  constructor(startIndex: number = 0, objectId?: string) {\n    this.#startIndex = startIndex;\n    this.#objectToDelete = objectId;\n    this.#newSlide();\n  }\n\n  addMarkdown(markdown: string) {\n    let bodyText = this.#getBodyText();\n    if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n      this.#newSlide();\n    }\n    const tokens = marked.lexer(markdown) as Token[];\n    tokens.forEach((token) => this.#addToken(token));\n  }\n\n  #hasContent() {}\n\n  addInlineData(data: InlineDataCapabilityPart[\"inlineData\"]) {\n    let bodyText = this.#getBodyText();\n    if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n      this.#newSlide();\n      bodyText = this.#getBodyText();\n    }\n    bodyText.images ??= [];\n    bodyText.images.push(\n      this.#addImage({\n        type: \"image\",\n        href: `data:${data.mimeType};base64,${data.data}`,\n      })\n    );\n  }\n\n  #addToken(token: Token) {\n    const { type } = token;\n    switch (type) {\n      case \"hr\":\n        this.#newSlide();\n        break;\n      case \"paragraph\":\n        this.#newParagraph(token.tokens);\n        break;\n      case \"heading\":\n        this.#newHeading(token);\n        break;\n      case \"list\":\n        this.#addListToBody(token);\n        break;\n    }\n  }\n\n  images() {\n    return this.#images;\n  }\n\n  build(imageUrls: string[]) {\n    this.#finalizeSlide();\n    console.log(\"SLIDES\", this.#slides);\n    const requests = slidesToRequests(this.#slides, imageUrls);\n    if (this.#objectToDelete) {\n      requests.unshift({\n        deleteObject: {\n          objectId: this.#objectToDelete,\n        },\n      });\n    }\n    return requests;\n  }\n\n  get #slide(): Slide {\n    return this.#slides.at(-1)!;\n  }\n\n  #newHeading(token: HeadingToken) {\n    if (token.depth === 1) {\n      this.#slide.title = this.#parseText(token.tokens);\n    } else {\n      this.#slide.subtitle = this.#parseText(token.tokens);\n    }\n  }\n\n  #newParagraph(tokens: FormattingToken[]) {\n    const bodyText = this.#getBodyText();\n    const offset = bodyText.text.length - this.#depthAdjustment;\n    const {\n      text,\n      styles,\n      lists,\n      images = [],\n    } = this.#parseText(tokens, offset);\n    bodyText.text += text;\n    bodyText.styles.push(...styles);\n    bodyText.lists.push(...lists);\n    bodyText.images ??= [];\n    bodyText.images.push(...images);\n  }\n\n  #getBodyText() {\n    const slide = this.#slide;\n    if (!slide.body.length) {\n      slide.body.push({\n        text: { text: \"\", styles: [], lists: [] },\n      });\n    }\n    const body = slide.body.at(-1)!;\n    if (!body.text) {\n      body.text = { text: \"\", styles: [], lists: [] };\n    }\n    return body.text;\n  }\n\n  #addListToBody(token: ListToken) {\n    const slide = this.#slide;\n    const { ordered, items } = token;\n    let bulletedText = \"\";\n    const bodyText = this.#getBodyText();\n    let listOffset = bodyText.text.length;\n    let length = 0;\n    let localOffset = listOffset;\n    const addListItems = (depth: number, items: ListItemToken[]) => {\n      items.forEach((item) => {\n        const [textToken, listToken] = item.tokens;\n        const { text, styles } = this.#parseText(textToken.tokens, localOffset);\n        bodyText.text += `${\"\\t\".repeat(depth)}${text}`;\n        this.#depthAdjustment += depth;\n        localOffset += text.length;\n        length += text.length;\n        bodyText.styles.push(...styles);\n        if (listToken) {\n          addListItems(depth + 1, listToken.items);\n        }\n      });\n    };\n    addListItems(0, items);\n    bodyText.lists.push({ start: listOffset, end: listOffset + length });\n  }\n\n  #parseText(tokens: FormattingToken[], current = 0): SlideText {\n    let text = \"\";\n    const styles: SlideStyle[] = [];\n    const images: number[] = [];\n    tokens.forEach((token) => {\n      if (token.type === \"image\") {\n        images.push(this.#addImage(token));\n        return;\n      }\n      const { type, text: t } = token;\n      const length = t.length;\n      text += unescape(t);\n      const range = { start: current, end: current + length };\n      switch (type) {\n        case \"strong\":\n          styles.push({ range, bold: true });\n          break;\n        case \"em\":\n          styles.push({ range, italic: true });\n          break;\n        case \"del\":\n          styles.push({ range, strikethrough: true });\n          break;\n        case \"link\":\n          styles.push({ range, link: token.href });\n          break;\n      }\n      current += length;\n    });\n    return { text: `${text}\\n`, styles, lists: [], images };\n  }\n\n  #finalizeSlide() {\n    const slide = this.#slide;\n    if (!slide) return;\n    const hasText = !!slide.body?.at(0)?.text?.text;\n    const hasImages = !!slide.body?.at(0)?.text?.images?.length;\n    if (slide.subtitle && !hasText) {\n      slide.layout = \"TITLE\";\n    } else if (hasText) {\n      slide.layout = \"TITLE_AND_BODY\";\n      delete slide.subtitle;\n    } else if (!hasImages) {\n      slide.layout = \"MAIN_POINT\";\n      slide.body = [];\n    }\n    this.#depthAdjustment = 0;\n  }\n\n  #newSlide() {\n    this.#finalizeSlide();\n    this.#slides.push({\n      objectId: `Slide-${this.#startIndex + this.#slides.length}`,\n      layout: \"BLANK\",\n      body: [],\n    });\n  }\n\n  #addImage(token: ImageToken) {\n    const id = this.#images.length;\n    this.#images.push(token);\n    return id;\n  }\n}\n\nfunction slidesToRequests(\n  slides: Slide[],\n  imageUrls: string[]\n): SlidesRequest[] {\n  const requests: SlidesRequest[] = [];\n  slides.forEach((slide) => {\n    const request: SlidesCreateSlideRequest = {\n      objectId: slide.objectId,\n      slideLayoutReference: { predefinedLayout: slide.layout },\n      placeholderIdMappings: mapPlaceholders(slide.objectId, slide.layout),\n    };\n    requests.push({ createSlide: request });\n    if (slide.title) {\n      requests.push({\n        insertText: {\n          text: slide.title.text,\n          objectId: `${slide.objectId}-title`,\n        },\n      });\n    }\n    if (slide.subtitle) {\n      requests.push({\n        insertText: {\n          text: slide.subtitle.text,\n          objectId: `${slide.objectId}-subtitle`,\n        },\n      });\n    }\n    slide.body.forEach((body) => {\n      const bodyText = body.text;\n      if (!bodyText) return;\n      if (bodyText.images?.length) {\n        requests.push({\n          createImage: {\n            url: imageUrls[bodyText.images[0]],\n            elementProperties: {\n              pageObjectId: slide.objectId,\n            },\n          },\n        });\n      } else if (bodyText.text) {\n        const objectId = `${slide.objectId}-body`;\n        requests.push({\n          insertText: { text: bodyText.text, objectId },\n        });\n        bodyText.lists.forEach((list) => {\n          requests.push({\n            createParagraphBullets: {\n              objectId,\n              textRange: {\n                type: \"FIXED_RANGE\",\n                startIndex: list.start,\n                endIndex: list.end,\n              },\n            },\n          });\n        });\n        bodyText.styles.forEach((style) => {\n          requests.push({\n            updateTextStyle: {\n              objectId,\n              ...getTextStyle(style),\n              textRange: {\n                type: \"FIXED_RANGE\",\n                startIndex: style.range.start,\n                endIndex: style.range.end,\n              },\n            },\n          });\n        });\n      }\n    });\n  });\n  return requests;\n}\n\nfunction getTextStyle(style: SlideStyle): {\n  style: SlidesTextStyle;\n  fields: string;\n} {\n  const { link: url, range: _, ...rest } = style;\n  const linkStyle = url ? { link: { url } } : {};\n  const fields = Object.keys(rest);\n  if (url) fields.push(\"link\");\n\n  return { style: { ...linkStyle, ...rest }, fields: fields.join(\",\") };\n}\n\nfunction mapPlaceholders(slideId: string, layout: SlidesPredefinedLayout) {\n  const mappings: SlidesLayoutPlaceholderIdMapping[] = [];\n  switch (layout) {\n    case \"TITLE\":\n      mappings.push({\n        layoutPlaceholder: { type: \"CENTERED_TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      mappings.push({\n        layoutPlaceholder: { type: \"SUBTITLE\", index: 0 },\n        objectId: `${slideId}-subtitle`,\n      });\n      break;\n    case \"TITLE_AND_BODY\":\n      mappings.push({\n        layoutPlaceholder: { type: \"TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      mappings.push({\n        layoutPlaceholder: { type: \"BODY\", index: 0 },\n        objectId: `${slideId}-body`,\n      });\n      break;\n    case \"MAIN_POINT\":\n      mappings.push({\n        layoutPlaceholder: { type: \"TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      break;\n  }\n  return mappings;\n}\n",
              "language": "typescript"
            },
            "description": "Slides bits."
          }
        },
        "unescape": {
          "code": "export { unescape };\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\nconst namedEntities = {\n    colon: \":\",\n    quot: '\"',\n    amp: \"&\",\n    lt: \"<\",\n    gt: \">\",\n    apos: \"'\",\n    // add more as needed\n};\nfunction unescape(html) {\n    return html.replace(unescapeTest, (_, n) => {\n        n = n.toLowerCase();\n        if (n in namedEntities)\n            return namedEntities[n];\n        if (n.charAt(0) === \"#\") {\n            const code = n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n            return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n        }\n        return \"\";\n    });\n}\n",
          "metadata": {
            "runnable": false,
            "source": {
              "code": "export { unescape };\n\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\n\nconst namedEntities: Record<string, string> = {\n  colon: \":\",\n  quot: '\"',\n  amp: \"&\",\n  lt: \"<\",\n  gt: \">\",\n  apos: \"'\",\n  // add more as needed\n};\n\nfunction unescape(html: string) {\n  return html.replace(unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n in namedEntities) return namedEntities[n];\n\n    if (n.charAt(0) === \"#\") {\n      const code =\n        n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n\n      return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n    }\n    return \"\";\n  });\n}\n",
              "language": "typescript"
            },
            "description": ""
          }
        },
        "tests": {
          "code": "import { marked } from \"./marked\";\nimport { SlideBuilder } from \"./slides\";\nimport { connect, unwrap, getPresentation, updatePresentation, } from \"./api\";\nconst simpleMarkdown = `\n\n---\n\n---\n\n# This page has bullets\n\nThis page has bullets\n\n- Bullet 1\n  - Sub bullet\n  - sub bull*et*\n  - Sub bullet ~~ag~~ain\n    - Sub-sub-bullet\n    - Check **me** out\n- Bullet **2**\n\nAND MORE **STUFF** MORE STUFF\n\n---\n\n# Heading 2\n\n**B**o~~d~~y of the _slide_\nMore **body**\n**B**o~~d~~y of the _slide_\n**B**o~~d~~y of the _slide_\n**B**o~~d~~y of the _slide_\n\nLots of ~~stuff~~ goes here\n\n---\n\n# This is a title slide\n\n---\n\n# Hello!\n\nDo you have the:\n\n* Skills\n* Fire in your belly?\n\n`;\nasync function test() {\n    const tokens = marked.lexer(simpleMarkdown);\n    const slideBuilder = new SlideBuilder(0);\n    tokens.forEach((token) => slideBuilder.addToken(token));\n    const requests = slideBuilder.build();\n    const token = await connect({ title: \"Get API Token\" });\n    const presentationId = \"1KUEfmB2p6mIWKBR05KPbilUMgRx13BcWDoqpP4DUcww\";\n    const presentation = unwrap(await getPresentation(token, presentationId, { title: \"Get Presentatoin\" }), \"Unable to get presentation\");\n    const toDelete = presentation.slides?.map((slide) => ({\n        deleteObject: { objectId: slide.objectId },\n    })) || [];\n    const deleteAll = unwrap(await updatePresentation(token, presentationId, { requests: toDelete }, { title: \"Delete existing slides\" }), \"Failed to delete existing sildes\");\n    const update = unwrap(await updatePresentation(token, presentationId, { requests }, { title: \"Update Presentation\" }), \"Failed to update presentation\");\n    return { tokens, requests };\n}\n",
          "metadata": {
            "runnable": true,
            "source": {
              "code": "import { marked } from \"./marked\";\nimport { SlideBuilder } from \"./slides\";\nimport {\n  connect,\n  unwrap,\n  getPresentation,\n  updatePresentation,\n  type SlidesRequest,\n} from \"./api\";\n\nconst simpleMarkdown = `\n\n---\n\n---\n\n# This page has bullets\n\nThis page has bullets\n\n- Bullet 1\n  - Sub bullet\n  - sub bull*et*\n  - Sub bullet ~~ag~~ain\n    - Sub-sub-bullet\n    - Check **me** out\n- Bullet **2**\n\nAND MORE **STUFF** MORE STUFF\n\n---\n\n# Heading 2\n\n**B**o~~d~~y of the _slide_\nMore **body**\n**B**o~~d~~y of the _slide_\n**B**o~~d~~y of the _slide_\n**B**o~~d~~y of the _slide_\n\nLots of ~~stuff~~ goes here\n\n---\n\n# This is a title slide\n\n---\n\n# Hello!\n\nDo you have the:\n\n* Skills\n* Fire in your belly?\n\n`;\n\nasync function test() {\n  const tokens = marked.lexer(simpleMarkdown);\n  const slideBuilder = new SlideBuilder(0);\n  tokens.forEach((token) => slideBuilder.addToken(token));\n  const requests = slideBuilder.build();\n  const token = await connect({ title: \"Get API Token\" });\n  const presentationId = \"1KUEfmB2p6mIWKBR05KPbilUMgRx13BcWDoqpP4DUcww\";\n\n  const presentation = unwrap(\n    await getPresentation(token, presentationId, { title: \"Get Presentatoin\" }),\n    \"Unable to get presentation\"\n  );\n\n  const toDelete =\n    (presentation.slides?.map((slide) => ({\n      deleteObject: { objectId: slide.objectId },\n    })) as SlidesRequest[]) || [];\n  const deleteAll = unwrap(\n    await updatePresentation(\n      token,\n      presentationId,\n      { requests: toDelete },\n      { title: \"Delete existing slides\" }\n    ),\n    \"Failed to delete existing sildes\"\n  );\n\n  const update = unwrap(\n    await updatePresentation(\n      token,\n      presentationId,\n      { requests },\n      { title: \"Update Presentation\" }\n    ),\n    \"Failed to update presentation\"\n  );\n\n  return { tokens, requests };\n}\n",
              "language": "typescript"
            },
            "description": ""
          }
        },
        "images": {
          "code": "import { unwrap, create, createMultipart, createPermission, del } from \"./api\";\nexport { ImageUploader };\nclass ImageUploader {\n    #token;\n    #tempId = null;\n    constructor(token) {\n        this.#token = token;\n    }\n    async upload(images) {\n        if (!images.length)\n            return [];\n        const { id } = unwrap(await create(this.#token, {\n            name: \"temp\",\n            mimeType: \"application/vnd.google-apps.folder\",\n        }, { title: \"Create temp folder\" }), \"Failed to create the temp folder\");\n        this.#tempId = id;\n        const uploadedIds = await Promise.all(images.map(async (image, i) => {\n            const { mimeType, body } = this.#splitDataUrl(image.href);\n            const file = unwrap(await createMultipart(this.#token, {\n                parents: [id],\n                mimeType,\n            }, body, mimeType, { title: `Upload image ${image.title || `${i + 1}`}` }), `Failed to upload image ${image.title || `${i + 1}`}`);\n            return file.id;\n        }));\n        const pub = { role: \"reader\", type: \"anyone\" };\n        const meta = { title: \"Make image public\" };\n        return await Promise.all(uploadedIds.map(async (id, i) => {\n            const url = `https://drive.google.com/uc?id=${id}&export=download`;\n            unwrap(await createPermission(this.#token, id, pub, meta));\n            return url;\n        }));\n    }\n    async cleanup() {\n        if (!this.#tempId)\n            return;\n        unwrap(await del(this.#token, this.#tempId, { title: \"Delete temp folder\" }), \"Failed to delete temp folder\");\n    }\n    #splitDataUrl(url) {\n        const [mimeType, base64] = url.slice(5).split(\";\");\n        const body = base64.slice(7);\n        return { mimeType, body };\n    }\n}\n",
          "metadata": {
            "runnable": false,
            "source": {
              "code": "import { unwrap, create, createMultipart, createPermission, del } from \"./api\";\n\nexport type ImageInfo = {\n  href: string;\n  title?: string;\n};\n\nexport { ImageUploader };\n\nclass ImageUploader {\n  #token: string;\n  #tempId: string | null = null;\n\n  constructor(token: string) {\n    this.#token = token;\n  }\n\n  async upload(images: ImageInfo[]) {\n    if (!images.length) return [];\n    const { id } = unwrap(\n      await create(\n        this.#token,\n        {\n          name: \"temp\",\n          mimeType: \"application/vnd.google-apps.folder\",\n        },\n        { title: \"Create temp folder\" }\n      ),\n      \"Failed to create the temp folder\"\n    );\n    this.#tempId = id;\n    const uploadedIds = await Promise.all(\n      images.map(async (image, i) => {\n        const { mimeType, body } = this.#splitDataUrl(image.href);\n        const file = unwrap(\n          await createMultipart(\n            this.#token,\n            {\n              parents: [id],\n              mimeType,\n            },\n            body,\n            mimeType,\n            { title: `Upload image ${image.title || `${i + 1}`}` }\n          ),\n          `Failed to upload image ${image.title || `${i + 1}`}`\n        );\n        return file.id;\n      })\n    );\n\n    const pub = { role: \"reader\", type: \"anyone\" };\n    const meta = { title: \"Make image public\" };\n\n    return await Promise.all(\n      uploadedIds.map(async (id, i) => {\n        const url = `https://drive.google.com/uc?id=${id}&export=download`;\n        unwrap(await createPermission(this.#token, id, pub, meta));\n        return url;\n      })\n    );\n  }\n\n  async cleanup() {\n    if (!this.#tempId) return;\n\n    unwrap(\n      await del(this.#token, this.#tempId, { title: \"Delete temp folder\" }),\n      \"Failed to delete temp folder\"\n    );\n  }\n\n  #splitDataUrl(url: string) {\n    const [mimeType, base64] = url.slice(5).split(\";\");\n    const body = base64.slice(7);\n    return { mimeType, body };\n  }\n}\n",
              "language": "typescript"
            },
            "description": ""
          }
        }
      },
      "nodes": [
        {
          "id": "input",
          "type": "input",
          "metadata": {
            "title": "Input"
          }
        },
        {
          "id": "run-module",
          "type": "runModule",
          "configuration": {
            "$module": "main"
          },
          "metadata": {
            "title": "Run \"Context to Slides v3\" module"
          }
        },
        {
          "id": "output",
          "type": "output",
          "metadata": {
            "title": "Output"
          }
        }
      ],
      "edges": [
        {
          "from": "input",
          "to": "run-module",
          "out": "*",
          "in": ""
        },
        {
          "from": "run-module",
          "to": "output",
          "out": "*",
          "in": ""
        }
      ],
      "metadata": {
        "tags": [
          "published",
          "component"
        ],
        "icon": "google-drive"
      }
    }
  },
  "nodes": [],
  "edges": []
}