{
  "title": "A2 Go Over a List",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {
      "presentation": {
        "themes": {
          "5f3ca599-8fee-46fb-951f-0d47b16a6d56": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "5f3ca599-8fee-46fb-951f-0d47b16a6d56"
      }
    },
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Break an objective into tasks and then execute them.\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./a2/gemini\";\nimport {} from \"./a2/common\";\nimport { ok, err, toLLMContent, llm, generateId } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ArgumentNameGenerator } from \"./a2/introducer\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {} from \"./types\";\nimport { fanOutContext } from \"./a2/lists\";\nexport { invoke as default, describe };\nconst STRATEGISTS = [\n    new ParallelStrategist(),\n    new SequentialStrategist(),\n    new ThinkStrategist(),\n];\nfunction findStrategist(name) {\n    return STRATEGISTS.find((strategist) => strategist.name === name);\n}\nasync function invoke({ context, plan: objective, strategy, \"z-list\": makeList, ...params }) {\n    const toolManager = new ToolManager(new ArgumentNameGenerator());\n    const template = new Template(objective);\n    const substituting = await template.substitute(params, async ({ path: url }) => toolManager.addTool(url));\n    if (!ok(substituting))\n        return substituting;\n    const strategist = findStrategist(strategy);\n    if (!strategist) {\n        return err(`Unknown strategy: \"${strategy}\"`);\n    }\n    const result = await fanOutContext(substituting, context, async (objective, context) => {\n        const executor = new Runtime(context, toolManager, makeList);\n        const executingOne = await executor.executeStrategy(objective, strategist);\n        if (!ok(executingOne))\n            return executingOne;\n        if (makeList) {\n            return {\n                role: \"model\",\n                parts: [\n                    {\n                        id: generateId(),\n                        list: executingOne.map((item) => {\n                            return { content: [item] };\n                        }),\n                    },\n                ],\n            };\n        }\n        const oneContent = {\n            role: \"model\",\n            parts: executingOne.flatMap((item) => {\n                return item.parts;\n            }),\n        };\n        return oneContent;\n    });\n    if (!ok(result))\n        return result;\n    return { context: result };\n}\nasync function describe({ inputs: { plan } }) {\n    const template = new Template(plan);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                plan: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Objective\",\n                    description: \"Describe what will be turned into a list and then gone over\",\n                },\n                strategy: {\n                    title: \"Strategy\",\n                    description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n                    type: \"string\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    enum: STRATEGISTS.map((strategist) => strategist.name),\n                    icon: \"joiner\",\n                    default: STRATEGISTS[0].name,\n                },\n                \"z-list\": {\n                    type: \"boolean\",\n                    title: \"Make a list\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    icon: \"summarize\",\n                    description: \"When checked, this step will try to create a list as its output. Make sure that the prompt asks for a list of some sort\",\n                },\n                ...template.schemas(),\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Results\",\n                },\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n            additionalProperties: false,\n        },\n        title: \"Plan and Execute\",\n        description: \"Break an objective into tasks and then execute them\",\n        metadata: {\n            icon: \"laps\",\n            tags: [\"quick-access\", \"generative\", \"experimental\"],\n            order: 102,\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Break an objective into tasks and then execute them.\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, type Tool } from \"./a2/gemini\";\nimport { type Params } from \"./a2/common\";\nimport { ok, err, toLLMContent, llm, generateId } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ArgumentNameGenerator } from \"./a2/introducer\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {\n  type Task,\n  type Plan,\n  type Strategy,\n  type ExecuteStepFunction,\n  type Strategist,\n} from \"./types\";\nimport { fanOutContext } from \"./a2/lists\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n  plan: LLMContent;\n  strategy: string;\n  \"z-list\": boolean;\n} & Params;\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nconst STRATEGISTS: Strategist[] = [\n  new ParallelStrategist(),\n  new SequentialStrategist(),\n  new ThinkStrategist(),\n];\n\nfunction findStrategist(name: string): Strategist | undefined {\n  return STRATEGISTS.find((strategist) => strategist.name === name);\n}\n\nasync function invoke({\n  context,\n  plan: objective,\n  strategy,\n  \"z-list\": makeList,\n  ...params\n}: Inputs): Promise<Outcome<Outputs>> {\n  const toolManager = new ToolManager(new ArgumentNameGenerator());\n  const template = new Template(objective);\n  const substituting = await template.substitute(\n    params,\n    async ({ path: url }) => toolManager.addTool(url)\n  );\n  if (!ok(substituting)) return substituting;\n\n  const strategist = findStrategist(strategy);\n  if (!strategist) {\n    return err(`Unknown strategy: \"${strategy}\"`);\n  }\n\n  const result = await fanOutContext(\n    substituting,\n    context,\n    async (objective, context) => {\n      const executor = new Runtime(context, toolManager, makeList);\n      const executingOne = await executor.executeStrategy(\n        objective,\n        strategist\n      );\n      if (!ok(executingOne)) return executingOne;\n\n      if (makeList) {\n        return {\n          role: \"model\",\n          parts: [\n            {\n              id: generateId(),\n              list: executingOne.map((item) => {\n                return { content: [item] };\n              }),\n            },\n          ],\n        };\n      }\n\n      const oneContent = {\n        role: \"model\",\n        parts: executingOne.flatMap((item) => {\n          return item.parts;\n        }),\n      };\n\n      return oneContent;\n    }\n  );\n  if (!ok(result)) return result;\n  return { context: result };\n}\n\ntype DescribeInputs = {\n  inputs: {\n    plan: LLMContent;\n  };\n};\n\nasync function describe({ inputs: { plan } }: DescribeInputs) {\n  const template = new Template(plan);\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n          behavior: [\"main-port\"],\n        },\n        plan: {\n          type: \"object\",\n          behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n          title: \"Objective\",\n          description:\n            \"Describe what will be turned into a list and then gone over\",\n        },\n        strategy: {\n          title: \"Strategy\",\n          description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n          type: \"string\",\n          behavior: [\"config\", \"hint-preview\"],\n          enum: STRATEGISTS.map((strategist) => strategist.name),\n          icon: \"joiner\",\n          default: STRATEGISTS[0].name,\n        },\n        \"z-list\": {\n          type: \"boolean\",\n          title: \"Make a list\",\n          behavior: [\"config\", \"hint-preview\"],\n          icon: \"summarize\",\n          description:\n            \"When checked, this step will try to create a list as its output. Make sure that the prompt asks for a list of some sort\",\n        },\n        ...template.schemas(),\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Results\",\n        },\n      },\n      behavior: [\"at-wireable\"],\n      ...template.requireds(),\n      additionalProperties: false,\n    } satisfies Schema,\n    title: \"Plan and Execute\",\n    description: \"Break an objective into tasks and then execute them\",\n    metadata: {\n      icon: \"laps\",\n      tags: [\"quick-access\", \"generative\", \"experimental\"],\n      order: 102,\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Break an objective into tasks and then execute them.",
        "runnable": true
      }
    },
    "planner-prompt": {
      "code": "/**\n * @fileoverview Contains the planner prompt.\n */\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport {} from \"./types\";\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\nfunction preamble(extraPlannerPrompt) {\n    return `You are a planner. \nYou are to create a precise plan -- a list of tasks -- for a given objective. This plan will be executed by others.\n\n${extraPlannerPrompt}\n\nYour responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\n}\nfunction planSchema(organize) {\n    const organizeFlag = (organize\n        ? {\n            summarizeResults: {\n                type: \"boolean\",\n                description: \"Set to true if and only if the objective calls for summarizing results at the end. Set to false otherwise.\",\n            },\n        }\n        : {});\n    const required = [\"thinking\", \"todo\"];\n    if (organize) {\n        required.push(...Object.keys(organizeFlag));\n    }\n    return {\n        type: \"object\",\n        properties: {\n            thinking: {\n                type: \"string\",\n                description: \"Brief reasoning on why these steps are the right steps to fulfill the objective.\",\n            },\n            todo: {\n                type: \"array\",\n                items: {\n                    type: \"object\",\n                    properties: {\n                        task: {\n                            type: \"string\",\n                            description: \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n                        },\n                        label: {\n                            description: \"Short, precise label for that describes the task.\",\n                            type: \"string\",\n                        },\n                    },\n                    required: [\"task\", \"label\"],\n                },\n            },\n            ...organizeFlag,\n        },\n        required,\n    };\n}\nfunction getPlan(content) {\n    const planPart = content.parts.at(0);\n    if (!planPart || !(\"json\" in planPart)) {\n        // TODO: Error recovery.\n        return err(`Gemini generated invalid plan`);\n    }\n    console.log(\"PLAN\", planPart.json);\n    return planPart.json;\n}\nfunction prependInstruction(text, plan) {\n    return {\n        ...plan,\n        parts: [...plan.parts, { text }],\n    };\n}\nfunction thinkingPlannerPrompt(context, objective, plan, steps, extraPlannerPrompt) {\n    const instruction = llm `\n${preamble(extraPlannerPrompt)}\n\nYour objective is:\n\n\\`\\`\\`\n\n${objective}\n\n\\`\\`\\`\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n    const contents = [...context, instruction];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(true),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\nfunction plannerPrompt(context, objective, extraPlannerPrompt, organize) {\n    context ??= [];\n    const instruction = `${preamble(extraPlannerPrompt)}`;\n    const contents = [...context, prependInstruction(instruction, objective)];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(organize),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\n",
      "metadata": {
        "title": "planner-prompt",
        "source": {
          "code": "/**\n * @fileoverview Contains the planner prompt.\n */\n\nimport { type GeminiSchema, defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport { type Plan } from \"./types\";\n\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\n\nfunction preamble(extraPlannerPrompt: string) {\n  return `You are a planner. \nYou are to create a precise plan -- a list of tasks -- for a given objective. This plan will be executed by others.\n\n${extraPlannerPrompt}\n\nYour responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\n}\n\nfunction planSchema(organize?: boolean): GeminiSchema {\n  const organizeFlag = (\n    organize\n      ? {\n          summarizeResults: {\n            type: \"boolean\",\n            description:\n              \"Set to true if and only if the objective calls for summarizing results at the end. Set to false otherwise.\",\n          },\n        }\n      : {}\n  ) as Record<string, GeminiSchema>;\n  const required = [\"thinking\", \"todo\"];\n  if (organize) {\n    required.push(...Object.keys(organizeFlag));\n  }\n  return {\n    type: \"object\",\n    properties: {\n      thinking: {\n        type: \"string\",\n        description:\n          \"Brief reasoning on why these steps are the right steps to fulfill the objective.\",\n      },\n      todo: {\n        type: \"array\",\n        items: {\n          type: \"object\",\n          properties: {\n            task: {\n              type: \"string\",\n              description:\n                \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n            },\n            label: {\n              description: \"Short, precise label for that describes the task.\",\n              type: \"string\",\n            },\n          },\n          required: [\"task\", \"label\"],\n        },\n      },\n      ...organizeFlag,\n    },\n    required,\n  };\n}\n\nfunction getPlan(content: LLMContent): Outcome<Plan> {\n  const planPart = content.parts.at(0);\n  if (!planPart || !(\"json\" in planPart)) {\n    // TODO: Error recovery.\n    return err(`Gemini generated invalid plan`);\n  }\n  console.log(\"PLAN\", planPart.json);\n  return planPart.json as Plan;\n}\n\nfunction prependInstruction(text: string, plan: LLMContent): LLMContent {\n  return {\n    ...plan,\n    parts: [...plan.parts, { text }],\n  };\n}\n\nfunction thinkingPlannerPrompt(\n  context: LLMContent[],\n  objective: LLMContent,\n  plan: Plan,\n  steps: string[],\n  extraPlannerPrompt: string\n): GeminiPrompt {\n  const instruction = llm`\n${preamble(extraPlannerPrompt)}\n\nYour objective is:\n\n\\`\\`\\`\n\n${objective}\n\n\\`\\`\\`\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n\n  const contents = [...context, instruction];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(true),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n\nfunction plannerPrompt(\n  context: LLMContent[] | undefined,\n  objective: LLMContent,\n  extraPlannerPrompt: string,\n  organize: boolean\n): GeminiPrompt {\n  context ??= [];\n  const instruction = `${preamble(extraPlannerPrompt)}`;\n\n  const contents = [...context, prependInstruction(instruction, objective)];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(organize),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n",
          "language": "typescript"
        },
        "description": "Contains the planner prompt.",
        "runnable": false
      }
    },
    "types": {
      "code": "/**\n * @fileoverview Common types.\n */\n",
      "metadata": {
        "title": "types",
        "source": {
          "code": "/**\n * @fileoverview Common types.\n */\n\nexport type Task = {\n  label: string;\n  task: string;\n};\n\nexport type Plan = {\n  thinking?: string;\n  todo: Task[];\n  summarizeResults: boolean;\n};\n\nexport type Strategy = \"Parallel\" | \"Sequence\";\n\nexport type ExecuteStepFunction = (\n  item: Task\n) => Promise<LLMContent | undefined>;\n\nexport type Strategist = {\n  name: string;\n  execute(\n    singleStepExecutor: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent,\n    makeList?: boolean\n  ): Promise<Outcome<LLMContent[]>>;\n};\n\nexport type Invokable<T> = {\n  invoke(): T;\n};\n",
          "language": "typescript"
        },
        "description": "Common types.",
        "runnable": false
      }
    },
    "runtime": {
      "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./types\";\nexport { Runtime, generateId };\nfunction generateId() {\n    return Math.random().toString(36).substring(2, 5);\n}\nclass Runtime {\n    toolManager;\n    makeList;\n    context;\n    errors = [];\n    execute;\n    constructor(context, toolManager, makeList) {\n        this.toolManager = toolManager;\n        this.makeList = makeList;\n        this.context = context ? [...context] : [];\n        this.execute = this.#execute.bind(this);\n    }\n    async executeStrategy(objective, strategist) {\n        return strategist.execute(this.execute, this.context, objective, this.makeList);\n    }\n    async #execute(item) {\n        const { toolManager, context, errors } = this;\n        let structuredResponse;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        let toolConfig = {};\n        if (!toolManager.hasTools()) {\n            structuredResponse = new StructuredResponse(generateId(), false);\n            contents = structuredResponse.addPrompt(context, prompt);\n        }\n        else {\n            toolConfig = {\n                toolConfig: {\n                    functionCallingConfig: {\n                        mode: \"ANY\",\n                    },\n                },\n            };\n            contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt({\n            body: {\n                contents,\n                tools: toolManager.list(),\n                ...toolConfig,\n            },\n            systemInstruction: structuredResponse?.instruction(),\n        }, {\n            toolManager,\n            allowToolErrors: true,\n            validator: (content) => {\n                return structuredResponse?.parseContent(content);\n            },\n        }).invoke();\n        if (!ok(executing)) {\n            errors.push(executing.$error);\n            return;\n        }\n        return structuredResponse\n            ? toLLMContent(structuredResponse.body, \"model\")\n            : executing.last;\n    }\n}\n",
      "metadata": {
        "title": "runtime",
        "source": {
          "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\n\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {\n  type ExecuteStepFunction,\n  type Plan,\n  type Task,\n  type Strategist,\n} from \"./types\";\n\nexport { Runtime, generateId };\n\nfunction generateId() {\n  return Math.random().toString(36).substring(2, 5);\n}\n\nclass Runtime {\n  readonly context: LLMContent[];\n  readonly errors: string[] = [];\n  readonly execute: ExecuteStepFunction;\n\n  constructor(\n    context: LLMContent[] | undefined,\n    public readonly toolManager: ToolManager,\n    public readonly makeList: boolean\n  ) {\n    this.context = context ? [...context] : [];\n    this.execute = this.#execute.bind(this);\n  }\n\n  async executeStrategy(\n    objective: LLMContent,\n    strategist: Strategist\n  ): Promise<Outcome<LLMContent[]>> {\n    return strategist.execute(\n      this.execute,\n      this.context,\n      objective,\n      this.makeList\n    );\n  }\n\n  async #execute(item: Task): Promise<LLMContent | undefined> {\n    const { toolManager, context, errors } = this;\n    let structuredResponse: StructuredResponse | undefined;\n    const prompt = toLLMContent(item.task);\n    let contents;\n    let toolConfig = {};\n    if (!toolManager.hasTools()) {\n      structuredResponse = new StructuredResponse(generateId(), false);\n      contents = structuredResponse.addPrompt(context, prompt);\n    } else {\n      toolConfig = {\n        toolConfig: {\n          functionCallingConfig: {\n            mode: \"ANY\",\n          },\n        },\n      };\n      contents = [...context, toLLMContent(item.task)];\n    }\n    const executing = await new GeminiPrompt(\n      {\n        body: {\n          contents,\n          tools: toolManager.list(),\n          ...toolConfig,\n        },\n        systemInstruction: structuredResponse?.instruction(),\n      },\n      {\n        toolManager,\n        allowToolErrors: true,\n        validator: (content) => {\n          return structuredResponse?.parseContent(content);\n        },\n      }\n    ).invoke();\n    if (!ok(executing)) {\n      errors.push(executing.$error);\n      return;\n    }\n    return structuredResponse\n      ? toLLMContent(structuredResponse.body, \"model\")\n      : executing.last;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "The runtime that powers going over the list.",
        "runnable": false
      }
    },
    "parallel-strategist": {
      "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\nimport { report } from \"./a2/output\";\nimport { ok } from \"./a2/utils\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport {} from \"./types\";\nexport { ParallelStrategist };\nclass ParallelStrategist {\n    name = \"All at once\";\n    extraPlannerPrompt = `\nAll tasks in the plan will be executed in any order or all at once, so make sure that the tasks don't depend on each other.\nThink carefully: for every task in the list, does any task depend on another task? If so, rethink your list\nuntil all tasks are indepedent`;\n    async execute(execute, mutableContext, objective) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt, false).invoke();\n        if (!ok(planning))\n            return planning;\n        const plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        await report({\n            actor: \"Planner\",\n            category: `Creating a plan`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all items at the same time.`,\n        });\n        return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n    }\n}\n",
      "metadata": {
        "title": "parallel-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\n\nimport { report } from \"./a2/output\";\nimport { ok } from \"./a2/utils\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\n\nexport { ParallelStrategist };\n\nclass ParallelStrategist implements Strategist {\n  readonly name = \"All at once\";\n  readonly extraPlannerPrompt = `\nAll tasks in the plan will be executed in any order or all at once, so make sure that the tasks don't depend on each other.\nThink carefully: for every task in the list, does any task depend on another task? If so, rethink your list\nuntil all tasks are indepedent`;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt,\n      false\n    ).invoke();\n    if (!ok(planning)) return planning;\n    const plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    await report({\n      actor: \"Planner\",\n      category: `Creating a plan`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all items at the same time.`,\n    });\n    return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes a parallel strategy.",
        "runnable": false
      }
    },
    "sequential-strategist": {
      "code": "/**\n * @fileoverview Executes sequential strategy.\n */\nimport {} from \"./types\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { toLLMContent, ok } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nexport { SequentialStrategist };\nclass SequentialStrategist {\n    name = \"Go in order\";\n    extraPlannerPrompt = `\nAll tasks in the plan will be executed in sequence, building on each other.`;\n    async execute(execute, mutableContext, objective) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt, false).invoke();\n        if (!ok(planning))\n            return planning;\n        const plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n        });\n        const results = [];\n        for (const task of plan.todo) {\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Item\",\n                icon: \"laps\",\n                details: `Currently working on:\n  \n  ${task.task}\n  `,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "sequential-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes sequential strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { toLLMContent, ok } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nexport { SequentialStrategist };\n\nclass SequentialStrategist implements Strategist {\n  readonly name = \"Go in order\";\n  readonly extraPlannerPrompt = `\nAll tasks in the plan will be executed in sequence, building on each other.`;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt,\n      false\n    ).invoke();\n    if (!ok(planning)) return planning;\n    const plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n    });\n\n    const results: LLMContent[] = [];\n    for (const task of plan.todo) {\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Item\",\n        icon: \"laps\",\n        details: `Currently working on:\n  \n  ${task.task}\n  `,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes sequential strategy.",
        "runnable": false
      }
    },
    "think-strategist": {
      "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\nimport {} from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { organizerPrompt } from \"./organizer-prompt\";\nimport { plannerPrompt, thinkingPlannerPrompt, getPlan, } from \"./planner-prompt\";\nexport { ThinkStrategist };\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\nclass ThinkStrategist {\n    name = \"Think as I go\";\n    tasks = [];\n    extraPlannerPrompt = `\nIf the objective calls to organize or summarize results at the end, do not add that as a step.\nInstead, set the \"organizeResults\" property to \"true\". This will let the organizing agent know\nto kick off the organizing task after you're done.\n\nWhen the objective does not explicitly contain the request to organize or summarize results,\nmake sure to set the \"organizeProperty\" to \"false\". Do not invent new work.\n\nNow think real hard: do you need to organize or summarize results?\n`;\n    async execute(execute, mutableContext, objective, makeList) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt, true).invoke();\n        if (!ok(planning))\n            return planning;\n        let plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        const results = [];\n        let max = plan.todo.length + OVERRUN_BUFFER;\n        let organizeResults = false;\n        let planDescription = \"Here is my starting plan\";\n        while (--max) {\n            const task = plan.todo.at(0);\n            if (plan.summarizeResults) {\n                organizeResults = true;\n            }\n            if (!task)\n                break;\n            await report({\n                actor: \"Planner\",\n                category: \"Progress update\",\n                name: \"Thinking\",\n                icon: \"laps\",\n                details: `\n\nHere's my thinking:\n\n${plan.thinking}\n        \n${planDescription}:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the plan in order, thinking after each step\nand adjusting the plan if necessary.`,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n            this.tasks.push(task.task);\n            const thinking = await thinkingPlannerPrompt(mutableContext, objective, plan, this.tasks, this.extraPlannerPrompt).invoke();\n            if (!ok(thinking))\n                return thinking;\n            const newPlan = getPlan(thinking.last);\n            if (!ok(newPlan))\n                return newPlan;\n            plan = newPlan;\n            planDescription = \"Here are the remaining steps in the plan\";\n        }\n        if (organizeResults) {\n            await report({\n                actor: \"Planner\",\n                category: \"Organizing work into a report\",\n                name: \"Organizing work report\",\n                icon: \"laps\",\n                details: `I will now organize all of my work into a report.`,\n            });\n            const organizing = await organizerPrompt(results, objective).invoke();\n            if (!ok(organizing))\n                return organizing;\n            return [organizing.last];\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "think-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { organizerPrompt } from \"./organizer-prompt\";\n\nimport {\n  plannerPrompt,\n  thinkingPlannerPrompt,\n  getPlan,\n} from \"./planner-prompt\";\n\nexport { ThinkStrategist };\n\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\n\nclass ThinkStrategist implements Strategist {\n  readonly name = \"Think as I go\";\n  readonly tasks: string[] = [];\n  readonly extraPlannerPrompt = `\nIf the objective calls to organize or summarize results at the end, do not add that as a step.\nInstead, set the \"organizeResults\" property to \"true\". This will let the organizing agent know\nto kick off the organizing task after you're done.\n\nWhen the objective does not explicitly contain the request to organize or summarize results,\nmake sure to set the \"organizeProperty\" to \"false\". Do not invent new work.\n\nNow think real hard: do you need to organize or summarize results?\n`;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent,\n    makeList: boolean\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt,\n      true\n    ).invoke();\n    if (!ok(planning)) return planning;\n    let plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    const results: LLMContent[] = [];\n    let max = plan.todo.length + OVERRUN_BUFFER;\n    let organizeResults = false;\n\n    let planDescription = \"Here is my starting plan\";\n\n    while (--max) {\n      const task = plan.todo.at(0);\n      if (plan.summarizeResults) {\n        organizeResults = true;\n      }\n      if (!task) break;\n      await report({\n        actor: \"Planner\",\n        category: \"Progress update\",\n        name: \"Thinking\",\n        icon: \"laps\",\n        details: `\n\nHere's my thinking:\n\n${plan.thinking}\n        \n${planDescription}:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the plan in order, thinking after each step\nand adjusting the plan if necessary.`,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n      this.tasks.push(task.task);\n      const thinking = await thinkingPlannerPrompt(\n        mutableContext,\n        objective,\n        plan,\n        this.tasks,\n        this.extraPlannerPrompt\n      ).invoke();\n      if (!ok(thinking)) return thinking;\n      const newPlan = getPlan(thinking.last);\n      if (!ok(newPlan)) return newPlan;\n      plan = newPlan;\n      planDescription = \"Here are the remaining steps in the plan\";\n    }\n    if (organizeResults) {\n      await report({\n        actor: \"Planner\",\n        category: \"Organizing work into a report\",\n        name: \"Organizing work report\",\n        icon: \"laps\",\n        details: `I will now organize all of my work into a report.`,\n      });\n\n      const organizing = await organizerPrompt(results, objective).invoke();\n      if (!ok(organizing)) return organizing;\n\n      return [organizing.last];\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes think-as-i strategy.",
        "runnable": false
      }
    },
    "organizer-prompt": {
      "code": "/**\n * @fileoverview Plumbing that handles organizing/summarizing content at the end.\n */\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { llm, ok, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { generateId } from \"./runtime\";\nimport {} from \"./types\";\nexport { organizerPrompt };\nfunction organizerPrompt(results, objective) {\n    const research = {\n        parts: results.flatMap((item) => item.parts),\n    };\n    console.log(\"RESEARCH\", research);\n    const prompt = llm `\nYou are an expert organizer of raw material. This raw material was produced by \nan AI agent that was tasked with satisfying the the provided objective.\n\nYour job is to examine in detail and organize the provided raw material into\na thorough, detailed write-up that captures all of it in one place, so that\nthe final product is a perfect response to the objective.\n\nThe final must product must contain references to the sources (always cite your sources).\n\n## Plan\n\n${objective}\n\n## Raw Research\n\n\\`\\`\\`\n${research}\n\n\\`\\`\\`\n`.asContent();\n    const structuredResponse = new StructuredResponse(generateId(), false);\n    const geminiPrompt = new GeminiPrompt({\n        body: {\n            systemInstruction: structuredResponse.instruction(),\n            contents: structuredResponse.addPrompt([], prompt),\n            safetySettings: defaultSafetySettings(),\n        },\n    }, {\n        validator: (content) => {\n            return structuredResponse.parseContent(content);\n        },\n    });\n    return {\n        invoke: async () => {\n            const invoking = await geminiPrompt.invoke();\n            if (!ok(invoking))\n                return invoking;\n            const response = toLLMContent(structuredResponse.body, \"model\");\n            return {\n                ...invoking,\n                last: response,\n            };\n        },\n    };\n}\n",
      "metadata": {
        "title": "organizer-prompt",
        "source": {
          "code": "/**\n * @fileoverview Plumbing that handles organizing/summarizing content at the end.\n */\n\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { llm, ok, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { generateId } from \"./runtime\";\nimport { type Invokable } from \"./types\";\n\nexport { organizerPrompt };\n\ntype InvokeReturnType = ReturnType<GeminiPrompt[\"invoke\"]>;\n\nfunction organizerPrompt(\n  results: LLMContent[],\n  objective: LLMContent\n): Invokable<InvokeReturnType> {\n  const research = {\n    parts: results.flatMap((item) => item.parts),\n  };\n  console.log(\"RESEARCH\", research);\n  const prompt = llm`\nYou are an expert organizer of raw material. This raw material was produced by \nan AI agent that was tasked with satisfying the the provided objective.\n\nYour job is to examine in detail and organize the provided raw material into\na thorough, detailed write-up that captures all of it in one place, so that\nthe final product is a perfect response to the objective.\n\nThe final must product must contain references to the sources (always cite your sources).\n\n## Plan\n\n${objective}\n\n## Raw Research\n\n\\`\\`\\`\n${research}\n\n\\`\\`\\`\n`.asContent();\n\n  const structuredResponse = new StructuredResponse(generateId(), false);\n\n  const geminiPrompt = new GeminiPrompt(\n    {\n      body: {\n        systemInstruction: structuredResponse.instruction(),\n        contents: structuredResponse.addPrompt([], prompt),\n        safetySettings: defaultSafetySettings(),\n      },\n    },\n    {\n      validator: (content) => {\n        return structuredResponse.parseContent(content);\n      },\n    }\n  );\n\n  return {\n    invoke: async () => {\n      const invoking = await geminiPrompt.invoke();\n      if (!ok(invoking)) return invoking;\n      const response = toLLMContent(structuredResponse.body, \"model\");\n      return {\n        ...invoking,\n        last: response,\n      };\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Plumbing that handles organizing/summarizing content at the end.",
        "runnable": false
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}