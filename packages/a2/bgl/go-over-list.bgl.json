{
  "title": "A2 Go Over a List",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {
      "presentation": {
        "themes": {
          "5f3ca599-8fee-46fb-951f-0d47b16a6d56": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "5f3ca599-8fee-46fb-951f-0d47b16a6d56"
      }
    },
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Break an objective into tasks and then execute them.\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./a2/gemini\";\nimport {} from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ArgumentNameGenerator } from \"./a2/introducer\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {} from \"./types\";\nexport { invoke as default, describe };\nconst STRATEGISTS = [\n    new ParallelStrategist(),\n    new SequentialStrategist(),\n    new ThinkStrategist(),\n];\nfunction findStrategist(name) {\n    return STRATEGISTS.find((strategist) => strategist.name === name);\n}\nasync function invoke({ context, plan: objective, strategy, ...params }) {\n    const toolManager = new ToolManager(new ArgumentNameGenerator());\n    const template = new Template(objective);\n    const substituting = await template.substitute(params, async ({ path: url }) => toolManager.addTool(url));\n    if (!ok(substituting))\n        return substituting;\n    objective = substituting;\n    const strategist = findStrategist(strategy);\n    if (!strategist) {\n        return err(`Unknown strategy: \"${strategy}\"`);\n    }\n    const executor = new Runtime(context, toolManager);\n    const executing = await executor.executeStrategy(objective, strategist);\n    if (!ok(executing))\n        return executing;\n    const oneContent = {\n        role: \"model\",\n        parts: executing.flatMap((item) => {\n            return item.parts;\n        }),\n    };\n    return { context: [oneContent] };\n}\nasync function describe({ inputs: { plan } }) {\n    const template = new Template(plan);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                plan: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Objective\",\n                    description: \"Describe what will be turned into a list and then gone over\",\n                },\n                strategy: {\n                    title: \"Strategy\",\n                    description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n                    type: \"string\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    enum: STRATEGISTS.map((strategist) => strategist.name),\n                    icon: \"joiner\",\n                    default: STRATEGISTS[0].name,\n                },\n                ...template.schemas(),\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Results\",\n                },\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n            additionalProperties: false,\n        },\n        title: \"Plan and Execute\",\n        description: \"Break an objective into tasks and then execute them\",\n        metadata: {\n            icon: \"laps\",\n            tags: [\"quick-access\", \"generative\", \"experimental\"],\n            order: 102,\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Break an objective into tasks and then execute them.\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, type Tool } from \"./a2/gemini\";\nimport { type Params } from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ArgumentNameGenerator } from \"./a2/introducer\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {\n  type Task,\n  type Plan,\n  type Strategy,\n  type ExecuteStepFunction,\n  type Strategist,\n} from \"./types\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n  plan: LLMContent;\n  strategy: string;\n} & Params;\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nconst STRATEGISTS: Strategist[] = [\n  new ParallelStrategist(),\n  new SequentialStrategist(),\n  new ThinkStrategist(),\n];\n\nfunction findStrategist(name: string): Strategist | undefined {\n  return STRATEGISTS.find((strategist) => strategist.name === name);\n}\n\nasync function invoke({\n  context,\n  plan: objective,\n  strategy,\n  ...params\n}: Inputs): Promise<Outcome<Outputs>> {\n  const toolManager = new ToolManager(new ArgumentNameGenerator());\n  const template = new Template(objective);\n  const substituting = await template.substitute(\n    params,\n    async ({ path: url }) => toolManager.addTool(url)\n  );\n  if (!ok(substituting)) return substituting;\n  objective = substituting;\n\n  const strategist = findStrategist(strategy);\n  if (!strategist) {\n    return err(`Unknown strategy: \"${strategy}\"`);\n  }\n  const executor = new Runtime(context, toolManager);\n  const executing = await executor.executeStrategy(objective, strategist);\n  if (!ok(executing)) return executing;\n\n  const oneContent = {\n    role: \"model\",\n    parts: executing.flatMap((item) => {\n      return item.parts;\n    }),\n  };\n  return { context: [oneContent] };\n}\n\ntype DescribeInputs = {\n  inputs: {\n    plan: LLMContent;\n  };\n};\n\nasync function describe({ inputs: { plan } }: DescribeInputs) {\n  const template = new Template(plan);\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n          behavior: [\"main-port\"],\n        },\n        plan: {\n          type: \"object\",\n          behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n          title: \"Objective\",\n          description:\n            \"Describe what will be turned into a list and then gone over\",\n        },\n        strategy: {\n          title: \"Strategy\",\n          description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n          type: \"string\",\n          behavior: [\"config\", \"hint-preview\"],\n          enum: STRATEGISTS.map((strategist) => strategist.name),\n          icon: \"joiner\",\n          default: STRATEGISTS[0].name,\n        },\n        ...template.schemas(),\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Results\",\n        },\n      },\n      behavior: [\"at-wireable\"],\n      ...template.requireds(),\n      additionalProperties: false,\n    } satisfies Schema,\n    title: \"Plan and Execute\",\n    description: \"Break an objective into tasks and then execute them\",\n    metadata: {\n      icon: \"laps\",\n      tags: [\"quick-access\", \"generative\", \"experimental\"],\n      order: 102,\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Break an objective into tasks and then execute them.",
        "runnable": true
      }
    },
    "planner-prompt": {
      "code": "/**\n * @fileoverview Contains the planner prompt.\n */\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport {} from \"./types\";\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\nfunction preamble(extraPlannerPrompt) {\n    return `You are a planner. \nYou are to create a precise plan -- a list of tasks -- for a given objective. This plan will be executed by others.\n\n${extraPlannerPrompt}\n\nYour responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\n}\nfunction planSchema() {\n    return {\n        type: \"object\",\n        properties: {\n            thinking: {\n                type: \"string\",\n                description: \"Brief reasoning on why these steps are the right steps to fulfill the objective\",\n            },\n            todo: {\n                type: \"array\",\n                items: {\n                    type: \"object\",\n                    properties: {\n                        task: {\n                            type: \"string\",\n                            description: \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n                        },\n                        label: {\n                            description: \"Short, precise label for that describes the tasks\",\n                            type: \"string\",\n                        },\n                    },\n                    required: [\"task\", \"label\"],\n                },\n            },\n            keepLastOnly: {\n                description: \"Set to true when the last task's results incorporate all of previous tasks' results. Set to false otherwise\",\n                type: \"boolean\",\n            },\n        },\n        required: [\"thinking\", \"todo\"],\n    };\n}\nfunction getPlan(content) {\n    const planPart = content.parts.at(0);\n    if (!planPart || !(\"json\" in planPart)) {\n        // TODO: Error recovery.\n        return err(`Gemini generated invalid plan`);\n    }\n    return planPart.json;\n}\nfunction prependInstruction(text, plan) {\n    return {\n        ...plan,\n        parts: [...plan.parts, { text }],\n    };\n}\nfunction thinkingPlannerPrompt(context, objective, plan, steps, extraPlannerPrompt) {\n    const instruction = llm `\n${preamble(extraPlannerPrompt)}\n\nYour objective is:\n\n${objective}\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n    const contents = [...context, instruction];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\nfunction plannerPrompt(context, objective, extraPlannerPrompt) {\n    context ??= [];\n    const instruction = `${preamble(extraPlannerPrompt)}`;\n    const contents = [...context, prependInstruction(instruction, objective)];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\n",
      "metadata": {
        "title": "planner-prompt",
        "source": {
          "code": "/**\n * @fileoverview Contains the planner prompt.\n */\n\nimport { type GeminiSchema, defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport { type Plan } from \"./types\";\n\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\n\nfunction preamble(extraPlannerPrompt: string) {\n  return `You are a planner. \nYou are to create a precise plan -- a list of tasks -- for a given objective. This plan will be executed by others.\n\n${extraPlannerPrompt}\n\nYour responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\n}\n\nfunction planSchema(): GeminiSchema {\n  return {\n    type: \"object\",\n    properties: {\n      thinking: {\n        type: \"string\",\n        description:\n          \"Brief reasoning on why these steps are the right steps to fulfill the objective\",\n      },\n      todo: {\n        type: \"array\",\n        items: {\n          type: \"object\",\n          properties: {\n            task: {\n              type: \"string\",\n              description:\n                \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n            },\n            label: {\n              description: \"Short, precise label for that describes the tasks\",\n              type: \"string\",\n            },\n          },\n          required: [\"task\", \"label\"],\n        },\n      },\n      keepLastOnly: {\n        description:\n          \"Set to true when the last task's results incorporate all of previous tasks' results. Set to false otherwise\",\n        type: \"boolean\",\n      },\n    },\n    required: [\"thinking\", \"todo\"],\n  };\n}\n\nfunction getPlan(content: LLMContent): Outcome<Plan> {\n  const planPart = content.parts.at(0);\n  if (!planPart || !(\"json\" in planPart)) {\n    // TODO: Error recovery.\n    return err(`Gemini generated invalid plan`);\n  }\n  return planPart.json as Plan;\n}\n\nfunction prependInstruction(text: string, plan: LLMContent): LLMContent {\n  return {\n    ...plan,\n    parts: [...plan.parts, { text }],\n  };\n}\n\nfunction thinkingPlannerPrompt(\n  context: LLMContent[],\n  objective: LLMContent,\n  plan: Plan,\n  steps: string[],\n  extraPlannerPrompt: string\n): GeminiPrompt {\n  const instruction = llm`\n${preamble(extraPlannerPrompt)}\n\nYour objective is:\n\n${objective}\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n\n  const contents = [...context, instruction];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n\nfunction plannerPrompt(\n  context: LLMContent[] | undefined,\n  objective: LLMContent,\n  extraPlannerPrompt: string\n): GeminiPrompt {\n  context ??= [];\n  const instruction = `${preamble(extraPlannerPrompt)}`;\n\n  const contents = [...context, prependInstruction(instruction, objective)];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n",
          "language": "typescript"
        },
        "description": "Contains the planner prompt.",
        "runnable": false
      }
    },
    "types": {
      "code": "/**\n * @fileoverview Common types.\n */\n",
      "metadata": {
        "title": "types",
        "source": {
          "code": "/**\n * @fileoverview Common types.\n */\n\nexport type Task = {\n  label: string;\n  task: string;\n};\n\nexport type Plan = {\n  thinking?: string;\n  todo: Task[];\n  keepLastOnly: boolean;\n};\n\nexport type Strategy = \"Parallel\" | \"Sequence\";\n\nexport type ExecuteStepFunction = (\n  item: Task\n) => Promise<LLMContent | undefined>;\n\nexport type Strategist = {\n  name: string;\n  extraPlannerPrompt: string;\n  execute(\n    singleStepExecutor: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>>;\n};\n",
          "language": "typescript"
        },
        "description": "Common types.",
        "runnable": false
      }
    },
    "runtime": {
      "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./types\";\nexport { Runtime };\nclass Runtime {\n    toolManager;\n    context;\n    errors = [];\n    execute;\n    constructor(context, toolManager) {\n        this.toolManager = toolManager;\n        this.context = context ? [...context] : [];\n        this.execute = this.#execute.bind(this);\n    }\n    generateId() {\n        return Math.random().toString(36).substring(2, 5);\n    }\n    async executeStrategy(objective, strategist) {\n        return strategist.execute(this.execute, this.context, objective);\n    }\n    async #execute(item) {\n        const { toolManager, context, errors } = this;\n        let structuredResponse;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        let toolConfig = {};\n        if (!toolManager.hasTools()) {\n            structuredResponse = new StructuredResponse(this.generateId(), false);\n            contents = structuredResponse.addPrompt(context, prompt);\n        }\n        else {\n            toolConfig = {\n                toolConfig: {\n                    functionCallingConfig: {\n                        mode: \"ANY\",\n                    },\n                },\n            };\n            contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt({\n            body: {\n                contents,\n                tools: toolManager.list(),\n                ...toolConfig,\n            },\n            systemInstruction: structuredResponse?.instruction(),\n        }, {\n            toolManager,\n            allowToolErrors: true,\n            validator: (content) => {\n                return structuredResponse?.parseContent(content);\n            },\n        }).invoke();\n        if (!ok(executing)) {\n            errors.push(executing.$error);\n            return;\n        }\n        return structuredResponse\n            ? toLLMContent(structuredResponse.body, \"model\")\n            : executing.last;\n    }\n}\n",
      "metadata": {
        "title": "runtime",
        "source": {
          "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\n\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {\n  type ExecuteStepFunction,\n  type Plan,\n  type Task,\n  type Strategist,\n} from \"./types\";\n\nexport { Runtime };\n\nclass Runtime {\n  readonly context: LLMContent[];\n  readonly errors: string[] = [];\n  readonly execute: ExecuteStepFunction;\n\n  constructor(\n    context: LLMContent[] | undefined,\n    public readonly toolManager: ToolManager\n  ) {\n    this.context = context ? [...context] : [];\n    this.execute = this.#execute.bind(this);\n  }\n\n  generateId() {\n    return Math.random().toString(36).substring(2, 5);\n  }\n\n  async executeStrategy(\n    objective: LLMContent,\n    strategist: Strategist\n  ): Promise<Outcome<LLMContent[]>> {\n    return strategist.execute(this.execute, this.context, objective);\n  }\n\n  async #execute(item: Task): Promise<LLMContent | undefined> {\n    const { toolManager, context, errors } = this;\n    let structuredResponse: StructuredResponse | undefined;\n    const prompt = toLLMContent(item.task);\n    let contents;\n    let toolConfig = {};\n    if (!toolManager.hasTools()) {\n      structuredResponse = new StructuredResponse(this.generateId(), false);\n      contents = structuredResponse.addPrompt(context, prompt);\n    } else {\n      toolConfig = {\n        toolConfig: {\n          functionCallingConfig: {\n            mode: \"ANY\",\n          },\n        },\n      };\n      contents = [...context, toLLMContent(item.task)];\n    }\n    const executing = await new GeminiPrompt(\n      {\n        body: {\n          contents,\n          tools: toolManager.list(),\n          ...toolConfig,\n        },\n        systemInstruction: structuredResponse?.instruction(),\n      },\n      {\n        toolManager,\n        allowToolErrors: true,\n        validator: (content) => {\n          return structuredResponse?.parseContent(content);\n        },\n      }\n    ).invoke();\n    if (!ok(executing)) {\n      errors.push(executing.$error);\n      return;\n    }\n    return structuredResponse\n      ? toLLMContent(structuredResponse.body, \"model\")\n      : executing.last;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "The runtime that powers going over the list.",
        "runnable": false
      }
    },
    "parallel-strategist": {
      "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\nimport { report } from \"./a2/output\";\nimport { ok } from \"./a2/utils\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport {} from \"./types\";\nexport { ParallelStrategist };\nclass ParallelStrategist {\n    name = \"All at once\";\n    parallel = true;\n    extraPlannerPrompt = `\nAll tasks in the plan will be executed in any order or all at once, so make sure that the tasks don't depend on each other.\nThink carefully: for every task in the list, does any task depend on another task? If so, rethink your list\nuntil all tasks are indepedent`;\n    async execute(execute, mutableContext, objective) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt).invoke();\n        if (!ok(planning))\n            return planning;\n        const plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        console.log(\"PLAN\", plan);\n        await report({\n            actor: \"Planner\",\n            category: `Creating a plan`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all items at the same time.`,\n        });\n        return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n    }\n}\n",
      "metadata": {
        "title": "parallel-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\n\nimport { report } from \"./a2/output\";\nimport { ok } from \"./a2/utils\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\n\nexport { ParallelStrategist };\n\nclass ParallelStrategist implements Strategist {\n  readonly name = \"All at once\";\n  readonly parallel = true;\n  readonly extraPlannerPrompt = `\nAll tasks in the plan will be executed in any order or all at once, so make sure that the tasks don't depend on each other.\nThink carefully: for every task in the list, does any task depend on another task? If so, rethink your list\nuntil all tasks are indepedent`;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt\n    ).invoke();\n    if (!ok(planning)) return planning;\n    const plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    console.log(\"PLAN\", plan);\n\n    await report({\n      actor: \"Planner\",\n      category: `Creating a plan`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all items at the same time.`,\n    });\n    return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes a parallel strategy.",
        "runnable": false
      }
    },
    "sequential-strategist": {
      "code": "/**\n * @fileoverview Executes sequential strategy.\n */\nimport {} from \"./types\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { toLLMContent, ok } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nexport { SequentialStrategist };\nclass SequentialStrategist {\n    name = \"Go in order\";\n    parallel = false;\n    extraPlannerPrompt = `\nAll tasks in the plan will be executed in sequence, building on each other.`;\n    async execute(execute, mutableContext, objective) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt).invoke();\n        if (!ok(planning))\n            return planning;\n        const plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n        });\n        const results = [];\n        for (const task of plan.todo) {\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Item\",\n                icon: \"laps\",\n                details: `Currently working on:\n  \n  ${task.task}\n  `,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "sequential-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes sequential strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { toLLMContent, ok } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nexport { SequentialStrategist };\n\nclass SequentialStrategist implements Strategist {\n  readonly name = \"Go in order\";\n  readonly parallel = false;\n  readonly extraPlannerPrompt = `\nAll tasks in the plan will be executed in sequence, building on each other.`;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt\n    ).invoke();\n    if (!ok(planning)) return planning;\n    const plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n    });\n\n    const results: LLMContent[] = [];\n    for (const task of plan.todo) {\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Item\",\n        icon: \"laps\",\n        details: `Currently working on:\n  \n  ${task.task}\n  `,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes sequential strategy.",
        "runnable": false
      }
    },
    "think-strategist": {
      "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\nimport {} from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { plannerPrompt, thinkingPlannerPrompt, getPlan, } from \"./planner-prompt\";\nexport { ThinkStrategist };\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\nclass ThinkStrategist {\n    name = \"Think as I go\";\n    tasks = [];\n    extraPlannerPrompt = ``;\n    async execute(execute, mutableContext, objective) {\n        const planning = await plannerPrompt(mutableContext, objective, this.extraPlannerPrompt).invoke();\n        if (!ok(planning))\n            return planning;\n        let plan = getPlan(planning.last);\n        if (!ok(plan))\n            return plan;\n        await report({\n            actor: \"Planner\",\n            category: \"Progress update\",\n            name: \"Thinking\",\n            icon: \"laps\",\n            details: plan.thinking\n                ? plan.thinking\n                : `\nHere's the list I created:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order, thinking after each step\nand adjusting the list if necessary.`,\n        });\n        const results = [];\n        let max = plan.todo.length + OVERRUN_BUFFER;\n        let discardIntermediateWork = false;\n        while (--max) {\n            const task = plan.todo.at(0);\n            if (plan.keepLastOnly) {\n                discardIntermediateWork = true;\n            }\n            if (!task)\n                break;\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Currently working on\",\n                icon: \"laps\",\n                details: task.task,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n            this.tasks.push(task.task);\n            const thinking = await thinkingPlannerPrompt(mutableContext, objective, plan, this.tasks, this.extraPlannerPrompt).invoke();\n            if (!ok(thinking))\n                return thinking;\n            const newPlan = getPlan(thinking.last);\n            if (!ok(newPlan))\n                return newPlan;\n            await report({\n                actor: \"Planner\",\n                category: \"Thinking about the plan\",\n                name: \"Thinking\",\n                icon: \"laps\",\n                details: newPlan.thinking || \"Thinking\",\n            });\n            plan = newPlan;\n        }\n        if (discardIntermediateWork) {\n            const last = results.at(-1);\n            return last ? [last] : [];\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "think-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nimport {\n  plannerPrompt,\n  thinkingPlannerPrompt,\n  getPlan,\n} from \"./planner-prompt\";\n\nexport { ThinkStrategist };\n\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\n\nclass ThinkStrategist implements Strategist {\n  readonly name = \"Think as I go\";\n  readonly tasks: string[] = [];\n  readonly extraPlannerPrompt = ``;\n\n  async execute(\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    const planning = await plannerPrompt(\n      mutableContext,\n      objective,\n      this.extraPlannerPrompt\n    ).invoke();\n    if (!ok(planning)) return planning;\n    let plan = getPlan(planning.last);\n    if (!ok(plan)) return plan;\n\n    await report({\n      actor: \"Planner\",\n      category: \"Progress update\",\n      name: \"Thinking\",\n      icon: \"laps\",\n      details: plan.thinking\n        ? plan.thinking\n        : `\nHere's the list I created:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order, thinking after each step\nand adjusting the list if necessary.`,\n    });\n\n    const results: LLMContent[] = [];\n    let max = plan.todo.length + OVERRUN_BUFFER;\n    let discardIntermediateWork = false;\n    while (--max) {\n      const task = plan.todo.at(0);\n      if (plan.keepLastOnly) {\n        discardIntermediateWork = true;\n      }\n      if (!task) break;\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Currently working on\",\n        icon: \"laps\",\n        details: task.task,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n      this.tasks.push(task.task);\n      const thinking = await thinkingPlannerPrompt(\n        mutableContext,\n        objective,\n        plan,\n        this.tasks,\n        this.extraPlannerPrompt\n      ).invoke();\n      if (!ok(thinking)) return thinking;\n      const newPlan = getPlan(thinking.last);\n      if (!ok(newPlan)) return newPlan;\n      await report({\n        actor: \"Planner\",\n        category: \"Thinking about the plan\",\n        name: \"Thinking\",\n        icon: \"laps\",\n        details: newPlan.thinking || \"Thinking\",\n      });\n\n      plan = newPlan;\n    }\n    if (discardIntermediateWork) {\n      const last = results.at(-1);\n      return last ? [last] : [];\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes think-as-i strategy.",
        "runnable": false
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}