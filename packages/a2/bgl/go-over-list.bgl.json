{
  "title": "A2 Go Over a List",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {},
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./a2/gemini\";\nimport {} from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nexport { invoke as default, describe };\nconst STRATEGY = [\"In Parallel\", \"As a sequence\"];\nfunction planSchema() {\n    return {\n        type: \"object\",\n        properties: {\n            todo: {\n                type: \"array\",\n                items: {\n                    type: \"object\",\n                    properties: { task: { type: \"string\" }, label: { type: \"string\" } },\n                },\n            },\n        },\n    };\n}\nfunction prependInstruction(text, plan) {\n    return {\n        ...plan,\n        parts: [...plan.parts, { text }],\n    };\n}\nfunction plannerPrompt(context, plan) {\n    context ??= [];\n    const instruction = `\nYou are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n\nYour output must be a valid JSON of the following format:\n\n\\`\\`\\`json\n{\n  \"todo\": [{\n    \"label\": \"string, a short label for the task\",\n    \"task\": \"string, The task description. Use action-oriented language, starting with a verb that fits the task.\"\n  }]\n}\n\\`\\`\\`\n`;\n    const contents = [...context, prependInstruction(instruction, plan)];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\nfunction generateId() {\n    return Math.random().toString(36).substring(2, 5);\n}\nasync function executePlan(context, plan, toolManager) {\n    context ??= [];\n    await report({\n        actor: \"Planner\",\n        category: `Creating a plan`,\n        name: \"Plan\",\n        icon: \"laps\",\n        details: `Here's my plan:\n    \n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}`,\n    });\n    const errors = [];\n    const results = (await Promise.all(plan.todo.map(async (item) => {\n        let structuredResponse;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        if (!toolManager.hasTools()) {\n            structuredResponse = new StructuredResponse(generateId(), false);\n            contents = structuredResponse.addPrompt(context, prompt);\n        }\n        else {\n            contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt({\n            body: {\n                contents,\n                tools: toolManager.list(),\n            },\n            systemInstruction: structuredResponse?.instruction(),\n        }, toolManager).invoke({\n            allowToolErrors: true,\n            validator: (content) => {\n                return structuredResponse?.parseContent(content);\n            },\n        });\n        if (!ok(executing)) {\n            errors.push(executing.$error);\n            return;\n        }\n        return structuredResponse\n            ? toLLMContent(structuredResponse.body)\n            : executing.last;\n    }))).filter((item) => !!item);\n    // TODO: Decide what to do here.\n    // if (errors.length > 0) {\n    //   return err(errors.join(\"\\n\\n\"));\n    // }\n    return results;\n}\nasync function invoke({ context, plan, ...params }) {\n    const toolManager = new ToolManager();\n    const template = new Template(plan);\n    const substituting = await template.substitute(params, async ({ path: url }) => toolManager.addTool(url));\n    if (!ok(substituting))\n        return substituting;\n    const planning = await plannerPrompt(context, substituting).invoke();\n    if (!ok(planning))\n        return planning;\n    const planPart = planning.last.parts.at(0);\n    if (!planPart || !(\"json\" in planPart)) {\n        // TODO: Error recovery.\n        return err(`Gemini generated invalid plan`);\n    }\n    const iterating = await executePlan(context, planPart.json, toolManager);\n    if (!ok(iterating))\n        return iterating;\n    const oneContent = {\n        role: \"model\",\n        parts: iterating.flatMap((item) => {\n            return item.parts;\n        }),\n    };\n    return { context: [oneContent] };\n}\nasync function describe({ inputs: { plan } }) {\n    const template = new Template(plan);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                plan: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Instruction\",\n                    description: \"Describe what will be turned into a list and then gone over\",\n                },\n                strategy: {\n                    title: \"Strategy\",\n                    description: \"Whether to process the list in parallel or as a sequence. Parallel is faster. Running in sequence builds on previous work.\",\n                    type: \"string\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    enum: STRATEGY,\n                    icon: \"joiner\",\n                    default: STRATEGY[0],\n                },\n                ...template.schemas(),\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n            additionalProperties: false,\n        },\n        title: \"Go over a list\",\n        description: \"Turn anything into a list, make a plan for that list, and go over it\",\n        metadata: {\n            icon: \"laps\",\n            tags: [\"quick-access\", \"generative\", \"experimental\"],\n            order: 102,\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, type Tool } from \"./a2/gemini\";\nimport { type Params } from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n  plan: LLMContent;\n  strategy: string;\n} & Params;\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\ntype Plan = {\n  todo: {\n    label: string;\n    task: string;\n  }[];\n};\n\nconst STRATEGY = [\"In Parallel\", \"As a sequence\"];\n\nfunction planSchema(): GeminiSchema {\n  return {\n    type: \"object\",\n    properties: {\n      todo: {\n        type: \"array\",\n        items: {\n          type: \"object\",\n          properties: { task: { type: \"string\" }, label: { type: \"string\" } },\n        },\n      },\n    },\n  };\n}\n\nfunction prependInstruction(text: string, plan: LLMContent): LLMContent {\n  return {\n    ...plan,\n    parts: [...plan.parts, { text }],\n  };\n}\n\nfunction plannerPrompt(\n  context: LLMContent[] | undefined,\n  plan: LLMContent\n): GeminiPrompt {\n  context ??= [];\n  const instruction = `\nYou are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n\nYour output must be a valid JSON of the following format:\n\n\\`\\`\\`json\n{\n  \"todo\": [{\n    \"label\": \"string, a short label for the task\",\n    \"task\": \"string, The task description. Use action-oriented language, starting with a verb that fits the task.\"\n  }]\n}\n\\`\\`\\`\n`;\n  const contents = [...context, prependInstruction(instruction, plan)];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n\nfunction generateId() {\n  return Math.random().toString(36).substring(2, 5);\n}\n\nasync function executePlan(\n  context: LLMContent[] | undefined,\n  plan: Plan,\n  toolManager: ToolManager\n): Promise<Outcome<LLMContent[]>> {\n  context ??= [];\n  await report({\n    actor: \"Planner\",\n    category: `Creating a plan`,\n    name: \"Plan\",\n    icon: \"laps\",\n    details: `Here's my plan:\n    \n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}`,\n  });\n  const errors: string[] = [];\n  const results = (\n    await Promise.all(\n      plan.todo.map(async (item) => {\n        let structuredResponse: StructuredResponse | undefined;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        if (!toolManager.hasTools()) {\n          structuredResponse = new StructuredResponse(generateId(), false);\n          contents = structuredResponse.addPrompt(context, prompt);\n        } else {\n          contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt(\n          {\n            body: {\n              contents,\n              tools: toolManager.list(),\n            },\n            systemInstruction: structuredResponse?.instruction(),\n          },\n          toolManager\n        ).invoke({\n          allowToolErrors: true,\n          validator: (content) => {\n            return structuredResponse?.parseContent(content);\n          },\n        });\n        if (!ok(executing)) {\n          errors.push(executing.$error);\n          return;\n        }\n        return structuredResponse\n          ? toLLMContent(structuredResponse.body)\n          : executing.last;\n      })\n    )\n  ).filter((item) => !!item);\n  // TODO: Decide what to do here.\n  // if (errors.length > 0) {\n  //   return err(errors.join(\"\\n\\n\"));\n  // }\n  return results as LLMContent[];\n}\n\nasync function invoke({\n  context,\n  plan,\n  ...params\n}: Inputs): Promise<Outcome<Outputs>> {\n  const toolManager = new ToolManager();\n  const template = new Template(plan);\n  const substituting = await template.substitute(\n    params,\n    async ({ path: url }) => toolManager.addTool(url)\n  );\n  if (!ok(substituting)) return substituting;\n\n  const planning = await plannerPrompt(context, substituting).invoke();\n  if (!ok(planning)) return planning;\n\n  const planPart = planning.last.parts.at(0);\n  if (!planPart || !(\"json\" in planPart)) {\n    // TODO: Error recovery.\n    return err(`Gemini generated invalid plan`);\n  }\n  const iterating = await executePlan(\n    context,\n    planPart.json as Plan,\n    toolManager\n  );\n  if (!ok(iterating)) return iterating;\n  const oneContent = {\n    role: \"model\",\n    parts: iterating.flatMap((item) => {\n      return item.parts;\n    }),\n  };\n  return { context: [oneContent] };\n}\n\ntype DescribeInputs = {\n  inputs: {\n    plan: LLMContent;\n  };\n};\n\nasync function describe({ inputs: { plan } }: DescribeInputs) {\n  const template = new Template(plan);\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n          behavior: [\"main-port\"],\n        },\n        plan: {\n          type: \"object\",\n          behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n          title: \"Instruction\",\n          description:\n            \"Describe what will be turned into a list and then gone over\",\n        },\n        strategy: {\n          title: \"Strategy\",\n          description:\n            \"Whether to process the list in parallel or as a sequence. Parallel is faster. Running in sequence builds on previous work.\",\n          type: \"string\",\n          behavior: [\"config\", \"hint-preview\"],\n          enum: STRATEGY,\n          icon: \"joiner\",\n          default: STRATEGY[0],\n        },\n        ...template.schemas(),\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n      behavior: [\"at-wireable\"],\n      ...template.requireds(),\n      additionalProperties: false,\n    } satisfies Schema,\n    title: \"Go over a list\",\n    description:\n      \"Turn anything into a list, make a plan for that list, and go over it\",\n    metadata: {\n      icon: \"laps\",\n      tags: [\"quick-access\", \"generative\", \"experimental\"],\n      order: 102,\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Turn anything into a list, make a plan for that list, and go over it",
        "runnable": true
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}