{
  "title": "A2 Go Over a List",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {},
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./a2/gemini\";\nimport {} from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { plannerPrompt } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport {} from \"./types\";\nexport { invoke as default, describe };\nconst STRATEGY = [\"All at once\", \"Go in order\", \"Think as I go\"];\nasync function executePlan(context, plan, strategy, toolManager) {\n    const executor = new Runtime(context, toolManager);\n    const strategist = strategy === \"Parallel\"\n        ? new ParallelStrategist()\n        : new SequentialStrategist();\n    // TODO: Decide what to do with errors.\n    return executor.executeStrategy(plan, strategist);\n}\nfunction mapStrategy(strategy) {\n    if (strategy === STRATEGY[0])\n        return \"Parallel\";\n    return \"Sequence\";\n}\nasync function invoke({ context, plan, strategy, ...params }) {\n    const toolManager = new ToolManager();\n    const template = new Template(plan);\n    const substituting = await template.substitute(params, async ({ path: url }) => toolManager.addTool(url));\n    if (!ok(substituting))\n        return substituting;\n    const planning = await plannerPrompt(context, substituting).invoke();\n    if (!ok(planning))\n        return planning;\n    const planPart = planning.last.parts.at(0);\n    if (!planPart || !(\"json\" in planPart)) {\n        // TODO: Error recovery.\n        return err(`Gemini generated invalid plan`);\n    }\n    const iterating = await executePlan(context, planPart.json, mapStrategy(strategy), toolManager);\n    if (!ok(iterating))\n        return iterating;\n    const oneContent = {\n        role: \"model\",\n        parts: iterating.flatMap((item) => {\n            return item.parts;\n        }),\n    };\n    return { context: [oneContent] };\n}\nasync function describe({ inputs: { plan } }) {\n    const template = new Template(plan);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                plan: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Instruction\",\n                    description: \"Describe what will be turned into a list and then gone over\",\n                },\n                strategy: {\n                    title: \"Strategy\",\n                    description: `How to go over the list: \"${STRATEGY[0]}\" is fastest, working in parallel. \n\"${STRATEGY[1]}\" will build on previous work.\n\"${STRATEGY[2]}\" will think after each step adjust the list if necessary`,\n                    type: \"string\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    enum: STRATEGY,\n                    icon: \"joiner\",\n                    default: STRATEGY[0],\n                },\n                ...template.schemas(),\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Results\",\n                },\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n            additionalProperties: false,\n        },\n        title: \"Go over a list\",\n        description: \"Turn anything into a list, make a plan for that list, and go over it\",\n        metadata: {\n            icon: \"laps\",\n            tags: [\"quick-access\", \"generative\", \"experimental\"],\n            order: 102,\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, type Tool } from \"./a2/gemini\";\nimport { type Params } from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { plannerPrompt } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport {\n  type Task,\n  type Plan,\n  type Strategy,\n  type ExecuteStepFunction,\n  type Strategist,\n} from \"./types\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n  plan: LLMContent;\n  strategy: string;\n} & Params;\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nconst STRATEGY = [\"All at once\", \"Go in order\", \"Think as I go\"];\n\nasync function executePlan(\n  context: LLMContent[] | undefined,\n  plan: Plan,\n  strategy: Strategy,\n  toolManager: ToolManager\n): Promise<Outcome<LLMContent[]>> {\n  const executor = new Runtime(context, toolManager);\n  const strategist =\n    strategy === \"Parallel\"\n      ? new ParallelStrategist()\n      : new SequentialStrategist();\n  // TODO: Decide what to do with errors.\n  return executor.executeStrategy(plan, strategist);\n}\n\nfunction mapStrategy(strategy: string): Strategy {\n  if (strategy === STRATEGY[0]) return \"Parallel\";\n  return \"Sequence\";\n}\n\nasync function invoke({\n  context,\n  plan,\n  strategy,\n  ...params\n}: Inputs): Promise<Outcome<Outputs>> {\n  const toolManager = new ToolManager();\n  const template = new Template(plan);\n  const substituting = await template.substitute(\n    params,\n    async ({ path: url }) => toolManager.addTool(url)\n  );\n  if (!ok(substituting)) return substituting;\n\n  const planning = await plannerPrompt(context, substituting).invoke();\n  if (!ok(planning)) return planning;\n\n  const planPart = planning.last.parts.at(0);\n  if (!planPart || !(\"json\" in planPart)) {\n    // TODO: Error recovery.\n    return err(`Gemini generated invalid plan`);\n  }\n  const iterating = await executePlan(\n    context,\n    planPart.json as Plan,\n    mapStrategy(strategy),\n    toolManager\n  );\n  if (!ok(iterating)) return iterating;\n  const oneContent = {\n    role: \"model\",\n    parts: iterating.flatMap((item) => {\n      return item.parts;\n    }),\n  };\n  return { context: [oneContent] };\n}\n\ntype DescribeInputs = {\n  inputs: {\n    plan: LLMContent;\n  };\n};\n\nasync function describe({ inputs: { plan } }: DescribeInputs) {\n  const template = new Template(plan);\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n          behavior: [\"main-port\"],\n        },\n        plan: {\n          type: \"object\",\n          behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n          title: \"Instruction\",\n          description:\n            \"Describe what will be turned into a list and then gone over\",\n        },\n        strategy: {\n          title: \"Strategy\",\n          description: `How to go over the list: \"${STRATEGY[0]}\" is fastest, working in parallel. \n\"${STRATEGY[1]}\" will build on previous work.\n\"${STRATEGY[2]}\" will think after each step adjust the list if necessary`,\n          type: \"string\",\n          behavior: [\"config\", \"hint-preview\"],\n          enum: STRATEGY,\n          icon: \"joiner\",\n          default: STRATEGY[0],\n        },\n        ...template.schemas(),\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Results\",\n        },\n      },\n      behavior: [\"at-wireable\"],\n      ...template.requireds(),\n      additionalProperties: false,\n    } satisfies Schema,\n    title: \"Go over a list\",\n    description:\n      \"Turn anything into a list, make a plan for that list, and go over it\",\n    metadata: {\n      icon: \"laps\",\n      tags: [\"quick-access\", \"generative\", \"experimental\"],\n      order: 102,\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Turn anything into a list, make a plan for that list, and go over it",
        "runnable": true
      }
    },
    "planner-prompt": {
      "code": "/**\n * @fileoverview Contains the planner prompt.\n */\nimport {} from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nexport { plannerPrompt };\nfunction planSchema() {\n    return {\n        type: \"object\",\n        properties: {\n            todo: {\n                type: \"array\",\n                items: {\n                    type: \"object\",\n                    properties: { task: { type: \"string\" }, label: { type: \"string\" } },\n                },\n            },\n        },\n    };\n}\nfunction prependInstruction(text, plan) {\n    return {\n        ...plan,\n        parts: [...plan.parts, { text }],\n    };\n}\nfunction plannerPrompt(context, plan) {\n    context ??= [];\n    const instruction = `\nYou are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n\nYour output must be a valid JSON of the following format:\n\n\\`\\`\\`json\n{\n  \"todo\": [{\n    \"label\": \"string, a short label for the task\",\n    \"task\": \"string, The task description. Use action-oriented language, starting with a verb that fits the task.\"\n  }]\n}\n\\`\\`\\`\n`;\n    const contents = [...context, prependInstruction(instruction, plan)];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\n",
      "metadata": {
        "title": "planner-prompt",
        "source": {
          "code": "/**\n * @fileoverview Contains the planner prompt.\n */\n\nimport { type GeminiSchema } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\n\nexport { plannerPrompt };\n\nfunction planSchema(): GeminiSchema {\n  return {\n    type: \"object\",\n    properties: {\n      todo: {\n        type: \"array\",\n        items: {\n          type: \"object\",\n          properties: { task: { type: \"string\" }, label: { type: \"string\" } },\n        },\n      },\n    },\n  };\n}\n\nfunction prependInstruction(text: string, plan: LLMContent): LLMContent {\n  return {\n    ...plan,\n    parts: [...plan.parts, { text }],\n  };\n}\n\nfunction plannerPrompt(\n  context: LLMContent[] | undefined,\n  plan: LLMContent\n): GeminiPrompt {\n  context ??= [];\n  const instruction = `\nYou are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n\nYour output must be a valid JSON of the following format:\n\n\\`\\`\\`json\n{\n  \"todo\": [{\n    \"label\": \"string, a short label for the task\",\n    \"task\": \"string, The task description. Use action-oriented language, starting with a verb that fits the task.\"\n  }]\n}\n\\`\\`\\`\n`;\n  const contents = [...context, prependInstruction(instruction, plan)];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n",
          "language": "typescript"
        },
        "description": "Contains the planner prompt.",
        "runnable": false
      }
    },
    "types": {
      "code": "/**\n * @fileoverview Common types.\n */\n",
      "metadata": {
        "title": "types",
        "source": {
          "code": "/**\n * @fileoverview Common types.\n */\n\nexport type Task = {\n  label: string;\n  task: string;\n};\n\nexport type Plan = {\n  todo: Task[];\n};\n\nexport type Strategy = \"Parallel\" | \"Sequence\";\n\nexport type ExecuteStepFunction = (\n  item: Task\n) => Promise<LLMContent | undefined>;\n\nexport type Strategist = {\n  execute(\n    plan: Plan,\n    singleStepExecutor: ExecuteStepFunction,\n    mutableContext: LLMContent[]\n  ): Promise<Outcome<LLMContent[]>>;\n};\n",
          "language": "typescript"
        },
        "description": "Common types.",
        "runnable": false
      }
    },
    "runtime": {
      "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./types\";\nexport { Runtime };\nclass Runtime {\n    toolManager;\n    context;\n    errors = [];\n    execute;\n    constructor(context, toolManager) {\n        this.toolManager = toolManager;\n        this.context = context ? [...context] : [];\n        this.execute = this.#execute.bind(this);\n    }\n    generateId() {\n        return Math.random().toString(36).substring(2, 5);\n    }\n    async executeStrategy(plan, strategist) {\n        return strategist.execute(plan, this.execute, this.context);\n    }\n    async #execute(item) {\n        const { toolManager, context, errors } = this;\n        let structuredResponse;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        if (!toolManager.hasTools()) {\n            structuredResponse = new StructuredResponse(this.generateId(), false);\n            contents = structuredResponse.addPrompt(context, prompt);\n        }\n        else {\n            contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt({\n            body: {\n                contents,\n                tools: toolManager.list(),\n            },\n            systemInstruction: structuredResponse?.instruction(),\n        }, {\n            toolManager,\n            allowToolErrors: true,\n            validator: (content) => {\n                return structuredResponse?.parseContent(content);\n            },\n        }).invoke();\n        if (!ok(executing)) {\n            errors.push(executing.$error);\n            return;\n        }\n        return structuredResponse\n            ? toLLMContent(structuredResponse.body, \"model\")\n            : executing.last;\n    }\n}\n",
      "metadata": {
        "title": "runtime",
        "source": {
          "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\n\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {\n  type ExecuteStepFunction,\n  type Plan,\n  type Task,\n  type Strategist,\n} from \"./types\";\n\nexport { Runtime };\n\nclass Runtime {\n  readonly context: LLMContent[];\n  readonly errors: string[] = [];\n  readonly execute: ExecuteStepFunction;\n\n  constructor(\n    context: LLMContent[] | undefined,\n    public readonly toolManager: ToolManager\n  ) {\n    this.context = context ? [...context] : [];\n    this.execute = this.#execute.bind(this);\n  }\n\n  generateId() {\n    return Math.random().toString(36).substring(2, 5);\n  }\n\n  async executeStrategy(\n    plan: Plan,\n    strategist: Strategist\n  ): Promise<Outcome<LLMContent[]>> {\n    return strategist.execute(plan, this.execute, this.context);\n  }\n\n  async #execute(item: Task): Promise<LLMContent | undefined> {\n    const { toolManager, context, errors } = this;\n    let structuredResponse: StructuredResponse | undefined;\n    const prompt = toLLMContent(item.task);\n    let contents;\n    if (!toolManager.hasTools()) {\n      structuredResponse = new StructuredResponse(this.generateId(), false);\n      contents = structuredResponse.addPrompt(context, prompt);\n    } else {\n      contents = [...context, toLLMContent(item.task)];\n    }\n    const executing = await new GeminiPrompt(\n      {\n        body: {\n          contents,\n          tools: toolManager.list(),\n        },\n        systemInstruction: structuredResponse?.instruction(),\n      },\n      {\n        toolManager,\n        allowToolErrors: true,\n        validator: (content) => {\n          return structuredResponse?.parseContent(content);\n        },\n      }\n    ).invoke();\n    if (!ok(executing)) {\n      errors.push(executing.$error);\n      return;\n    }\n    return structuredResponse\n      ? toLLMContent(structuredResponse.body, \"model\")\n      : executing.last;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "The runtime that powers going over the list.",
        "runnable": false
      }
    },
    "parallel-strategist": {
      "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\nimport { report } from \"./a2/output\";\nimport {} from \"./types\";\nexport { ParallelStrategist };\nclass ParallelStrategist {\n    async execute(plan, execute) {\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all list items at the same time.`,\n        });\n        return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n    }\n}\n",
      "metadata": {
        "title": "parallel-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\n\nimport { report } from \"./a2/output\";\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\n\nexport { ParallelStrategist };\n\nclass ParallelStrategist implements Strategist {\n  async execute(\n    plan: Plan,\n    execute: ExecuteStepFunction\n  ): Promise<Outcome<LLMContent[]>> {\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all list items at the same time.`,\n    });\n    return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes a parallel strategy.",
        "runnable": false
      }
    },
    "sequential-strategist": {
      "code": "/**\n * @fileoverview Executes sequential strategy.\n */\nimport {} from \"./types\";\nimport { toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nexport { SequentialStrategist };\nclass SequentialStrategist {\n    async execute(plan, execute, mutableContext) {\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n        });\n        const results = [];\n        for (const task of plan.todo) {\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Item\",\n                icon: \"laps\",\n                details: `Currently working on:\n  \n  ${task.task}\n  `,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "sequential-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes sequential strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nexport { SequentialStrategist };\n\nclass SequentialStrategist implements Strategist {\n  async execute(\n    plan: Plan,\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[]\n  ): Promise<Outcome<LLMContent[]>> {\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n    });\n\n    const results: LLMContent[] = [];\n    for (const task of plan.todo) {\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Item\",\n        icon: \"laps\",\n        details: `Currently working on:\n  \n  ${task.task}\n  `,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes sequential strategy.",
        "runnable": false
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}