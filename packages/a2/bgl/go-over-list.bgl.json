{
  "title": "A2 Go Over a List",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {},
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./a2/gemini\";\nimport {} from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {} from \"./types\";\nexport { invoke as default, describe };\nconst STRATEGISTS = [\n    new ParallelStrategist(),\n    new SequentialStrategist(),\n    new ThinkStrategist(),\n];\nasync function executePlan(objective, context, plan, strategist, toolManager) {\n    if (!strategist)\n        return err(`Unknown strategy`);\n    const executor = new Runtime(context, toolManager);\n    return executor.executeStrategy(objective, plan, strategist);\n}\nfunction findStrategist(name) {\n    return STRATEGISTS.find((strategist) => strategist.name === name);\n}\nasync function invoke({ context, plan: objective, strategy, ...params }) {\n    const toolManager = new ToolManager();\n    const template = new Template(objective);\n    const substituting = await template.substitute(params, async ({ path: url }) => toolManager.addTool(url));\n    if (!ok(substituting))\n        return substituting;\n    const strategist = findStrategist(strategy);\n    const planning = await plannerPrompt(context, substituting, false).invoke();\n    if (!ok(planning))\n        return planning;\n    const plan = getPlan(planning.last);\n    if (!ok(plan))\n        return plan;\n    const iterating = await executePlan(substituting, context, plan, strategist, toolManager);\n    if (!ok(iterating))\n        return iterating;\n    const oneContent = {\n        role: \"model\",\n        parts: iterating.flatMap((item) => {\n            return item.parts;\n        }),\n    };\n    return { context: [oneContent] };\n}\nasync function describe({ inputs: { plan } }) {\n    const template = new Template(plan);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                plan: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Objective\",\n                    description: \"Describe what will be turned into a list and then gone over\",\n                },\n                strategy: {\n                    title: \"Strategy\",\n                    description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n                    type: \"string\",\n                    behavior: [\"config\", \"hint-preview\"],\n                    enum: STRATEGISTS.map((strategist) => strategist.name),\n                    icon: \"joiner\",\n                    default: STRATEGISTS[0].name,\n                },\n                ...template.schemas(),\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Results\",\n                },\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n            additionalProperties: false,\n        },\n        title: \"Go over a list\",\n        description: \"Turn anything into a list, make a plan for that list, and go over it\",\n        metadata: {\n            icon: \"laps\",\n            tags: [\"quick-access\", \"generative\", \"experimental\"],\n            order: 102,\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Turn anything into a list, make a plan for that list, and go over it\n */\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, type Tool } from \"./a2/gemini\";\nimport { type Params } from \"./a2/common\";\nimport { ok, err, toLLMContent, llm } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { plannerPrompt, getPlan } from \"./planner-prompt\";\nimport { Runtime } from \"./runtime\";\nimport { ParallelStrategist } from \"./parallel-strategist\";\nimport { SequentialStrategist } from \"./sequential-strategist\";\nimport { ThinkStrategist } from \"./think-strategist\";\nimport {\n  type Task,\n  type Plan,\n  type Strategy,\n  type ExecuteStepFunction,\n  type Strategist,\n} from \"./types\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n  plan: LLMContent;\n  strategy: string;\n} & Params;\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nconst STRATEGISTS: Strategist[] = [\n  new ParallelStrategist(),\n  new SequentialStrategist(),\n  new ThinkStrategist(),\n];\n\nasync function executePlan(\n  objective: LLMContent,\n  context: LLMContent[] | undefined,\n  plan: Plan,\n  strategist: Strategist | undefined,\n  toolManager: ToolManager\n): Promise<Outcome<LLMContent[]>> {\n  if (!strategist) return err(`Unknown strategy`);\n  const executor = new Runtime(context, toolManager);\n  return executor.executeStrategy(objective, plan, strategist);\n}\n\nfunction findStrategist(name: string): Strategist | undefined {\n  return STRATEGISTS.find((strategist) => strategist.name === name);\n}\n\nasync function invoke({\n  context,\n  plan: objective,\n  strategy,\n  ...params\n}: Inputs): Promise<Outcome<Outputs>> {\n  const toolManager = new ToolManager();\n  const template = new Template(objective);\n  const substituting = await template.substitute(\n    params,\n    async ({ path: url }) => toolManager.addTool(url)\n  );\n  if (!ok(substituting)) return substituting;\n\n  const strategist = findStrategist(strategy);\n  const planning = await plannerPrompt(context, substituting, false).invoke();\n  if (!ok(planning)) return planning;\n  const plan = getPlan(planning.last);\n  if (!ok(plan)) return plan;\n  const iterating = await executePlan(\n    substituting,\n    context,\n    plan,\n    strategist,\n    toolManager\n  );\n  if (!ok(iterating)) return iterating;\n  const oneContent = {\n    role: \"model\",\n    parts: iterating.flatMap((item) => {\n      return item.parts;\n    }),\n  };\n  return { context: [oneContent] };\n}\n\ntype DescribeInputs = {\n  inputs: {\n    plan: LLMContent;\n  };\n};\n\nasync function describe({ inputs: { plan } }: DescribeInputs) {\n  const template = new Template(plan);\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n          behavior: [\"main-port\"],\n        },\n        plan: {\n          type: \"object\",\n          behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n          title: \"Objective\",\n          description:\n            \"Describe what will be turned into a list and then gone over\",\n        },\n        strategy: {\n          title: \"Strategy\",\n          description: `How to go over the list: \n\"${STRATEGISTS[0].name}\" is fastest, working in parallel. \n\"${STRATEGISTS[1].name}\" will build on previous work.\n\"${STRATEGISTS[2].name}\" will think after each step adjust the list if necessary`,\n          type: \"string\",\n          behavior: [\"config\", \"hint-preview\"],\n          enum: STRATEGISTS.map((strategist) => strategist.name),\n          icon: \"joiner\",\n          default: STRATEGISTS[0].name,\n        },\n        ...template.schemas(),\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Results\",\n        },\n      },\n      behavior: [\"at-wireable\"],\n      ...template.requireds(),\n      additionalProperties: false,\n    } satisfies Schema,\n    title: \"Go over a list\",\n    description:\n      \"Turn anything into a list, make a plan for that list, and go over it\",\n    metadata: {\n      icon: \"laps\",\n      tags: [\"quick-access\", \"generative\", \"experimental\"],\n      order: 102,\n    },\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Turn anything into a list, make a plan for that list, and go over it",
        "runnable": true
      }
    },
    "planner-prompt": {
      "code": "/**\n * @fileoverview Contains the planner prompt.\n */\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport {} from \"./types\";\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\nconst PREAMBLE = `You are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\nconst KEEP_LAST_ONLY = `Make sure to decide whether to keep only last tasks's output or output of all tasks. Think about it this way: if the results of the last task\nincorporate all results of the previous task, then we only need to keep the last tasks's output.`;\nfunction planSchema() {\n    return {\n        type: \"object\",\n        properties: {\n            thinking: {\n                type: \"string\",\n                description: \"Brief reasoning on why these steps are the right steps to fulfill the objective\",\n            },\n            todo: {\n                type: \"array\",\n                items: {\n                    type: \"object\",\n                    properties: {\n                        task: {\n                            type: \"string\",\n                            description: \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n                        },\n                        label: {\n                            description: \"Short label for the task\",\n                            type: \"string\",\n                        },\n                    },\n                },\n            },\n            keepLastOnly: {\n                description: \"Set to true when the last task's results incorporate all of previous tasks' results. Set to false otherwise\",\n                type: \"boolean\",\n            },\n        },\n    };\n}\nfunction getPlan(content) {\n    const planPart = content.parts.at(0);\n    if (!planPart || !(\"json\" in planPart)) {\n        // TODO: Error recovery.\n        return err(`Gemini generated invalid plan`);\n    }\n    return planPart.json;\n}\nfunction prependInstruction(text, plan) {\n    return {\n        ...plan,\n        parts: [...plan.parts, { text }],\n    };\n}\nfunction thinkingPlannerPrompt(context, objective, plan, steps) {\n    const instruction = llm `\n${PREAMBLE}\n${KEEP_LAST_ONLY}\n\nYour objective is:\n\n${objective}\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n    const contents = [...context, instruction];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\nfunction plannerPrompt(context, objective, parallel) {\n    context ??= [];\n    const instruction = `${PREAMBLE}${parallel ? KEEP_LAST_ONLY : \"\"}`;\n    const contents = [...context, prependInstruction(instruction, objective)];\n    return new GeminiPrompt({\n        body: {\n            contents,\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseSchema: planSchema(),\n                responseMimeType: \"application/json\",\n            },\n        },\n    });\n}\n",
      "metadata": {
        "title": "planner-prompt",
        "source": {
          "code": "/**\n * @fileoverview Contains the planner prompt.\n */\n\nimport { type GeminiSchema, defaultSafetySettings } from \"./a2/gemini\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { llm, err } from \"./a2/utils\";\nimport { type Plan } from \"./types\";\n\nexport { plannerPrompt, thinkingPlannerPrompt, getPlan };\n\nconst PREAMBLE = `You are a planner. \nYou are to create a precise plan for a given objective. This plan will be executed by others \nand your responsibility is to produce a plan that fulfills the objective.\n\nExamine the objective, slow down, take a deep breath.\nNow think: how might you break the objective into tasks that, when all completed, will fulfill the objective?\nNow write out the tasks. Do not add any superflous tasks.\n\nFor each task, also think of a brief label that describes that task and could be used in a UI as a hint to the user.\n\nIf multiple tools are mentioned in the objective, make sure to mention them all in the task so that whoever\nexecutes the task can decide which tool to use.\n`;\n\nconst KEEP_LAST_ONLY = `Make sure to decide whether to keep only last tasks's output or output of all tasks. Think about it this way: if the results of the last task\nincorporate all results of the previous task, then we only need to keep the last tasks's output.`;\n\nfunction planSchema(): GeminiSchema {\n  return {\n    type: \"object\",\n    properties: {\n      thinking: {\n        type: \"string\",\n        description:\n          \"Brief reasoning on why these steps are the right steps to fulfill the objective\",\n      },\n      todo: {\n        type: \"array\",\n        items: {\n          type: \"object\",\n          properties: {\n            task: {\n              type: \"string\",\n              description:\n                \"The task description. Use action-oriented language, starting with a verb that fits the task.\",\n            },\n            label: {\n              description: \"Short label for the task\",\n              type: \"string\",\n            },\n          },\n        },\n      },\n      keepLastOnly: {\n        description:\n          \"Set to true when the last task's results incorporate all of previous tasks' results. Set to false otherwise\",\n        type: \"boolean\",\n      },\n    },\n  };\n}\n\nfunction getPlan(content: LLMContent): Outcome<Plan> {\n  const planPart = content.parts.at(0);\n  if (!planPart || !(\"json\" in planPart)) {\n    // TODO: Error recovery.\n    return err(`Gemini generated invalid plan`);\n  }\n  return planPart.json as Plan;\n}\n\nfunction prependInstruction(text: string, plan: LLMContent): LLMContent {\n  return {\n    ...plan,\n    parts: [...plan.parts, { text }],\n  };\n}\n\nfunction thinkingPlannerPrompt(\n  context: LLMContent[],\n  objective: LLMContent,\n  plan: Plan,\n  steps: string[]\n): GeminiPrompt {\n  const instruction = llm`\n${PREAMBLE}\n${KEEP_LAST_ONLY}\n\nYour objective is:\n\n${objective}\n\nYour original plan was:\n\n\\`\\`\\`json\n${JSON.stringify(plan)}\n\\`\\`\\`\n\nSo far, you've completed these steps:\n\n${steps.map((step) => `- ${step}`).join(\"\\n\")}\n\nUpdate the plan to ensure that the steps that follow achieve the objective.\nPay particular attention to steps that did not complete successfully and strategize\ndifferent approaches and steps that might be necesssary to complete them.\n\nOnly add steps to the plan that still need to be completed.\nDo not return completed steps as part of the updated plan.\nIf no more steps are needed, return no steps.\n`.asContent();\n\n  const contents = [...context, instruction];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n\nfunction plannerPrompt(\n  context: LLMContent[] | undefined,\n  objective: LLMContent,\n  parallel: boolean\n): GeminiPrompt {\n  context ??= [];\n  const instruction = `${PREAMBLE}${parallel ? KEEP_LAST_ONLY : \"\"}`;\n\n  const contents = [...context, prependInstruction(instruction, objective)];\n  return new GeminiPrompt({\n    body: {\n      contents,\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseSchema: planSchema(),\n        responseMimeType: \"application/json\",\n      },\n    },\n  });\n}\n",
          "language": "typescript"
        },
        "description": "Contains the planner prompt.",
        "runnable": false
      }
    },
    "types": {
      "code": "/**\n * @fileoverview Common types.\n */\n",
      "metadata": {
        "title": "types",
        "source": {
          "code": "/**\n * @fileoverview Common types.\n */\n\nexport type Task = {\n  label: string;\n  task: string;\n};\n\nexport type Plan = {\n  thinking?: string;\n  todo: Task[];\n  keepLastOnly: boolean;\n};\n\nexport type Strategy = \"Parallel\" | \"Sequence\";\n\nexport type ExecuteStepFunction = (\n  item: Task\n) => Promise<LLMContent | undefined>;\n\nexport type Strategist = {\n  name: string;\n  parallel: boolean;\n  execute(\n    plan: Plan,\n    singleStepExecutor: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>>;\n};\n",
          "language": "typescript"
        },
        "description": "Common types.",
        "runnable": false
      }
    },
    "runtime": {
      "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {} from \"./types\";\nexport { Runtime };\nclass Runtime {\n    toolManager;\n    context;\n    errors = [];\n    execute;\n    constructor(context, toolManager) {\n        this.toolManager = toolManager;\n        this.context = context ? [...context] : [];\n        this.execute = this.#execute.bind(this);\n    }\n    generateId() {\n        return Math.random().toString(36).substring(2, 5);\n    }\n    async executeStrategy(objective, plan, strategist) {\n        return strategist.execute(plan, this.execute, this.context, objective);\n    }\n    async #execute(item) {\n        const { toolManager, context, errors } = this;\n        let structuredResponse;\n        const prompt = toLLMContent(item.task);\n        let contents;\n        if (!toolManager.hasTools()) {\n            structuredResponse = new StructuredResponse(this.generateId(), false);\n            contents = structuredResponse.addPrompt(context, prompt);\n        }\n        else {\n            contents = [...context, toLLMContent(item.task)];\n        }\n        const executing = await new GeminiPrompt({\n            body: {\n                contents,\n                tools: toolManager.list(),\n            },\n            systemInstruction: structuredResponse?.instruction(),\n        }, {\n            toolManager,\n            allowToolErrors: true,\n            validator: (content) => {\n                return structuredResponse?.parseContent(content);\n            },\n        }).invoke();\n        if (!ok(executing)) {\n            errors.push(executing.$error);\n            return;\n        }\n        return structuredResponse\n            ? toLLMContent(structuredResponse.body, \"model\")\n            : executing.last;\n    }\n}\n",
      "metadata": {
        "title": "runtime",
        "source": {
          "code": "/**\n * @fileoverview The runtime that powers going over the list.\n */\n\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { StructuredResponse } from \"./a2/structured-response\";\nimport { ok, err, toLLMContent } from \"./a2/utils\";\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport {\n  type ExecuteStepFunction,\n  type Plan,\n  type Task,\n  type Strategist,\n} from \"./types\";\n\nexport { Runtime };\n\nclass Runtime {\n  readonly context: LLMContent[];\n  readonly errors: string[] = [];\n  readonly execute: ExecuteStepFunction;\n\n  constructor(\n    context: LLMContent[] | undefined,\n    public readonly toolManager: ToolManager\n  ) {\n    this.context = context ? [...context] : [];\n    this.execute = this.#execute.bind(this);\n  }\n\n  generateId() {\n    return Math.random().toString(36).substring(2, 5);\n  }\n\n  async executeStrategy(\n    objective: LLMContent,\n    plan: Plan,\n    strategist: Strategist\n  ): Promise<Outcome<LLMContent[]>> {\n    return strategist.execute(plan, this.execute, this.context, objective);\n  }\n\n  async #execute(item: Task): Promise<LLMContent | undefined> {\n    const { toolManager, context, errors } = this;\n    let structuredResponse: StructuredResponse | undefined;\n    const prompt = toLLMContent(item.task);\n    let contents;\n    if (!toolManager.hasTools()) {\n      structuredResponse = new StructuredResponse(this.generateId(), false);\n      contents = structuredResponse.addPrompt(context, prompt);\n    } else {\n      contents = [...context, toLLMContent(item.task)];\n    }\n    const executing = await new GeminiPrompt(\n      {\n        body: {\n          contents,\n          tools: toolManager.list(),\n        },\n        systemInstruction: structuredResponse?.instruction(),\n      },\n      {\n        toolManager,\n        allowToolErrors: true,\n        validator: (content) => {\n          return structuredResponse?.parseContent(content);\n        },\n      }\n    ).invoke();\n    if (!ok(executing)) {\n      errors.push(executing.$error);\n      return;\n    }\n    return structuredResponse\n      ? toLLMContent(structuredResponse.body, \"model\")\n      : executing.last;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "The runtime that powers going over the list.",
        "runnable": false
      }
    },
    "parallel-strategist": {
      "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\nimport { report } from \"./a2/output\";\nimport {} from \"./types\";\nexport { ParallelStrategist };\nclass ParallelStrategist {\n    name = \"All at once\";\n    parallel = true;\n    async execute(plan, execute) {\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all list items at the same time.`,\n        });\n        return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n    }\n}\n",
      "metadata": {
        "title": "parallel-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes a parallel strategy.\n */\n\nimport { report } from \"./a2/output\";\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\n\nexport { ParallelStrategist };\n\nclass ParallelStrategist implements Strategist {\n  readonly name = \"All at once\";\n  readonly parallel = true;\n\n  async execute(\n    plan: Plan,\n    execute: ExecuteStepFunction\n  ): Promise<Outcome<LLMContent[]>> {\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `- ${item.label}`).join(\"\\n\")}\n\nI will now work on all list items at the same time.`,\n    });\n    return (await Promise.all(plan.todo.map(execute))).filter((item) => !!item);\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes a parallel strategy.",
        "runnable": false
      }
    },
    "sequential-strategist": {
      "code": "/**\n * @fileoverview Executes sequential strategy.\n */\nimport {} from \"./types\";\nimport { toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nexport { SequentialStrategist };\nclass SequentialStrategist {\n    name = \"Go in order\";\n    parallel = false;\n    async execute(plan, execute, mutableContext) {\n        await report({\n            actor: \"Planner\",\n            category: `Creating a list`,\n            name: \"Here's my list\",\n            icon: \"laps\",\n            details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n        });\n        const results = [];\n        for (const task of plan.todo) {\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Item\",\n                icon: \"laps\",\n                details: `Currently working on:\n  \n  ${task.task}\n  `,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "sequential-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes sequential strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nexport { SequentialStrategist };\n\nclass SequentialStrategist implements Strategist {\n  readonly name = \"Go in order\";\n  readonly parallel = false;\n\n  async execute(\n    plan: Plan,\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[]\n  ): Promise<Outcome<LLMContent[]>> {\n    await report({\n      actor: \"Planner\",\n      category: `Creating a list`,\n      name: \"Here's my list\",\n      icon: \"laps\",\n      details: `\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order.`,\n    });\n\n    const results: LLMContent[] = [];\n    for (const task of plan.todo) {\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Item\",\n        icon: \"laps\",\n        details: `Currently working on:\n  \n  ${task.task}\n  `,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes sequential strategy.",
        "runnable": false
      }
    },
    "think-strategist": {
      "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\nimport {} from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\nimport { thinkingPlannerPrompt, getPlan } from \"./planner-prompt\";\nexport { ThinkStrategist };\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\nclass ThinkStrategist {\n    name = \"Think as I go\";\n    tasks = [];\n    parallel = false;\n    async execute(plan, execute, mutableContext, objective) {\n        await report({\n            actor: \"Planner\",\n            category: \"Progress update\",\n            name: \"Thinking\",\n            icon: \"laps\",\n            details: plan.thinking\n                ? plan.thinking\n                : `\nHere's the list I created:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order, thinking after each step\nand adjusting the list if necessary.`,\n        });\n        const results = [];\n        let max = plan.todo.length + OVERRUN_BUFFER;\n        let discardIntermediateWork = false;\n        while (--max) {\n            const task = plan.todo.at(0);\n            if (plan.keepLastOnly) {\n                discardIntermediateWork = true;\n            }\n            if (!task)\n                break;\n            await report({\n                actor: \"Worker\",\n                category: \"Working on a list item\",\n                name: \"Currently working on\",\n                icon: \"laps\",\n                details: task.task,\n            });\n            const result = await execute(task);\n            if (result) {\n                mutableContext.push(toLLMContent(task.task), result);\n                results.push(result);\n            }\n            this.tasks.push(task.task);\n            const thinking = await thinkingPlannerPrompt(mutableContext, objective, plan, this.tasks).invoke();\n            if (!ok(thinking))\n                return thinking;\n            const newPlan = getPlan(thinking.last);\n            if (!ok(newPlan))\n                return newPlan;\n            await report({\n                actor: \"Planner\",\n                category: \"Thinking about the plan\",\n                name: \"Thinking\",\n                icon: \"laps\",\n                details: newPlan.thinking || \"Thinking\",\n            });\n            plan = newPlan;\n        }\n        if (discardIntermediateWork) {\n            const last = results.at(-1);\n            return last ? [last] : [];\n        }\n        return results;\n    }\n}\n",
      "metadata": {
        "title": "think-strategist",
        "source": {
          "code": "/**\n * @fileoverview Executes think-as-i strategy.\n */\n\nimport { type Strategist, type Plan, type ExecuteStepFunction } from \"./types\";\nimport { ok, toLLMContent } from \"./a2/utils\";\nimport { report } from \"./a2/output\";\n\nimport { thinkingPlannerPrompt, getPlan } from \"./planner-prompt\";\n\nexport { ThinkStrategist };\n\n/**\n * How many extra steps beyond original plan do we allow\n * before concluding we are in the weeds and giving up.\n */\nconst OVERRUN_BUFFER = 10;\n\nclass ThinkStrategist implements Strategist {\n  readonly name = \"Think as I go\";\n  readonly tasks: string[] = [];\n  readonly parallel = false;\n\n  async execute(\n    plan: Plan,\n    execute: ExecuteStepFunction,\n    mutableContext: LLMContent[],\n    objective: LLMContent\n  ): Promise<Outcome<LLMContent[]>> {\n    await report({\n      actor: \"Planner\",\n      category: \"Progress update\",\n      name: \"Thinking\",\n      icon: \"laps\",\n      details: plan.thinking\n        ? plan.thinking\n        : `\nHere's the list I created:\n\n${plan.todo.map((item) => `1. ${item.label}`).join(\"\\n\")}\n\nI will now go over the list in order, thinking after each step\nand adjusting the list if necessary.`,\n    });\n\n    const results: LLMContent[] = [];\n    let max = plan.todo.length + OVERRUN_BUFFER;\n    let discardIntermediateWork = false;\n    while (--max) {\n      const task = plan.todo.at(0);\n      if (plan.keepLastOnly) {\n        discardIntermediateWork = true;\n      }\n      if (!task) break;\n      await report({\n        actor: \"Worker\",\n        category: \"Working on a list item\",\n        name: \"Currently working on\",\n        icon: \"laps\",\n        details: task.task,\n      });\n      const result = await execute(task);\n      if (result) {\n        mutableContext.push(toLLMContent(task.task), result);\n        results.push(result);\n      }\n      this.tasks.push(task.task);\n      const thinking = await thinkingPlannerPrompt(\n        mutableContext,\n        objective,\n        plan,\n        this.tasks\n      ).invoke();\n      if (!ok(thinking)) return thinking;\n      const newPlan = getPlan(thinking.last);\n      if (!ok(newPlan)) return newPlan;\n      await report({\n        actor: \"Planner\",\n        category: \"Thinking about the plan\",\n        name: \"Thinking\",\n        icon: \"laps\",\n        details: newPlan.thinking || \"Thinking\",\n      });\n\n      plan = newPlan;\n    }\n    if (discardIntermediateWork) {\n      const last = results.at(-1);\n      return last ? [last] : [];\n    }\n    return results;\n  }\n}\n",
          "language": "typescript"
        },
        "description": "Executes think-as-i strategy.",
        "runnable": false
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}