{
  "title": "Google Drive",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "icon": "gdrive",
    "visual": {
      "presentation": {
        "themes": {
          "f65ea9aa-b8c6-4c80-9667-a08c4f631013": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "f65ea9aa-b8c6-4c80-9667-a08c4f631013"
      }
    },
    "userModified": true,
    "tags": [
      "connector",
      "published",
      "experimental"
    ],
    "comments": [
      {
        "id": "comment-c74afa15",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 281,
            "y": 501,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ]
  },
  "modules": {
    "configurator": {
      "code": "/**\n * @fileoverview Add a description for your module here.\n */\nimport { err, ok } from \"./a2/utils\";\nimport { createConfigurator } from \"./a2/connector-manager\";\nexport { invoke as default, describe };\nconst CONNECTOR_TITLE = \"Google Drive\";\nconst { invoke, describe } = createConfigurator({\n    title: CONNECTOR_TITLE,\n    initialize: async () => {\n        return { title: \"Untitled Drive File\", configuration: {} };\n    },\n    read: async ({ id, configuration }) => {\n        return {\n            schema: {\n                type: \"object\",\n                properties: {\n                    file: {\n                        type: \"object\",\n                        title: \"Google Drive File\",\n                        description: \"Select Google Drive File\",\n                        behavior: [\"google-drive-file-id\"],\n                    },\n                },\n            },\n            values: configuration,\n        };\n    },\n    write: async ({ id, values }) => {\n        console.log(\"WRITE\", id, values);\n        return values;\n    },\n});\n",
      "metadata": {
        "title": "configurator",
        "source": {
          "code": "/**\n * @fileoverview Add a description for your module here.\n */\n\nimport { err, ok } from \"./a2/utils\";\nimport { createConfigurator } from \"./a2/connector-manager\";\nimport type { ConnectorConfiguration } from \"./types\";\n\nexport { invoke as default, describe };\n\nconst CONNECTOR_TITLE = \"Google Drive\";\n\nconst { invoke, describe } = createConfigurator<\n  ConnectorConfiguration,\n  ConnectorConfiguration\n>({\n  title: CONNECTOR_TITLE,\n  initialize: async () => {\n    return { title: \"Untitled Drive File\", configuration: {} };\n  },\n  read: async ({ id, configuration }) => {\n    return {\n      schema: {\n        type: \"object\",\n        properties: {\n          file: {\n            type: \"object\",\n            title: \"Google Drive File\",\n            description: \"Select Google Drive File\",\n            behavior: [\"google-drive-file-id\"],\n          },\n        },\n      },\n      values: configuration,\n    };\n  },\n  write: async ({ id, values }) => {\n    console.log(\"WRITE\", id, values);\n    return values;\n  },\n});\n",
          "language": "typescript"
        },
        "description": "Add a description for your module here.",
        "runnable": false
      }
    },
    "marked": {
      "code": "/**\n * marked v14.1.3 - a markdown parser\n * Copyright (c) 2011-2024, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n/**\n * Gets the original marked default options.\n */\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\nlet _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n/**\n * Helpers\n */\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = new RegExp(escapeTest.source, \"g\");\nconst escapeTestNoEncode = /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/;\nconst escapeReplaceNoEncode = new RegExp(escapeTestNoEncode.source, \"g\");\nconst escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\",\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nfunction escape$1(html, encode) {\n  if (encode) {\n    if (escapeTest.test(html)) {\n      return html.replace(escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (escapeTestNoEncode.test(html)) {\n      return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html;\n}\nconst caret = /(^|[^\\[])\\^/g;\nfunction edit(regex, opt) {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  opt = opt || \"\";\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(/%25/g, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nconst noopTest = { exec: () => null };\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return \"|\";\n      } else {\n        // add space before unescaped |\n        return \" |\";\n      }\n    }),\n    cells = row.split(/ \\|/);\n  let i = 0;\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, \"|\");\n  }\n  return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  return -1;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n  const href = link.href;\n  const title = link.title ? escape$1(link.title) : null;\n  const text = cap[1].replace(/\\\\([\\[\\]])/g, \"$1\");\n  if (cap[0].charAt(0) !== \"!\") {\n    lexer.state.inLink = true;\n    const token = {\n      type: \"link\",\n      raw,\n      href,\n      title,\n      text,\n      tokens: lexer.inlineTokens(text),\n    };\n    lexer.state.inLink = false;\n    return token;\n  }\n  return {\n    type: \"image\",\n    raw,\n    href,\n    title,\n    text: escape$1(text),\n  };\n}\nfunction indentCodeCompensation(raw, text) {\n  const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text\n    .split(\"\\n\")\n    .map((node) => {\n      const matchIndentInNode = node.match(/^\\s+/);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n      const [indentInNode] = matchIndentInNode;\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n      return node;\n    })\n    .join(\"\\n\");\n}\n/**\n * Tokenizer\n */\nclass _Tokenizer {\n  options;\n  rules; // set by the lexer\n  lexer; // set by the lexer\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0],\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(/^(?: {1,4}| {0,3}\\t)/gm, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text,\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\");\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2]\n          ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\")\n          : cap[2],\n        text,\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      // remove trailing #s\n      if (/#$/.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || / $/.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\"),\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (/^ {0,3}>/.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(/\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g, \"\\n    $1\")\n          .replace(/^ {0,3}>[ \\t]?/gm, \"\");\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens[tokens.length - 1];\n        if (lastToken?.type === \"code\") {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          // include continuation in nested blockquote\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.text.length) +\n            newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          // include continuation in nested list\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText\n            .substring(tokens[tokens.length - 1].raw.length)\n            .split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: [],\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      // Get next list item\n      const itemRegex = new RegExp(\n        `^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`\n      );\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2]\n          .split(\"\\n\", 1)[0]\n          .replace(/^\\t+/, (t) => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(/[^ ]/); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && /^[ \\t]*$/.test(nextLine)) {\n          // Items begin with at most one blank line\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`\n          );\n          const hrRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`\n          );\n          const fencesBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`\n          );\n          const headingBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}#`\n          );\n          const htmlBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}<[a-z].*>`,\n            \"i\"\n          );\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(/^ {1,4}(?=( {4})*[^ ])/g, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(/\\t/g, \"    \");\n            }\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (\n              nextLineWithoutTabs.search(/[^ ]/) >= indent ||\n              !nextLine.trim()\n            ) {\n              // Dedent if possible\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(/\\t/g, \"    \").search(/[^ ]/) >= 4) {\n                // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              // Check if current line is blank\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (/\\n[ \\t]*\\n[ \\t]*$/.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = /^\\[[ xX]\\] /.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(/^\\[[ xX]\\] +/, \"\");\n          }\n        }\n        list.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n        list.raw += raw;\n      }\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      list.items[list.items.length - 1].raw =\n        list.items[list.items.length - 1].raw.trimEnd();\n      list.items[list.items.length - 1].text =\n        list.items[list.items.length - 1].text.trimEnd();\n      list.raw = list.raw.trimEnd();\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(\n            (t) => t.type === \"space\"\n          );\n          const hasMultipleLineBreaks =\n            spacers.length > 0 && spacers.some((t) => /\\n.*\\n/.test(t.raw));\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n      return list;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(/\\s+/g, \" \");\n      const href = cap[2]\n        ? cap[2]\n            .replace(/^<(.*)>$/, \"$1\")\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : \"\";\n      const title = cap[3]\n        ? cap[3]\n            .substring(1, cap[3].length - 1)\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : cap[3];\n      return {\n        type: \"def\",\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!/[:|]/.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(/^\\||\\| *$/g, \"\").split(\"|\");\n    const rows =\n      cap[3] && cap[3].trim()\n        ? cap[3].replace(/\\n[ \\t]*$/, \"\").split(\"\\n\")\n        : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n    for (const align of aligns) {\n      if (/^ *-+: *$/.test(align)) {\n        item.align.push(\"right\");\n      } else if (/^ *:-+: *$/.test(align)) {\n        item.align.push(\"center\");\n      } else if (/^ *:-+ *$/.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(\n        splitCells(row, item.header.length).map((cell, i) => {\n          return {\n            text: cell,\n            tokens: this.lexer.inline(cell),\n            header: false,\n            align: item.align[i],\n          };\n        })\n      );\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text =\n        cap[1].charAt(cap[1].length - 1) === \"\\n\"\n          ? cap[1].slice(0, -1)\n          : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: escape$1(cap[1]),\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (\n        !this.lexer.state.inRawBlock &&\n        /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = true;\n      } else if (\n        this.lexer.state.inRawBlock &&\n        /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!/>$/.test(trimmedUrl)) {\n          return;\n        }\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (/^</.test(href)) {\n        if (this.options.pedantic && !/>$/.test(trimmedUrl)) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(\n        cap,\n        {\n          href: href\n            ? href.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : href,\n          title: title\n            ? title.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : title,\n        },\n        cap[0],\n        this.lexer\n      );\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if (\n      (cap = this.rules.inline.reflink.exec(src)) ||\n      (cap = this.rules.inline.nolink.exec(src))\n    ) {\n      const linkString = (cap[2] || cap[1]).replace(/\\s+/g, \" \");\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (\n      !nextChar ||\n      !prevChar ||\n      this.rules.inline.punctuation.exec(prevChar)\n    ) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg =\n        match[0][0] === \"*\"\n          ? this.rules.inline.emStrongRDelimAst\n          : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim =\n          match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue; // skip single * in __abc*abc__\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(\n          0,\n          lLength + match.index + lastCharLength + rLength\n        );\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(/\\n/g, \" \");\n      const hasNonSpaceChars = /[^ ]/.test(text);\n      const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      text = escape$1(text, true);\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0],\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[1]);\n        href = \"mailto:\" + text;\n      } else {\n        text = escape$1(cap[1]);\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if ((cap = this.rules.inline.url.exec(src))) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[0]);\n        href = \"mailto:\" + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = escape$1(cap[0]);\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      let text;\n      if (this.lexer.state.inRawBlock) {\n        text = cap[0];\n      } else {\n        text = escape$1(cap[0]);\n      }\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n}\n\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences =\n  /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheading = edit(\n  /^(?!bull |blockCode|fences|blockquote|heading|html)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/\n)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .getRegex();\nconst _paragraph =\n  /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(\n  /^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/\n)\n  .replace(\"label\", _blockLabel)\n  .replace(\n    \"title\",\n    /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/\n  )\n  .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\nconst _tag =\n  \"address|article|aside|base|basefont|blockquote|body|caption\" +\n  \"|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption\" +\n  \"|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe\" +\n  \"|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option\" +\n  \"|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title\" +\n  \"|tr|track|ul\";\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  \"^ {0,3}(?:\" + // optional indentation\n    \"<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)\" + // (1)\n    \"|comment[^\\\\n]*(\\\\n+|$)\" + // (2)\n    \"|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)\" + // (3)\n    \"|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)\" + // (4)\n    \"|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)\" + // (5)\n    \"|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (6)\n    \"|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) open tag\n    \"|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) closing tag\n    \")\",\n  \"i\"\n)\n  .replace(\"comment\", _comment)\n  .replace(\"tag\", _tag)\n  .replace(\n    \"attribute\",\n    / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst paragraph = edit(_paragraph)\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n  .replace(\"|table\", \"\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace(\"paragraph\", paragraph)\n  .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit(\n  \"^ *([^\\\\n ].*)\\\\n\" + // Header\n    \" {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)\" + // Align\n    \"(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\"\n) // Cells\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"code\", \"(?: {4}| {0,3}\\t)[^\\\\n]\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockGfm = {\n  ...blockNormal,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n    .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n    .replace(\"table\", gfmTable) // interrupt paragraphs with table\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n    .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n    .replace(\n      \"html\",\n      \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n    )\n    .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n  ...blockNormal,\n  html: edit(\n    \"^ *(?:comment *(?:\\\\n|\\\\s*$)\" +\n      \"|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)\" + // closed tag\n      \"|<tag(?:\\\"[^\\\"]*\\\"|'[^']*'|\\\\s[^'\\\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))\"\n  )\n    .replace(\"comment\", _comment)\n    .replace(\n      /tag/g,\n      \"(?!(?:\" +\n        \"a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub\" +\n        \"|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\" +\n        \"\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\"\n    )\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" *#{1,6} *[^\\n]\")\n    .replace(\"lheading\", lheading)\n    .replace(\"|table\", \"\")\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"|fences\", \"\")\n    .replace(\"|list\", \"\")\n    .replace(\"|html\", \"\")\n    .replace(\"|tag\", \"\")\n    .getRegex(),\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText =\n  /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = \"\\\\p{P}\\\\p{S}\";\nconst punctuation = edit(/^((?![*_])[\\spunctuation])/, \"u\")\n  .replace(/punctuation/g, _punctuation)\n  .getRegex();\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip =\n  /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelim = edit(\n  /^(?:\\*+(?:((?!\\*)[punct])|[^\\s*]))|^_+(?:((?!_)[punct])|([^\\s_]))/,\n  \"u\"\n)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst emStrongRDelimAst = edit(\n  \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)\" + // Skip orphan inside strong\n    \"|[^*]+(?=[^*])\" + // Consume to delim\n    \"|(?!\\\\*)[punct](\\\\*+)(?=[\\\\s]|$)\" + // (1) #*** can only be a Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?!\\\\*)(?=[punct\\\\s]|$)\" + // (2) a***#, a*** can only be a Right Delimiter\n    \"|(?!\\\\*)[punct\\\\s](\\\\*+)(?=[^punct\\\\s])\" + // (3) #***a, ***a can only be Left Delimiter\n    \"|[\\\\s](\\\\*+)(?!\\\\*)(?=[punct])\" + // (4) ***# can only be Left Delimiter\n    \"|(?!\\\\*)[punct](\\\\*+)(?!\\\\*)(?=[punct])\" + // (5) #***# can be either Left or Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?=[^punct\\\\s])\",\n  \"gu\"\n) // (6) a***a can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  \"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)\" + // Skip orphan inside strong\n    \"|[^_]+(?=[^_])\" + // Consume to delim\n    \"|(?!_)[punct](_+)(?=[\\\\s]|$)\" + // (1) #___ can only be a Right Delimiter\n    \"|[^punct\\\\s](_+)(?!_)(?=[punct\\\\s]|$)\" + // (2) a___#, a___ can only be a Right Delimiter\n    \"|(?!_)[punct\\\\s](_+)(?=[^punct\\\\s])\" + // (3) #___a, ___a can only be Left Delimiter\n    \"|[\\\\s](_+)(?!_)(?=[punct])\" + // (4) ___# can only be Left Delimiter\n    \"|(?!_)[punct](_+)(?!_)(?=[punct])\",\n  \"gu\"\n) // (5) #___# can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst anyPunctuation = edit(/\\\\([punct])/, \"gu\")\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace(\n    \"email\",\n    /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/\n  )\n  .getRegex();\nconst _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nconst tag = edit(\n  \"^comment\" +\n    \"|^</[a-zA-Z][\\\\w:-]*\\\\s*>\" + // self-closing tag\n    \"|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>\" + // open tag\n    \"|^<\\\\?[\\\\s\\\\S]*?\\\\?>\" + // processing instruction, e.g. <?php ?>\n    \"|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>\" + // declaration, e.g. <!DOCTYPE html>\n    \"|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\"\n) // CDATA section\n  .replace(\"comment\", _inlineComment)\n  .replace(\n    \"attribute\",\n    /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n  .replace(\n    \"title\",\n    /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/\n  )\n  .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\")\n  .replace(\"reflink\", reflink)\n  .replace(\"nolink\", nolink)\n  .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n  ...inlineNormal,\n  escape: edit(escape).replace(\"])\", \"~|])\").getRegex(),\n  url: edit(\n    /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n    \"i\"\n  )\n    .replace(\n      \"email\",\n      /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/\n    )\n    .getRegex(),\n  _backpedal:\n    /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text)\n    .replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\")\n    .replace(/\\{2,\\}/g, \"*\")\n    .getRegex(),\n};\n/**\n * exports\n */\nconst block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\nconst inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\n/**\n * Block Lexer\n */\nclass _Lexer {\n  tokens;\n  options;\n  state;\n  tokenizer;\n  inlineQueue;\n  constructor(options) {\n    // TokenList cannot be created in one go\n    this.tokens = [];\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n    const rules = {\n      block: block.normal,\n      inline: inline.normal,\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(/\\r\\n|\\r/g, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(/\\t/g, \"    \").replace(/^ +$/gm, \"\");\n    }\n    let token;\n    let lastToken;\n    let cutSrc;\n    while (src) {\n      if (\n        this.options.extensions &&\n        this.options.extensions.block &&\n        this.options.extensions.block.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // newline\n      if ((token = this.tokenizer.space(src))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.length === 1 && tokens.length > 0) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          tokens[tokens.length - 1].raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.code(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        // An indented code block cannot interrupt a paragraph.\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // fences\n      if ((token = this.tokenizer.fences(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // heading\n      if ((token = this.tokenizer.heading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // hr\n      if ((token = this.tokenizer.hr(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // blockquote\n      if ((token = this.tokenizer.blockquote(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // list\n      if ((token = this.tokenizer.list(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // html\n      if ((token = this.tokenizer.html(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // def\n      if ((token = this.tokenizer.def(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n      // table (gfm)\n      if ((token = this.tokenizer.table(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // lheading\n      if ((token = this.tokenizer.lheading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        lastToken = tokens[tokens.length - 1];\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      // text\n      if ((token = this.tokenizer.text(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let token, lastToken, cutSrc;\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match;\n    let keepPrevChar, prevChar;\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while (\n          (match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) !=\n          null\n        ) {\n          if (\n            links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))\n          ) {\n            maskedSrc =\n              maskedSrc.slice(0, match.index) +\n              \"[\" +\n              \"a\".repeat(match[0].length - 2) +\n              \"]\" +\n              maskedSrc.slice(\n                this.tokenizer.rules.inline.reflinkSearch.lastIndex\n              );\n          }\n        }\n      }\n    }\n    // Mask out other blocks\n    while (\n      (match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"[\" +\n        \"a\".repeat(match[0].length - 2) +\n        \"]\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    // Mask out escaped characters\n    while (\n      (match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) !=\n      null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"++\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      // extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.inline &&\n        this.options.extensions.inline.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // escape\n      if ((token = this.tokenizer.escape(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // tag\n      if ((token = this.tokenizer.tag(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // link\n      if ((token = this.tokenizer.link(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // reflink, nolink\n      if ((token = this.tokenizer.reflink(src, this.tokens.links))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // em & strong\n      if ((token = this.tokenizer.emStrong(src, maskedSrc, prevChar))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.codespan(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // br\n      if ((token = this.tokenizer.br(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // del (gfm)\n      if ((token = this.tokenizer.del(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // autolink\n      if ((token = this.tokenizer.autolink(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if ((token = this.tokenizer.inlineText(cutSrc))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n}\n\n/**\n * Renderer\n */\nclass _Renderer {\n  options;\n  parser; // set by the parser\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({ text, lang, escaped }) {\n    const langString = (lang || \"\").match(/^\\S*/)?.[0];\n    const code = text.replace(/\\n$/, \"\") + \"\\n\";\n    if (!langString) {\n      return (\n        \"<pre><code>\" +\n        (escaped ? code : escape$1(code, true)) +\n        \"</code></pre>\\n\"\n      );\n    }\n    return (\n      '<pre><code class=\"language-' +\n      escape$1(langString) +\n      '\">' +\n      (escaped ? code : escape$1(code, true)) +\n      \"</code></pre>\\n\"\n    );\n  }\n  blockquote({ tokens }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n  html({ text }) {\n    return text;\n  }\n  heading({ tokens, depth }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens.length > 0 && item.tokens[0].type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (\n            item.tokens[0].tokens &&\n            item.tokens[0].tokens.length > 0 &&\n            item.tokens[0].tokens[0].type === \"text\"\n          ) {\n            item.tokens[0].tokens[0].text =\n              checkbox + \" \" + item.tokens[0].tokens[0].text;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\\n`;\n  }\n  checkbox({ checked }) {\n    return (\n      \"<input \" +\n      (checked ? 'checked=\"\" ' : \"\") +\n      'disabled=\"\" type=\"checkbox\">'\n    );\n  }\n  paragraph({ tokens }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n  table(token) {\n    let header = \"\";\n    // header\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return (\n      \"<table>\\n\" + \"<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\"\n    );\n  }\n  tablerow({ text }) {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({ tokens }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({ tokens }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({ text }) {\n    return `<code>${text}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({ tokens }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({ href, title, tokens }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({ href, title, text }) {\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${title}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : token.text;\n  }\n}\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nclass _TextRenderer {\n  // no need for block level renderers\n  strong({ text }) {\n    return text;\n  }\n  em({ text }) {\n    return text;\n  }\n  codespan({ text }) {\n    return text;\n  }\n  del({ text }) {\n    return text;\n  }\n  html({ text }) {\n    return text;\n  }\n  text({ text }) {\n    return text;\n  }\n  link({ text }) {\n    return \"\" + text;\n  }\n  image({ text }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n}\n\n/**\n * Parsing & Compiling\n */\nclass _Parser {\n  options;\n  renderer;\n  textRenderer;\n  constructor(options) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call(\n          { parser: this },\n          genericToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"space\",\n            \"hr\",\n            \"heading\",\n            \"code\",\n            \"table\",\n            \"blockquote\",\n            \"list\",\n            \"html\",\n            \"paragraph\",\n            \"text\",\n          ].includes(genericToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\": {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case \"hr\": {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case \"heading\": {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case \"code\": {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case \"table\": {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case \"blockquote\": {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case \"list\": {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case \"html\": {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case \"paragraph\": {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case \"text\": {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n            textToken = tokens[++i];\n            body += \"\\n\" + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: \"paragraph\",\n              raw: body,\n              text: body,\n              tokens: [{ type: \"text\", raw: body, text: body }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer) {\n    renderer = renderer || this.renderer;\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const ret = this.options.extensions.renderers[anyToken.type].call(\n          { parser: this },\n          anyToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"escape\",\n            \"html\",\n            \"link\",\n            \"image\",\n            \"strong\",\n            \"em\",\n            \"codespan\",\n            \"br\",\n            \"del\",\n            \"text\",\n          ].includes(anyToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\": {\n          out += renderer.text(token);\n          break;\n        }\n        case \"html\": {\n          out += renderer.html(token);\n          break;\n        }\n        case \"link\": {\n          out += renderer.link(token);\n          break;\n        }\n        case \"image\": {\n          out += renderer.image(token);\n          break;\n        }\n        case \"strong\": {\n          out += renderer.strong(token);\n          break;\n        }\n        case \"em\": {\n          out += renderer.em(token);\n          break;\n        }\n        case \"codespan\": {\n          out += renderer.codespan(token);\n          break;\n        }\n        case \"br\": {\n          out += renderer.br(token);\n          break;\n        }\n        case \"del\": {\n          out += renderer.del(token);\n          break;\n        }\n        case \"text\": {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n\nclass _Hooks {\n  options;\n  block;\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  static passThroughHooks = new Set([\n    \"preprocess\",\n    \"postprocess\",\n    \"processAllTokens\",\n  ]);\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html) {\n    return html;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n\nclass Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n  constructor(...args) {\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\": {\n          const tableToken = token;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case \"list\": {\n          const listToken = token;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach(\n              (childTokens) => {\n                const tokens = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens, callback));\n              }\n            );\n          } else if (genericToken.tokens) {\n            values = values.concat(\n              this.walkTokens(genericToken.tokens, callback)\n            );\n          }\n        }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {},\n    };\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack };\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function (...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            // Tokenizer Extensions\n            if (\n              !ext.level ||\n              (ext.level !== \"block\" && ext.level !== \"inline\")\n            ) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              // Function to check for start of token\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer =\n          this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(\n                  (ret) => {\n                    return prevHook.call(hooks, ret);\n                  }\n                );\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = { ...this.defaults, ...opts };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n  lexer(src, options) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n  parser(tokens, options) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse = (src, options) => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(\n          new Error(\n            \"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"\n          )\n        );\n      }\n      // throw error in case of non string input\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(\n          new Error(\"marked(): input parameter is undefined or null\")\n        );\n      }\n      if (typeof src !== \"string\") {\n        return throwError(\n          new Error(\n            \"marked(): input parameter is of type \" +\n              Object.prototype.toString.call(src) +\n              \", string expected\"\n          )\n        );\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer = opt.hooks\n        ? opt.hooks.provideLexer()\n        : blockType\n          ? _Lexer.lex\n          : _Lexer.lexInline;\n      const parser = opt.hooks\n        ? opt.hooks.provideParser()\n        : blockType\n          ? _Parser.parse\n          : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then((src) => lexer(src, opt))\n          .then((tokens) =>\n            opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens\n          )\n          .then((tokens) =>\n            opt.walkTokens\n              ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(\n                  () => tokens\n                )\n              : tokens\n          )\n          .then((tokens) => parser(tokens, opt))\n          .then((html) => (opt.hooks ? opt.hooks.postprocess(html) : html))\n          .catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html);\n        }\n        return html;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse;\n  }\n  onError(silent, async) {\n    return (e) => {\n      e.message +=\n        \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg =\n          \"<p>An error occurred:</p><pre>\" +\n          escape$1(e.message + \"\", true) +\n          \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n\nconst markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options = marked.setOptions = function (options) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = _Parser.parse;\nconst lexer = _Lexer.lex;\n\nexport {\n  _Hooks as Hooks,\n  _Lexer as Lexer,\n  Marked,\n  _Parser as Parser,\n  _Renderer as Renderer,\n  _TextRenderer as TextRenderer,\n  _Tokenizer as Tokenizer,\n  _defaults as defaults,\n  _getDefaults as getDefaults,\n  lexer,\n  marked,\n  options,\n  parse,\n  parseInline,\n  parser,\n  setOptions,\n  use,\n  walkTokens,\n};\n//# sourceMappingURL=marked.esm.js.map\n",
      "metadata": {
        "title": "marked",
        "description": "",
        "runnable": false
      }
    },
    "unescape": {
      "code": "export { unescape };\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\nconst namedEntities = {\n    colon: \":\",\n    quot: '\"',\n    amp: \"&\",\n    lt: \"<\",\n    gt: \">\",\n    apos: \"'\",\n    // add more as needed\n};\nfunction unescape(html) {\n    return html.replace(unescapeTest, (_, n) => {\n        n = n.toLowerCase();\n        if (n in namedEntities)\n            return namedEntities[n];\n        if (n.charAt(0) === \"#\") {\n            const code = n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n            return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n        }\n        return \"\";\n    });\n}\n",
      "metadata": {
        "title": "unescape",
        "source": {
          "code": "export { unescape };\n\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\n\nconst namedEntities: Record<string, string> = {\n  colon: \":\",\n  quot: '\"',\n  amp: \"&\",\n  lt: \"<\",\n  gt: \">\",\n  apos: \"'\",\n  // add more as needed\n};\n\nfunction unescape(html: string): string {\n  return html.replace(unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n in namedEntities) return namedEntities[n];\n\n    if (n.charAt(0) === \"#\") {\n      const code =\n        n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n\n      return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n    }\n    return \"\";\n  });\n}\n",
          "language": "typescript"
        },
        "description": "",
        "runnable": false
      }
    },
    "api": {
      "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\nimport fetch, {} from \"@fetch\";\nimport secrets from \"@secrets\";\nimport { err, ok } from \"./a2/utils\";\nexport { connect, get, create, del, query, createMultipart, exp, getDoc, updateDoc, createPresentation, getPresentation, updatePresentation, createPermission, };\nconst connectionId = \"connection:$sign-in\";\nasync function get(token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply file id.\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"GET\");\n}\nasync function create(token, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the file to create.\");\n    }\n    return api(metadata, token, \"https://www.googleapis.com/drive/v3/files\", \"POST\", body);\n}\nasync function query(token, query, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!query) {\n        return err(\"Please supply the query.\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`, \"GET\");\n}\nasync function del(token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the file to delete\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"DELETE\");\n}\nasync function exp(token, fileId, mimeType, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!fileId) {\n        return err(\"Please supply the file id to export.\");\n    }\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${fileId}/export?mimeType=${mimeType}`, \"GET\");\n}\nasync function getDoc(token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the doc id to get.\");\n    }\n    return api(metadata, token, `https://docs.googleapis.com/v1/documents/${id}`, \"GET\");\n}\nasync function updateDoc(token, id, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the doc to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the doc update request.\");\n    }\n    return api(metadata, token, `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`, \"POST\", body);\n}\nasync function getPresentation(token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    return api(metadata, token, `https://slides.googleapis.com/v1/presentations/${id}`, \"GET\");\n}\nasync function createPresentation(token, title, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    return api(metadata, token, \"https://slides.googleapis.com/v1/presentations\", \"POST\", { title });\n}\nasync function updatePresentation(token, id, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the presentation to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the presentation update request.\");\n    }\n    return api(metadata, token, `https://slides.googleapis.com/v1/presentations/${id}:batchUpdate`, \"POST\", body);\n}\nasync function connect(metadata) {\n    const { [connectionId]: token } = await secrets({\n        ...meta(metadata),\n        keys: [connectionId],\n    });\n    return token;\n}\nasync function createMultipart(token, metadata, body, mimeType, $metadata) {\n    const boundary = \"BB-BB-BB-BB-BB-BB\";\n    const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n    const request = {\n        ...meta($metadata),\n        url,\n        method: \"POST\",\n        headers: {\n            Authorization: `Bearer ${token}`,\n            [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n        },\n        body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\nContent-Transfer-Encoding: base64\n\n${body}\n--${boundary}--`,\n    };\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n    }\n    return response;\n}\nasync function createPermission(token, fileId, permission, metadata) {\n    return api(metadata, token, `https://www.googleapis.com/drive/v3/files/${fileId}/permissions`, \"POST\", permission);\n}\nasync function api(metadata, token, url, method, body = null) {\n    const request = {\n        ...meta(metadata),\n        url,\n        method,\n        headers: {\n            Authorization: `Bearer ${token}`,\n        },\n    };\n    if (body) {\n        request.body = body;\n    }\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n    }\n    return response;\n}\nfunction meta({ title, description } = {}) {\n    if (!(title || description))\n        return {};\n    const $metadata = {};\n    if (title) {\n        $metadata.title = title;\n    }\n    if (description) {\n        $metadata.description = description;\n    }\n    return { $metadata };\n}\n",
      "metadata": {
        "title": "api",
        "source": {
          "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\n\nimport fetch, { type FetchInputs } from \"@fetch\";\nimport secrets from \"@secrets\";\n\nimport { err, ok } from \"./a2/utils\";\n\nexport {\n  connect,\n  get,\n  create,\n  del,\n  query,\n  createMultipart,\n  exp,\n  getDoc,\n  updateDoc,\n  createPresentation,\n  getPresentation,\n  updatePresentation,\n  createPermission,\n};\n\n// These are various Google Drive-specific types.\n\nexport type CreateFileResponse = {\n  id: string;\n};\n\nexport type FileQueryResponse = {\n  files: FileInfo[];\n};\n\nexport type FileInfo = {\n  id: string;\n};\n\n/**\n * A Google Slides presentation.\n */\nexport interface SlidesPresentation {\n  /**\n   * The layouts in the presentation. A layout is a template that determines how content is arranged and styled on the slides that inherit from that layout.\n   */\n  layouts?: SlidesPage[];\n  /**\n   * The locale of the presentation, as an IETF BCP 47 language tag.\n   */\n  locale?: string | null;\n  /**\n   * The slide masters in the presentation. A slide master contains all common page elements and the common properties for a set of layouts. They serve three purposes: - Placeholder shapes on a master contain the default text styles and shape properties of all placeholder shapes on pages that use that master. - The master page properties define the common page properties inherited by its layouts. - Any other shapes on the master slide appear on all slides using that master, regardless of their layout.\n   */\n  masters?: SlidesPage[];\n  /**\n   * The notes master in the presentation. It serves three purposes: - Placeholder shapes on a notes master contain the default text styles and shape properties of all placeholder shapes on notes pages. Specifically, a `SLIDE_IMAGE` placeholder shape contains the slide thumbnail, and a `BODY` placeholder shape contains the speaker notes. - The notes master page properties define the common page properties inherited by all notes pages. - Any other shapes on the notes master appear on all notes pages. The notes master is read-only.\n   */\n  notesMaster?: SlidesPage;\n  /**\n   * The size of pages in the presentation.\n   */\n  pageSize?: SlidesSize;\n  /**\n   * The ID of the presentation.\n   */\n  presentationId?: string | null;\n  /**\n   * Output only. The revision ID of the presentation. Can be used in update requests to assert the presentation revision hasn't changed since the last read operation. Only populated if the user has edit access to the presentation. The revision ID is not a sequential number but a nebulous string. The format of the revision ID may change over time, so it should be treated opaquely. A returned revision ID is only guaranteed to be valid for 24 hours after it has been returned and cannot be shared across users. If the revision ID is unchanged between calls, then the presentation has not changed. Conversely, a changed ID (for the same presentation and user) usually means the presentation has been updated. However, a changed ID can also be due to internal factors such as ID format changes.\n   */\n  revisionId?: string | null;\n  /**\n   * The slides in the presentation. A slide inherits properties from a slide layout.\n   */\n  slides?: SlidesPage[];\n  /**\n   * The title of the presentation.\n   */\n  title?: string | null;\n}\n\n/**\n * A width and height.\n */\nexport interface SlidesSize {\n  /**\n   * The height of the object.\n   */\n  height?: SlidesDimension;\n  /**\n   * The width of the object.\n   */\n  width?: SlidesDimension;\n}\n\n/**\n * A page in a presentation.\n */\nexport interface SlidesPage {\n  /**\n   * Layout specific properties. Only set if page_type = LAYOUT.\n   */\n  layoutProperties?: unknown; // Schema$LayoutProperties;\n  /**\n   * Master specific properties. Only set if page_type = MASTER.\n   */\n  masterProperties?: unknown; // Schema$MasterProperties;\n  /**\n   * Notes specific properties. Only set if page_type = NOTES.\n   */\n  notesProperties?: unknown; // Schema$NotesProperties;\n  /**\n   * The object ID for this page. Object IDs used by Page and PageElement share the same namespace.\n   */\n  objectId?: string | null;\n  /**\n   * The page elements rendered on the page.\n   */\n  pageElements?: unknown[]; // Schema$PageElement[];\n  /**\n   * The properties of the page.\n   */\n  pageProperties?: unknown; // Schema$PageProperties;\n  /**\n   * The type of the page.\n   */\n  pageType?: string | null;\n  /**\n   * Output only. The revision ID of the presentation. Can be used in update requests to assert the presentation revision hasn't changed since the last read operation. Only populated if the user has edit access to the presentation. The revision ID is not a sequential number but an opaque string. The format of the revision ID might change over time. A returned revision ID is only guaranteed to be valid for 24 hours after it has been returned and cannot be shared across users. If the revision ID is unchanged between calls, then the presentation has not changed. Conversely, a changed ID (for the same presentation and user) usually means the presentation has been updated. However, a changed ID can also be due to internal factors such as ID format changes.\n   */\n  revisionId?: string | null;\n  /**\n   * Slide specific properties. Only set if page_type = SLIDE.\n   */\n  slideProperties?: unknown; // Schema$SlideProperties;\n}\n\nexport type TextToSlideRequestsResult = {\n  requests: SlidesRequest[];\n  prevSlideId: number;\n};\n\nexport type SlidesDeleteObjectRequest = {\n  objectId: string;\n};\n\n/**\n * The placeholder information that uniquely identifies a placeholder shape.\n */\nexport type SlidesPlaceholder = {\n  /**\n   * The index of the placeholder. If the same placeholder types are present in the same page, they would have different index values.\n   */\n  index?: number | null;\n  /**\n   * The object ID of this shape's parent placeholder. If unset, the parent placeholder shape does not exist, so the shape does not inherit properties from any other shape.\n   */\n  parentObjectId?: string | null;\n  /**\n   * The type of the placeholder.\n   */\n  type?: string | null;\n};\n\nexport type SlidesTextRangeType =\n  // A fixed range. Both the startIndex and endIndex must be specified.\n  | \"FIXED_RANGE\"\n  // Starts the range at startIndex and continues until the end of the\n  // collection. The endIndex must not be specified.\n  | \"FROM_START_INDEX\"\n  | \"ALL\";\n\nexport type SlidesTextRange = {\n  startIndex?: number;\n  endIndex?: number;\n  type: SlidesTextRangeType;\n};\n\nexport type SlidesLayoutPlaceholderIdMapping = {\n  /**\n   * The placeholder on a layout that will be applied to a slide. Only type and index are needed. For example, a predefined `TITLE_AND_BODY` layout may usually have a TITLE placeholder with index 0 and a BODY placeholder with index 0.\n   */\n  layoutPlaceholder?: SlidesPlaceholder;\n  /**\n   * The object ID of the placeholder on a layout that will be applied to a slide.\n   */\n  layoutPlaceholderObjectId?: string | null;\n  /**\n   * A user-supplied object ID for the placeholder identified above that to be created onto a slide. If you specify an ID, it must be unique among all pages and page elements in the presentation. The ID must start with an alphanumeric character or an underscore (matches regex `[a-zA-Z0-9_]`); remaining characters may include those as well as a hyphen or colon (matches regex `[a-zA-Z0-9_-:]`). The length of the ID must not be less than 5 or greater than 50. If you don't specify an ID, a unique one is generated.\n   */\n  objectId?: string | null;\n};\n\n/**\n * A location of a single table cell within a table.\n */\nexport interface SlidesTableCellLocation {\n  /**\n   * The 0-based column index.\n   */\n  columnIndex?: number | null;\n  /**\n   * The 0-based row index.\n   */\n  rowIndex?: number | null;\n}\n\n/**\n * Inserts text into a shape or a table cell.\n */\nexport type SlidesInsertTextRequest = {\n  /**\n   * The optional table cell location if the text is to be inserted into a table cell. If present, the object_id must refer to a table.\n   */\n  cellLocation?: SlidesTableCellLocation;\n  /**\n   * The index where the text will be inserted, in Unicode code units, based on TextElement indexes. The index is zero-based and is computed from the start of the string. The index may be adjusted to prevent insertions inside Unicode grapheme clusters. In these cases, the text will be inserted immediately after the grapheme cluster.\n   */\n  insertionIndex?: number | null;\n  /**\n   * The object ID of the shape or table where the text will be inserted.\n   */\n  objectId?: string | null;\n  /**\n   * The text to be inserted. Inserting a newline character will implicitly create a new ParagraphMarker at that index. The paragraph style of the new paragraph will be copied from the paragraph at the current insertion index, including lists and bullets. Text styles for inserted text will be determined automatically, generally preserving the styling of neighboring text. In most cases, the text will be added to the TextRun that exists at the insertion index. Some control characters (U+0000-U+0008, U+000C-U+001F) and characters from the Unicode Basic Multilingual Plane Private Use Area (U+E000-U+F8FF) will be stripped out of the inserted text.\n   */\n  text?: string | null;\n};\n\nexport type SlidesCreateParagraphBulletsRequest = {\n  objectId: string | null;\n  textRange?: SlidesTextRange;\n};\n\n/**\n * Creates an image.\n */\nexport interface SlidesCreateImageRequest {\n  /**\n   * The element properties for the image. When the aspect ratio of the provided size does not match the image aspect ratio, the image is scaled and centered with respect to the size in order to maintain the aspect ratio. The provided transform is applied after this operation. The PageElementProperties.size property is optional. If you don't specify the size, the default size of the image is used. The PageElementProperties.transform property is optional. If you don't specify a transform, the image will be placed at the top-left corner of the page.\n   */\n  elementProperties?: SlidesPageElementProperties;\n  /**\n   * A user-supplied object ID. If you specify an ID, it must be unique among all pages and page elements in the presentation. The ID must start with an alphanumeric character or an underscore (matches regex `[a-zA-Z0-9_]`); remaining characters may include those as well as a hyphen or colon (matches regex `[a-zA-Z0-9_-:]`). The length of the ID must not be less than 5 or greater than 50. If you don't specify an ID, a unique one is generated.\n   */\n  objectId?: string | null;\n  /**\n   * The image URL. The image is fetched once at insertion time and a copy is stored for display inside the presentation. Images must be less than 50 MB in size, can't exceed 25 megapixels, and must be in one of PNG, JPEG, or GIF formats. The provided URL must be publicly accessible and up to 2 KB in length. The URL is saved with the image, and exposed through the Image.source_url field.\n   */\n  url?: string | null;\n}\n\n/**\n * Common properties for a page element. Note: When you initially create a PageElement, the API may modify the values of both `size` and `transform`, but the visual size will be unchanged.\n */\nexport interface SlidesPageElementProperties {\n  /**\n   * The object ID of the page where the element is located.\n   */\n  pageObjectId?: string | null;\n  /**\n   * The size of the element.\n   */\n  size?: SlidesSide;\n  /**\n   * The transform for the element.\n   */\n  transform?: SlidesAffineTransform;\n}\n\n/**\n * A width and height.\n */\nexport interface SlidesSide {\n  /**\n   * The height of the object.\n   */\n  height?: SlidesDimension;\n  /**\n   * The width of the object.\n   */\n  width?: SlidesDimension;\n}\n\n/**\n * A magnitude in a single direction in the specified units.\n */\nexport interface SlidesDimension {\n  /**\n   * The magnitude.\n   */\n  magnitude?: number | null;\n  /**\n   * The units for magnitude.\n   */\n  unit?: string | null;\n}\n\n/**\n * AffineTransform uses a 3x3 matrix with an implied last row of [ 0 0 1 ] to transform source coordinates (x,y) into destination coordinates (x', y') according to: x' x = shear_y scale_y translate_y 1 [ 1 ] After transformation, x' = scale_x * x + shear_x * y + translate_x; y' = scale_y * y + shear_y * x + translate_y; This message is therefore composed of these six matrix elements.\n */\nexport interface SlidesAffineTransform {\n  /**\n   * The X coordinate scaling element.\n   */\n  scaleX?: number | null;\n  /**\n   * The Y coordinate scaling element.\n   */\n  scaleY?: number | null;\n  /**\n   * The X coordinate shearing element.\n   */\n  shearX?: number | null;\n  /**\n   * The Y coordinate shearing element.\n   */\n  shearY?: number | null;\n  /**\n   * The X coordinate translation element.\n   */\n  translateX?: number | null;\n  /**\n   * The Y coordinate translation element.\n   */\n  translateY?: number | null;\n  /**\n   * The units for translate elements.\n   */\n  unit?: string | null;\n}\n\nexport type SlidesCreateSlideRequest = {\n  insertionIndex?: number;\n  objectId?: string;\n  slideLayoutReference: {\n    layoutId?: string;\n    predefinedLayout?: SlidesPredefinedLayout;\n  };\n  placeholderIdMappings: SlidesLayoutPlaceholderIdMapping[];\n};\n\n/**\n * The predefined layouts of a slide.\n */\nexport type SlidesPredefinedLayout =\n  /*\n   *\tUnspecified layout.\n   */\n  | \"PREDEFINED_LAYOUT_UNSPECIFIED\"\n\n  /*\n   * Blank layout with no placeholders.\n   */\n  | \"BLANK\"\n  /*\n   * Layout with a caption at the bottom.\n   */\n  | \"CAPTION_ONLY\"\n  /*\n   * Layout with a title and a subtitle.\n   */\n  | \"TITLE\"\n  /*\n   * Layout with a title and body.\n   */\n  | \"TITLE_AND_BODY\"\n  /*\n   * Layout with a title and two columns.\n   */\n  | \"TITLE_AND_TWO_COLUMNS\"\n  /*\n   * Layout with only a title\n   */\n  | \"TITLE_ONLY\"\n  /*\n   * Layout with a section title.\n   */\n  | \"SECTION_HEADER\"\n  /*\n   * Layout with a title and subtitle on one side and description on the other.\n   */\n  | \"SECTION_TITLE_AND_DESCRIPTION\"\n  /*\n   * Layout with one title and one body, arranged in a single column.\n   */\n  | \"ONE_COLUMN_TEXT\"\n  /*\n   * Layout with a main point.\n   */\n  | \"MAIN_POINT\"\n  /*\n   * Layout with a big number.\n   */\n  | \"BIG_NUMBER\";\n\n/**\n * Update the styling of text in a Shape or Table.\n */\nexport interface SlidesUpdateTextStyleRequest {\n  /**\n   * The location of the cell in the table containing the text to style. If `object_id` refers to a table, `cell_location` must have a value. Otherwise, it must not.\n   */\n  cellLocation?: SlidesTableCellLocation;\n  /**\n   * The fields that should be updated. At least one field must be specified. The root `style` is implied and should not be specified. A single `\"*\"` can be used as short-hand for listing every field. For example, to update the text style to bold, set `fields` to `\"bold\"`. To reset a property to its default value, include its field name in the field mask but leave the field itself unset.\n   */\n  fields?: string | null;\n  /**\n   * The object ID of the shape or table with the text to be styled.\n   */\n  objectId?: string | null;\n  /**\n   * The style(s) to set on the text. If the value for a particular style matches that of the parent, that style will be set to inherit. Certain text style changes may cause other changes meant to mirror the behavior of the Slides editor. See the documentation of TextStyle for more information.\n   */\n  style?: SlidesTextStyle;\n  /**\n   * The range of text to style. The range may be extended to include adjacent newlines. If the range fully contains a paragraph belonging to a list, the paragraph's bullet is also updated with the matching text style.\n   */\n  textRange?: SlidesRange;\n}\n\n/**\n * Represents the styling that can be applied to a TextRun. If this text is contained in a shape with a parent placeholder, then these text styles may be inherited from the parent. Which text styles are inherited depend on the nesting level of lists: * A text run in a paragraph that is not in a list will inherit its text style from the the newline character in the paragraph at the 0 nesting level of the list inside the parent placeholder. * A text run in a paragraph that is in a list will inherit its text style from the newline character in the paragraph at its corresponding nesting level of the list inside the parent placeholder. Inherited text styles are represented as unset fields in this message. If text is contained in a shape without a parent placeholder, unsetting these fields will revert the style to a value matching the defaults in the Slides editor.\n */\nexport interface SlidesTextStyle {\n  /**\n   * The background color of the text. If set, the color is either opaque or transparent, depending on if the `opaque_color` field in it is set.\n   */\n  backgroundColor?: SlidesOptionalColor;\n  /**\n   * The text's vertical offset from its normal position. Text with `SUPERSCRIPT` or `SUBSCRIPT` baseline offsets is automatically rendered in a smaller font size, computed based on the `font_size` field. The `font_size` itself is not affected by changes in this field.\n   */\n  baselineOffset?: string | null;\n  /**\n   * Whether or not the text is rendered as bold.\n   */\n  bold?: boolean | null;\n  /**\n   * The font family of the text. The font family can be any font from the Font menu in Slides or from [Google Fonts] (https://fonts.google.com/). If the font name is unrecognized, the text is rendered in `Arial`. Some fonts can affect the weight of the text. If an update request specifies values for both `font_family` and `bold`, the explicitly-set `bold` value is used.\n   */\n  fontFamily?: string | null;\n  /**\n   * The size of the text's font. When read, the `font_size` will specified in points.\n   */\n  fontSize?: SlidesDimension;\n  /**\n   * The color of the text itself. If set, the color is either opaque or transparent, depending on if the `opaque_color` field in it is set.\n   */\n  foregroundColor?: SlidesOptionalColor;\n  /**\n   * Whether or not the text is italicized.\n   */\n  italic?: boolean | null;\n  /**\n   * The hyperlink destination of the text. If unset, there is no link. Links are not inherited from parent text. Changing the link in an update request causes some other changes to the text style of the range: * When setting a link, the text foreground color will be set to ThemeColorType.HYPERLINK and the text will be underlined. If these fields are modified in the same request, those values will be used instead of the link defaults. * Setting a link on a text range that overlaps with an existing link will also update the existing link to point to the new URL. * Links are not settable on newline characters. As a result, setting a link on a text range that crosses a paragraph boundary, such as `\"ABC\\n123\"`, will separate the newline character(s) into their own text runs. The link will be applied separately to the runs before and after the newline. * Removing a link will update the text style of the range to match the style of the preceding text (or the default text styles if the preceding text is another link) unless different styles are being set in the same request.\n   */\n  link?: SlidesLink;\n  /**\n   * Whether or not the text is in small capital letters.\n   */\n  smallCaps?: boolean | null;\n  /**\n   * Whether or not the text is struck through.\n   */\n  strikethrough?: boolean | null;\n  /**\n   * Whether or not the text is underlined.\n   */\n  underline?: boolean | null;\n  /**\n   * The font family and rendered weight of the text. This field is an extension of `font_family` meant to support explicit font weights without breaking backwards compatibility. As such, when reading the style of a range of text, the value of `weighted_font_family#font_family` will always be equal to that of `font_family`. However, when writing, if both fields are included in the field mask (either explicitly or through the wildcard `\"*\"`), their values are reconciled as follows: * If `font_family` is set and `weighted_font_family` is not, the value of `font_family` is applied with weight `400` (\"normal\"). * If both fields are set, the value of `font_family` must match that of `weighted_font_family#font_family`. If so, the font family and weight of `weighted_font_family` is applied. Otherwise, a 400 bad request error is returned. * If `weighted_font_family` is set and `font_family` is not, the font family and weight of `weighted_font_family` is applied. * If neither field is set, the font family and weight of the text inherit from the parent. Note that these properties cannot inherit separately from each other. If an update request specifies values for both `weighted_font_family` and `bold`, the `weighted_font_family` is applied first, then `bold`. If `weighted_font_family#weight` is not set, it defaults to `400`. If `weighted_font_family` is set, then `weighted_font_family#font_family` must also be set with a non-empty value. Otherwise, a 400 bad request error is returned.\n   */\n  weightedFontFamily?: SlidesWeightedFontFamily;\n}\n\n/**\n * Represents a font family and weight used to style a TextRun.\n */\nexport interface SlidesWeightedFontFamily {\n  /**\n   * The font family of the text. The font family can be any font from the Font menu in Slides or from [Google Fonts] (https://fonts.google.com/). If the font name is unrecognized, the text is rendered in `Arial`.\n   */\n  fontFamily?: string | null;\n  /**\n   * The rendered weight of the text. This field can have any value that is a multiple of `100` between `100` and `900`, inclusive. This range corresponds to the numerical values described in the CSS 2.1 Specification, [section 15.6](https://www.w3.org/TR/CSS21/fonts.html#font-boldness), with non-numerical values disallowed. Weights greater than or equal to `700` are considered bold, and weights less than `700`are not bold. The default value is `400` (\"normal\").\n   */\n  weight?: number | null;\n}\n\n/**\n * A hypertext link.\n */\nexport interface SlidesLink {\n  /**\n   * If set, indicates this is a link to the specific page in this presentation with this ID. A page with this ID may not exist.\n   */\n  pageObjectId?: string | null;\n  /**\n   * If set, indicates this is a link to a slide in this presentation, addressed by its position.\n   */\n  relativeLink?: string | null;\n  /**\n   * If set, indicates this is a link to the slide at this zero-based index in the presentation. There may not be a slide at this index.\n   */\n  slideIndex?: number | null;\n  /**\n   * If set, indicates this is a link to the external web page at this URL.\n   */\n  url?: string | null;\n}\n/**\n * A color that can either be fully opaque or fully transparent.\n */\nexport interface SlidesOptionalColor {\n  /**\n   * If set, this will be used as an opaque color. If unset, this represents a transparent color.\n   */\n  opaqueColor?: SlidesOpaqueColor;\n}\n/**\n * The outline of a PageElement. If these fields are unset, they may be inherited from a parent placeholder if it exists. If there is no parent, the fields will default to the value used for new page elements created in the Slides editor, which may depend on the page element kind.\n */\nexport interface Schema$Outline {\n  /**\n   * The dash style of the outline.\n   */\n  dashStyle?: string | null;\n  /**\n   * The fill of the outline.\n   */\n  outlineFill?: SlidesOutlineFill;\n  /**\n   * The outline property state. Updating the outline on a page element will implicitly update this field to `RENDERED`, unless another value is specified in the same request. To have no outline on a page element, set this field to `NOT_RENDERED`. In this case, any other outline fields set in the same request will be ignored.\n   */\n  propertyState?: string | null;\n  /**\n   * The thickness of the outline.\n   */\n  weight?: SlidesDimension;\n}\n\n/**\n * The fill of the outline.\n */\nexport interface SlidesOutlineFill {\n  /**\n   * Solid color fill.\n   */\n  solidFill?: SlidesSolidFill;\n}\n\n/**\n * A solid color fill. The page or page element is filled entirely with the specified color value. If any field is unset, its value may be inherited from a parent placeholder if it exists.\n */\nexport interface SlidesSolidFill {\n  /**\n   * The fraction of this `color` that should be applied to the pixel. That is, the final pixel color is defined by the equation: pixel color = alpha * (color) + (1.0 - alpha) * (background color) This means that a value of 1.0 corresponds to a solid color, whereas a value of 0.0 corresponds to a completely transparent color.\n   */\n  alpha?: number | null;\n  /**\n   * The color value of the solid fill.\n   */\n  color?: SlidesOpaqueColor;\n}\n\n/**\n * A themeable solid color value.\n */\nexport interface SlidesOpaqueColor {\n  /**\n   * An opaque RGB color.\n   */\n  rgbColor?: SlidesRgbColor;\n  /**\n   * An opaque theme color.\n   */\n  themeColor?: string | null;\n}\n\n/**\n * An RGB color.\n */\nexport interface SlidesRgbColor {\n  /**\n   * The blue component of the color, from 0.0 to 1.0.\n   */\n  blue?: number | null;\n  /**\n   * The green component of the color, from 0.0 to 1.0.\n   */\n  green?: number | null;\n  /**\n   * The red component of the color, from 0.0 to 1.0.\n   */\n  red?: number | null;\n}\n/**\n * Specifies a contiguous range of an indexed collection, such as characters in text.\n */\nexport interface SlidesRange {\n  /**\n   * The optional zero-based index of the end of the collection. Required for `FIXED_RANGE` ranges.\n   */\n  endIndex?: number | null;\n  /**\n   * The optional zero-based index of the beginning of the collection. Required for `FIXED_RANGE` and `FROM_START_INDEX` ranges.\n   */\n  startIndex?: number | null;\n  /**\n   * The type of range.\n   */\n  type?: string | null;\n}\n\nexport type SlidesRequest =\n  | { deleteObject: SlidesDeleteObjectRequest }\n  | { createSlide: SlidesCreateSlideRequest }\n  | { insertText: SlidesInsertTextRequest }\n  | { createParagraphBullets: SlidesCreateParagraphBulletsRequest }\n  | { createImage: SlidesCreateImageRequest }\n  | { updateTextStyle: SlidesUpdateTextStyleRequest };\n\nconst connectionId = \"connection:$sign-in\";\n\nexport type Metadata = {\n  title?: string;\n  description?: string;\n};\n\nexport type Method = \"GET\" | \"POST\" | \"PUT\" | \"DELETE\";\n\nasync function get(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return err(\"Please supply file id.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"GET\"\n  );\n}\n\nasync function create(\n  token: string,\n  body: unknown,\n  metadata: Metadata\n): Promise<Outcome<CreateFileResponse>> {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!body) {\n    return err(\"Please supply the body of the file to create.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    \"https://www.googleapis.com/drive/v3/files\",\n    \"POST\",\n    body\n  );\n}\n\nasync function query(\n  token: string,\n  query: string,\n  metadata: Metadata\n): Promise<Outcome<FileQueryResponse>> {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!query) {\n    return err(\"Please supply the query.\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`,\n    \"GET\"\n  );\n}\n\nasync function del(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return err(\"Please supply the id of the file to delete\");\n  }\n\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${id}`,\n    \"DELETE\"\n  );\n}\n\nasync function exp(\n  token: string,\n  fileId: string,\n  mimeType: string,\n  metadata: Metadata\n) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!fileId) {\n    return err(\"Please supply the file id to export.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${fileId}/export?mimeType=${mimeType}`,\n    \"GET\"\n  );\n}\n\nasync function getDoc(token: string, id: string, metadata: Metadata) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return err(\"Please supply the doc id to get.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}`,\n    \"GET\"\n  );\n}\n\nasync function updateDoc(\n  token: string,\n  id: string,\n  body: unknown,\n  metadata: Metadata\n) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return err(\"Please supply the id of the doc to update.\");\n  }\n  if (!body) {\n    return err(\"Please supply the body of the doc update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function getPresentation(\n  token: string,\n  id: string,\n  metadata: Metadata\n): Promise<Outcome<SlidesPresentation>> {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://slides.googleapis.com/v1/presentations/${id}`,\n    \"GET\"\n  );\n}\n\nasync function createPresentation(\n  token: string,\n  title: string,\n  metadata: Metadata\n): Promise<Outcome<{ presentationId: string }>> {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  return api(\n    metadata,\n    token,\n    \"https://slides.googleapis.com/v1/presentations\",\n    \"POST\",\n    { title }\n  );\n}\n\nasync function updatePresentation(\n  token: string,\n  id: string,\n  body: { requests: SlidesRequest[] },\n  metadata: Metadata\n) {\n  if (!token) {\n    return err(\"Authentication token is required.\");\n  }\n  if (!id) {\n    return err(\"Please supply the id of the presentation to update.\");\n  }\n  if (!body) {\n    return err(\"Please supply the body of the presentation update request.\");\n  }\n  return api(\n    metadata,\n    token,\n    `https://slides.googleapis.com/v1/presentations/${id}:batchUpdate`,\n    \"POST\",\n    body\n  );\n}\n\nasync function connect(metadata: Metadata) {\n  const { [connectionId]: token } = await secrets({\n    ...meta(metadata),\n    keys: [connectionId],\n  });\n  return token;\n}\n\nasync function createMultipart(\n  token: string,\n  metadata: unknown,\n  body: unknown,\n  mimeType: string,\n  $metadata: Metadata\n): Promise<Outcome<{ id: string }>> {\n  const boundary = \"BB-BB-BB-BB-BB-BB\";\n  const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n  const request: FetchInputs = {\n    ...meta($metadata),\n    url,\n    method: \"POST\",\n    headers: {\n      Authorization: `Bearer ${token}`,\n      [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n    },\n    body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\nContent-Transfer-Encoding: base64\n\n${body}\n--${boundary}--`,\n  };\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n  }\n  return response as { id: string };\n}\n\nexport type Permission = {\n  id?: string;\n  displayName?: string;\n  type?: string;\n  kind?: string;\n  permissionDetails?: [\n    {\n      permissionType?: string;\n      inheritedFrom?: string;\n      role?: string;\n      inherited?: boolean;\n    },\n  ];\n  photoLink?: string;\n  emailAddress?: string;\n  role?: string;\n  allowFileDiscovery?: boolean;\n  domain?: string;\n  expirationTime?: string;\n  teamDrivePermissionDetails?: [\n    {\n      teamDrivePermissionType: string;\n      inheritedFrom: string;\n      role: string;\n      inherited: boolean;\n    },\n  ];\n  deleted?: boolean;\n  view?: string;\n  pendingOwner?: boolean;\n};\n\nasync function createPermission(\n  token: string,\n  fileId: string,\n  permission: Permission,\n  metadata: Metadata\n): Promise<Outcome<Permission>> {\n  return api(\n    metadata,\n    token,\n    `https://www.googleapis.com/drive/v3/files/${fileId}/permissions`,\n    \"POST\",\n    permission\n  );\n}\n\nasync function api<T>(\n  metadata: Metadata,\n  token: string,\n  url: string,\n  method: Method,\n  body: unknown | null = null\n): Promise<Outcome<T>> {\n  const request: FetchInputs = {\n    ...meta(metadata),\n    url,\n    method,\n    headers: {\n      Authorization: `Bearer ${token}`,\n    },\n  };\n  if (body) {\n    request.body = body;\n  }\n  const { response, $error } = await fetch(request);\n  if ($error) {\n    return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n  }\n  return response as T;\n}\n\nfunction meta({ title, description }: Metadata = {}) {\n  if (!(title || description)) return {};\n  const $metadata: Metadata = {};\n  if (title) {\n    $metadata.title = title;\n  }\n  if (description) {\n    $metadata.description = description;\n  }\n  return { $metadata };\n}\n",
          "language": "typescript"
        },
        "description": "",
        "runnable": false
      }
    },
    "slides": {
      "code": "/**\n * @fileoverview Slides bits.\n */\nimport { unescape } from \"./unescape\";\nimport { marked } from \"./marked\";\nexport { SlideBuilder, slidesToRequests };\nclass SlideBuilder {\n    #slides = [];\n    #images = [];\n    #startIndex;\n    #objectToDelete;\n    #depthAdjustment = 0;\n    constructor(startIndex = 0, objectId) {\n        this.#startIndex = startIndex;\n        this.#objectToDelete = objectId;\n        this.#newSlide();\n    }\n    addMarkdown(markdown) {\n        let bodyText = this.#getBodyText();\n        if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n            this.#newSlide();\n        }\n        const tokens = marked.lexer(markdown);\n        tokens.forEach((token) => this.#addToken(token));\n    }\n    #hasContent() { }\n    addInlineData(data) {\n        let bodyText = this.#getBodyText();\n        if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n            this.#newSlide();\n            bodyText = this.#getBodyText();\n        }\n        bodyText.images ??= [];\n        bodyText.images.push(this.#addImage({\n            type: \"image\",\n            href: `data:${data.mimeType};base64,${data.data}`,\n        }));\n    }\n    #addToken(token) {\n        const { type } = token;\n        switch (type) {\n            case \"hr\":\n                this.#newSlide();\n                break;\n            case \"paragraph\":\n                this.#newParagraph(token.tokens);\n                break;\n            case \"heading\":\n                this.#newHeading(token);\n                break;\n            case \"list\":\n                this.#addListToBody(token);\n                break;\n        }\n    }\n    images() {\n        return this.#images;\n    }\n    build(imageUrls) {\n        this.#finalizeSlide();\n        console.log(\"SLIDES\", this.#slides);\n        const requests = slidesToRequests(this.#slides, imageUrls);\n        if (this.#objectToDelete) {\n            requests.unshift({\n                deleteObject: {\n                    objectId: this.#objectToDelete,\n                },\n            });\n        }\n        return requests;\n    }\n    get #slide() {\n        return this.#slides.at(-1);\n    }\n    #newHeading(token) {\n        if (token.depth === 1) {\n            this.#slide.title = this.#parseText(token.tokens);\n        }\n        else {\n            this.#slide.subtitle = this.#parseText(token.tokens);\n        }\n    }\n    #newParagraph(tokens) {\n        const bodyText = this.#getBodyText();\n        const offset = bodyText.text.length - this.#depthAdjustment;\n        const { text, styles, lists, images = [], } = this.#parseText(tokens, offset);\n        bodyText.text += text;\n        bodyText.styles.push(...styles);\n        bodyText.lists.push(...lists);\n        bodyText.images ??= [];\n        bodyText.images.push(...images);\n    }\n    #getBodyText() {\n        const slide = this.#slide;\n        if (!slide.body.length) {\n            slide.body.push({\n                text: { text: \"\", styles: [], lists: [] },\n            });\n        }\n        const body = slide.body.at(-1);\n        if (!body.text) {\n            body.text = { text: \"\", styles: [], lists: [] };\n        }\n        return body.text;\n    }\n    #addListToBody(token) {\n        const slide = this.#slide;\n        const { ordered, items } = token;\n        let bulletedText = \"\";\n        const bodyText = this.#getBodyText();\n        let listOffset = bodyText.text.length;\n        let length = 0;\n        let localOffset = listOffset;\n        const addListItems = (depth, items) => {\n            items.forEach((item) => {\n                const [textToken, listToken] = item.tokens;\n                const { text, styles } = this.#parseText(textToken.tokens, localOffset);\n                bodyText.text += `${\"\\t\".repeat(depth)}${text}`;\n                this.#depthAdjustment += depth;\n                localOffset += text.length;\n                length += text.length;\n                bodyText.styles.push(...styles);\n                if (listToken) {\n                    addListItems(depth + 1, listToken.items);\n                }\n            });\n        };\n        addListItems(0, items);\n        bodyText.lists.push({ start: listOffset, end: listOffset + length });\n    }\n    #parseText(tokens, current = 0) {\n        let text = \"\";\n        const styles = [];\n        const images = [];\n        tokens.forEach((token) => {\n            if (token.type === \"image\") {\n                images.push(this.#addImage(token));\n                return;\n            }\n            const { type, text: t } = token;\n            const length = t.length;\n            text += unescape(t);\n            const range = { start: current, end: current + length };\n            switch (type) {\n                case \"strong\":\n                    styles.push({ range, bold: true });\n                    break;\n                case \"em\":\n                    styles.push({ range, italic: true });\n                    break;\n                case \"del\":\n                    styles.push({ range, strikethrough: true });\n                    break;\n                case \"link\":\n                    styles.push({ range, link: token.href });\n                    break;\n            }\n            current += length;\n        });\n        return { text: `${text}\\n`, styles, lists: [], images };\n    }\n    #finalizeSlide() {\n        const slide = this.#slide;\n        if (!slide)\n            return;\n        const hasText = !!slide.body?.at(0)?.text?.text;\n        const hasImages = !!slide.body?.at(0)?.text?.images?.length;\n        if (slide.subtitle && !hasText) {\n            slide.layout = \"TITLE\";\n        }\n        else if (hasText) {\n            slide.layout = \"TITLE_AND_BODY\";\n            delete slide.subtitle;\n        }\n        else if (!hasImages) {\n            slide.layout = \"MAIN_POINT\";\n            slide.body = [];\n        }\n        this.#depthAdjustment = 0;\n    }\n    #newSlide() {\n        this.#finalizeSlide();\n        this.#slides.push({\n            objectId: `Slide-${this.#startIndex + this.#slides.length}`,\n            layout: \"BLANK\",\n            body: [],\n        });\n    }\n    #addImage(token) {\n        const id = this.#images.length;\n        this.#images.push(token);\n        return id;\n    }\n}\nfunction slidesToRequests(slides, imageUrls) {\n    const requests = [];\n    slides.forEach((slide) => {\n        const request = {\n            objectId: slide.objectId,\n            slideLayoutReference: { predefinedLayout: slide.layout },\n            placeholderIdMappings: mapPlaceholders(slide.objectId, slide.layout),\n        };\n        requests.push({ createSlide: request });\n        if (slide.title) {\n            requests.push({\n                insertText: {\n                    text: slide.title.text,\n                    objectId: `${slide.objectId}-title`,\n                },\n            });\n        }\n        if (slide.subtitle) {\n            requests.push({\n                insertText: {\n                    text: slide.subtitle.text,\n                    objectId: `${slide.objectId}-subtitle`,\n                },\n            });\n        }\n        slide.body.forEach((body) => {\n            const bodyText = body.text;\n            if (!bodyText)\n                return;\n            if (bodyText.images?.length) {\n                requests.push({\n                    createImage: {\n                        url: imageUrls[bodyText.images[0]],\n                        elementProperties: {\n                            pageObjectId: slide.objectId,\n                        },\n                    },\n                });\n            }\n            else if (bodyText.text) {\n                const objectId = `${slide.objectId}-body`;\n                requests.push({\n                    insertText: { text: bodyText.text, objectId },\n                });\n                bodyText.lists.forEach((list) => {\n                    requests.push({\n                        createParagraphBullets: {\n                            objectId,\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: list.start,\n                                endIndex: list.end,\n                            },\n                        },\n                    });\n                });\n                bodyText.styles.forEach((style) => {\n                    requests.push({\n                        updateTextStyle: {\n                            objectId,\n                            ...getTextStyle(style),\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: style.range.start,\n                                endIndex: style.range.end,\n                            },\n                        },\n                    });\n                });\n            }\n        });\n    });\n    return requests;\n}\nfunction getTextStyle(style) {\n    const { link: url, range: _, ...rest } = style;\n    const linkStyle = url ? { link: { url } } : {};\n    const fields = Object.keys(rest);\n    if (url)\n        fields.push(\"link\");\n    return { style: { ...linkStyle, ...rest }, fields: fields.join(\",\") };\n}\nfunction mapPlaceholders(slideId, layout) {\n    const mappings = [];\n    switch (layout) {\n        case \"TITLE\":\n            mappings.push({\n                layoutPlaceholder: { type: \"CENTERED_TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"SUBTITLE\", index: 0 },\n                objectId: `${slideId}-subtitle`,\n            });\n            break;\n        case \"TITLE_AND_BODY\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"BODY\", index: 0 },\n                objectId: `${slideId}-body`,\n            });\n            break;\n        case \"MAIN_POINT\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            break;\n    }\n    return mappings;\n}\n",
      "metadata": {
        "title": "slides",
        "source": {
          "code": "/**\n * @fileoverview Slides bits.\n */\n\nimport type {\n  SlidesRequest,\n  SlidesPredefinedLayout,\n  SlidesCreateSlideRequest,\n  SlidesInsertTextRequest,\n  SlidesUpdateTextStyleRequest,\n  SlidesLayoutPlaceholderIdMapping,\n  SlidesTextStyle,\n} from \"./api\";\nimport type {\n  Token,\n  ImageToken,\n  FormattingToken,\n  ListToken,\n  HeadingToken,\n  ListItemToken,\n} from \"./types\";\nimport { unescape } from \"./unescape\";\nimport { marked } from \"./marked\";\n\nexport { SlideBuilder, slidesToRequests };\n\n// Slide Structure:\n// - Slide contains optional title, bodies, and text\n// - Text is string with styles and lists\n// - Style is various style flags + range\n// - Body is text and or images\n\nexport type Slide = {\n  objectId: string;\n  layout: SlidesPredefinedLayout;\n  title?: SlideText;\n  subtitle?: SlideText;\n  body: SlideBody[];\n};\n\nexport type SlideText = {\n  text: string;\n  styles: SlideStyle[];\n  lists: SlideRange[];\n  images?: number[];\n};\n\nexport type SlideRange = {\n  start: number;\n  end: number;\n};\n\nexport type SlideStyle = {\n  range: SlideRange;\n  bold?: boolean;\n  italic?: boolean;\n  link?: string;\n  underline?: boolean;\n  strikethrough?: boolean;\n};\n\nexport type SlideBody = {\n  text?: SlideText;\n};\n\nclass SlideBuilder {\n  #slides: Slide[] = [];\n  #images: ImageToken[] = [];\n\n  readonly #startIndex: number;\n  readonly #objectToDelete: string | undefined;\n  #depthAdjustment: number = 0;\n\n  constructor(startIndex: number = 0, objectId?: string) {\n    this.#startIndex = startIndex;\n    this.#objectToDelete = objectId;\n    this.#newSlide();\n  }\n\n  addMarkdown(markdown: string) {\n    let bodyText = this.#getBodyText();\n    if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n      this.#newSlide();\n    }\n    const tokens = marked.lexer(markdown) as Token[];\n    tokens.forEach((token) => this.#addToken(token));\n  }\n\n  #hasContent() {}\n\n  addInlineData(data: InlineDataCapabilityPart[\"inlineData\"]) {\n    let bodyText = this.#getBodyText();\n    if (this.#slide.title || bodyText.text || bodyText.images?.length) {\n      this.#newSlide();\n      bodyText = this.#getBodyText();\n    }\n    bodyText.images ??= [];\n    bodyText.images.push(\n      this.#addImage({\n        type: \"image\",\n        href: `data:${data.mimeType};base64,${data.data}`,\n      } as ImageToken)\n    );\n  }\n\n  #addToken(token: Token) {\n    const { type } = token;\n    switch (type) {\n      case \"hr\":\n        this.#newSlide();\n        break;\n      case \"paragraph\":\n        this.#newParagraph(token.tokens);\n        break;\n      case \"heading\":\n        this.#newHeading(token);\n        break;\n      case \"list\":\n        this.#addListToBody(token);\n        break;\n    }\n  }\n\n  images() {\n    return this.#images;\n  }\n\n  build(imageUrls: string[]) {\n    this.#finalizeSlide();\n    console.log(\"SLIDES\", this.#slides);\n    const requests = slidesToRequests(this.#slides, imageUrls);\n    if (this.#objectToDelete) {\n      requests.unshift({\n        deleteObject: {\n          objectId: this.#objectToDelete,\n        },\n      });\n    }\n    return requests;\n  }\n\n  get #slide(): Slide {\n    return this.#slides.at(-1)!;\n  }\n\n  #newHeading(token: HeadingToken) {\n    if (token.depth === 1) {\n      this.#slide.title = this.#parseText(token.tokens);\n    } else {\n      this.#slide.subtitle = this.#parseText(token.tokens);\n    }\n  }\n\n  #newParagraph(tokens: FormattingToken[]) {\n    const bodyText = this.#getBodyText();\n    const offset = bodyText.text.length - this.#depthAdjustment;\n    const {\n      text,\n      styles,\n      lists,\n      images = [],\n    } = this.#parseText(tokens, offset);\n    bodyText.text += text;\n    bodyText.styles.push(...styles);\n    bodyText.lists.push(...lists);\n    bodyText.images ??= [];\n    bodyText.images.push(...images);\n  }\n\n  #getBodyText() {\n    const slide = this.#slide;\n    if (!slide.body.length) {\n      slide.body.push({\n        text: { text: \"\", styles: [], lists: [] },\n      });\n    }\n    const body = slide.body.at(-1)!;\n    if (!body.text) {\n      body.text = { text: \"\", styles: [], lists: [] };\n    }\n    return body.text;\n  }\n\n  #addListToBody(token: ListToken) {\n    const slide = this.#slide;\n    const { ordered, items } = token;\n    let bulletedText = \"\";\n    const bodyText = this.#getBodyText();\n    let listOffset = bodyText.text.length;\n    let length = 0;\n    let localOffset = listOffset;\n    const addListItems = (depth: number, items: ListItemToken[]) => {\n      items.forEach((item) => {\n        const [textToken, listToken] = item.tokens;\n        const { text, styles } = this.#parseText(textToken.tokens, localOffset);\n        bodyText.text += `${\"\\t\".repeat(depth)}${text}`;\n        this.#depthAdjustment += depth;\n        localOffset += text.length;\n        length += text.length;\n        bodyText.styles.push(...styles);\n        if (listToken) {\n          addListItems(depth + 1, listToken.items);\n        }\n      });\n    };\n    addListItems(0, items);\n    bodyText.lists.push({ start: listOffset, end: listOffset + length });\n  }\n\n  #parseText(tokens: FormattingToken[], current = 0): SlideText {\n    let text = \"\";\n    const styles: SlideStyle[] = [];\n    const images: number[] = [];\n    tokens.forEach((token) => {\n      if (token.type === \"image\") {\n        images.push(this.#addImage(token));\n        return;\n      }\n      const { type, text: t } = token;\n      const length = t.length;\n      text += unescape(t);\n      const range = { start: current, end: current + length };\n      switch (type) {\n        case \"strong\":\n          styles.push({ range, bold: true });\n          break;\n        case \"em\":\n          styles.push({ range, italic: true });\n          break;\n        case \"del\":\n          styles.push({ range, strikethrough: true });\n          break;\n        case \"link\":\n          styles.push({ range, link: token.href });\n          break;\n      }\n      current += length;\n    });\n    return { text: `${text}\\n`, styles, lists: [], images };\n  }\n\n  #finalizeSlide() {\n    const slide = this.#slide;\n    if (!slide) return;\n    const hasText = !!slide.body?.at(0)?.text?.text;\n    const hasImages = !!slide.body?.at(0)?.text?.images?.length;\n    if (slide.subtitle && !hasText) {\n      slide.layout = \"TITLE\";\n    } else if (hasText) {\n      slide.layout = \"TITLE_AND_BODY\";\n      delete slide.subtitle;\n    } else if (!hasImages) {\n      slide.layout = \"MAIN_POINT\";\n      slide.body = [];\n    }\n    this.#depthAdjustment = 0;\n  }\n\n  #newSlide() {\n    this.#finalizeSlide();\n    this.#slides.push({\n      objectId: `Slide-${this.#startIndex + this.#slides.length}`,\n      layout: \"BLANK\",\n      body: [],\n    });\n  }\n\n  #addImage(token: ImageToken) {\n    const id = this.#images.length;\n    this.#images.push(token);\n    return id;\n  }\n}\n\nfunction slidesToRequests(\n  slides: Slide[],\n  imageUrls: string[]\n): SlidesRequest[] {\n  const requests: SlidesRequest[] = [];\n  slides.forEach((slide) => {\n    const request: SlidesCreateSlideRequest = {\n      objectId: slide.objectId,\n      slideLayoutReference: { predefinedLayout: slide.layout },\n      placeholderIdMappings: mapPlaceholders(slide.objectId, slide.layout),\n    };\n    requests.push({ createSlide: request });\n    if (slide.title) {\n      requests.push({\n        insertText: {\n          text: slide.title.text,\n          objectId: `${slide.objectId}-title`,\n        },\n      });\n    }\n    if (slide.subtitle) {\n      requests.push({\n        insertText: {\n          text: slide.subtitle.text,\n          objectId: `${slide.objectId}-subtitle`,\n        },\n      });\n    }\n    slide.body.forEach((body) => {\n      const bodyText = body.text;\n      if (!bodyText) return;\n      if (bodyText.images?.length) {\n        requests.push({\n          createImage: {\n            url: imageUrls[bodyText.images[0]],\n            elementProperties: {\n              pageObjectId: slide.objectId,\n            },\n          },\n        });\n      } else if (bodyText.text) {\n        const objectId = `${slide.objectId}-body`;\n        requests.push({\n          insertText: { text: bodyText.text, objectId },\n        });\n        bodyText.lists.forEach((list) => {\n          requests.push({\n            createParagraphBullets: {\n              objectId,\n              textRange: {\n                type: \"FIXED_RANGE\",\n                startIndex: list.start,\n                endIndex: list.end,\n              },\n            },\n          });\n        });\n        bodyText.styles.forEach((style) => {\n          requests.push({\n            updateTextStyle: {\n              objectId,\n              ...getTextStyle(style),\n              textRange: {\n                type: \"FIXED_RANGE\",\n                startIndex: style.range.start,\n                endIndex: style.range.end,\n              },\n            },\n          });\n        });\n      }\n    });\n  });\n  return requests;\n}\n\nfunction getTextStyle(style: SlideStyle): {\n  style: SlidesTextStyle;\n  fields: string;\n} {\n  const { link: url, range: _, ...rest } = style;\n  const linkStyle = url ? { link: { url } } : {};\n  const fields = Object.keys(rest);\n  if (url) fields.push(\"link\");\n\n  return { style: { ...linkStyle, ...rest }, fields: fields.join(\",\") };\n}\n\nfunction mapPlaceholders(slideId: string, layout: SlidesPredefinedLayout) {\n  const mappings: SlidesLayoutPlaceholderIdMapping[] = [];\n  switch (layout) {\n    case \"TITLE\":\n      mappings.push({\n        layoutPlaceholder: { type: \"CENTERED_TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      mappings.push({\n        layoutPlaceholder: { type: \"SUBTITLE\", index: 0 },\n        objectId: `${slideId}-subtitle`,\n      });\n      break;\n    case \"TITLE_AND_BODY\":\n      mappings.push({\n        layoutPlaceholder: { type: \"TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      mappings.push({\n        layoutPlaceholder: { type: \"BODY\", index: 0 },\n        objectId: `${slideId}-body`,\n      });\n      break;\n    case \"MAIN_POINT\":\n      mappings.push({\n        layoutPlaceholder: { type: \"TITLE\", index: 0 },\n        objectId: `${slideId}-title`,\n      });\n      break;\n  }\n  return mappings;\n}\n",
          "language": "typescript"
        },
        "description": "Slides bits.",
        "runnable": false
      }
    },
    "docs": {
      "code": "import { marked } from \"./marked\";\nimport { unescape } from \"./unescape\";\nimport { toText, mergeTextParts } from \"./a2/utils\";\nimport transformBlob from \"@blob\";\nexport { contextToRequests, markdownToContext, DOC_MIME_TYPE };\nconst DOC_MIME_TYPE = \"application/vnd.google-apps.document\";\n// async function transformBlob(args: {\n//   contents: LLMContent[];\n//   transform: string;\n// }): Promise<{ contents: LLMContent[] }> {\n//   return args;\n// }\n/**\n * Removes surrounding backticks from each line if each\n * line is surrounded by backticks.\n * This is a bug in Google Drive markdown conversion.\n * Here's hoping it won't do too much damage.\n */\nfunction sanitizeBackticks(s) {\n    return s\n        .split(\"\\n\")\n        .map((line) => {\n        const trimmed = line.trim();\n        if (trimmed.length === 0)\n            return line;\n        if (trimmed.startsWith(\"`\") && trimmed.endsWith(\"`\")) {\n            return trimmed.slice(1, -1);\n        }\n        return line;\n    })\n        .join(\"\\n\");\n}\nconst BASE64_DATA_URL_REGEX = /^data:(.+?);base64,(.+)$/;\nfunction parseBase64DataUrl(url) {\n    const matchResult = url.match(BASE64_DATA_URL_REGEX);\n    if (!matchResult || matchResult.length !== 3) {\n        return null;\n    }\n    const [, mimeType, data] = matchResult;\n    return { inlineData: { mimeType, data } };\n}\nfunction markdownToContext(markdown) {\n    const tokens = marked.lexer(sanitizeBackticks(markdown));\n    const parts = mergeTextParts(tokens.flatMap((token) => {\n        if (token.type === \"paragraph\") {\n            return token.tokens.map((token) => {\n                if (token.type === \"image\") {\n                    const inlineData = parseBase64DataUrl(token.href);\n                    if (inlineData)\n                        return inlineData;\n                }\n                return { text: token.raw };\n            });\n        }\n        return { text: token.raw };\n    }));\n    return [{ parts }];\n}\nasync function contextToRequests(context, startIndex) {\n    const parts = context?.at(-1)?.parts;\n    if (!parts)\n        return [];\n    const result = [];\n    let index = startIndex;\n    for (const part of parts) {\n        if (\"text\" in part) {\n            const tokens = marked.lexer(toText(context));\n            const { lastIndex, requests } = tokensToRequests(tokens, index);\n            result.push(...requests);\n            index = lastIndex;\n        }\n        else if (\"inlineData\" in part) {\n            const contents = await transformBlob({\n                contents: [{ parts: [part] }],\n                transform: \"persistent-temporary\",\n            });\n            const storedPart = contents?.contents\n                ?.at(0)\n                ?.parts?.at(0);\n            if (storedPart) {\n                result.push({\n                    insertInlineImage: {\n                        uri: storedPart.storedData.handle,\n                        location: {\n                            index,\n                        },\n                    },\n                });\n            }\n        }\n    }\n    return result;\n}\n/**\n * Converts markdown tokens to Google Doc Request array for the\n * `batchUpdate` call.\n */\nfunction tokensToRequests(tokens, startIndex) {\n    let current = startIndex;\n    const requests = tokens.flatMap((token) => {\n        switch (token.type) {\n            case \"paragraph\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"space\":\n                return insertSpace(token);\n            case \"code\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"heading\":\n                return insertFormattedText(token, `HEADING_${token.depth}`);\n            case \"blockquote\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"list\":\n                return insertList(token.items, token.ordered, 0);\n        }\n        return [];\n    });\n    return { lastIndex: current, requests };\n    function insertFormattedText(token, namedStyleType) {\n        const { requests, text: withoutBreak } = new TextStyles(current, token).parse();\n        const text = `${withoutBreak}\\n`;\n        if (namedStyleType) {\n            requests.unshift({\n                updateParagraphStyle: {\n                    range: range(text.length),\n                    paragraphStyle: { namedStyleType },\n                    fields: \"namedStyleType\",\n                },\n            });\n        }\n        requests.unshift({ insertText: { text, location: location() } });\n        current += text.length;\n        return requests;\n    }\n    function insertSpace(token) {\n        const text = token.raw.startsWith(\"\\n\") ? token.raw.slice(1) : token.raw;\n        const result = [\n            {\n                insertText: { text, location: location() },\n            },\n        ];\n        return advance(result, text.length);\n    }\n    function range(length) {\n        return { startIndex: current, endIndex: current + length };\n    }\n    function location() {\n        return { index: current };\n    }\n    function insertList(items, ordered, depth) {\n        const start = current;\n        // This is necessary to counteract a gnarly side-effect of creating a\n        // bullet list: the indent markers are being removed during that change,\n        // and change all of the ranges. So we have to make sure that the next\n        // request accounts for that.\n        let depthToRemove = 0;\n        const list = descendIntoList(items, ordered, depth).flat();\n        list.push({\n            createParagraphBullets: {\n                range: { startIndex: start, endIndex: current },\n                bulletPreset: \"BULLET_DISC_CIRCLE_SQUARE\",\n            },\n        });\n        current -= depthToRemove;\n        return list;\n        function descendIntoList(items, ordered, depth) {\n            const list = items.flatMap((item) => {\n                // For item, item.type === \"list_item\".\n                const indent = \"\\t\".repeat(depth);\n                depthToRemove += depth;\n                const result = [];\n                const maybeRichToken = \"tokens\" in item ? item : undefined;\n                const subList = maybeRichToken?.tokens.find((token) => token?.type === \"list\");\n                if (subList) {\n                    // assume that the first token is actually the text token.\n                    result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n                    result.push(...descendIntoList(subList.items, ordered, depth + 1));\n                }\n                else {\n                    result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n                }\n                return result;\n            });\n            return list;\n        }\n        function insertItemText(indent, token) {\n            const offset = current + indent.length;\n            const { requests, text: withoutIndent } = new TextStyles(offset, token).parse();\n            const text = `${indent}${withoutIndent}\\n`;\n            requests.unshift({\n                updateParagraphStyle: {\n                    range: range(text.length),\n                    paragraphStyle: { namedStyleType: \"NORMAL_TEXT\" },\n                    fields: \"namedStyleType\",\n                },\n            });\n            requests.unshift({ insertText: { text, location: location() } });\n            current += text.length;\n            return requests;\n        }\n    }\n    function advance(result, length) {\n        current += length;\n        return result;\n    }\n}\nclass TextStyles {\n    #offset;\n    #tokens = [];\n    #styles = [];\n    constructor(offset, token) {\n        this.#offset = offset;\n        if (token && \"tokens\" in token) {\n            this.#tokens = token.tokens;\n        }\n    }\n    range(startIndex, length) {\n        return { startIndex, endIndex: startIndex + length };\n    }\n    style(startIndex, length, textStyle) {\n        this.#styles.push({\n            updateTextStyle: {\n                range: this.range(startIndex, length),\n                textStyle,\n                fields: Object.keys(textStyle).join(\",\"),\n            },\n        });\n    }\n    parse() {\n        let current = this.#offset;\n        let text = \"\";\n        for (let token of this.#tokens) {\n            let tokenText = unescape(\"text\" in token ? token.text : \"\");\n            const length = tokenText.length;\n            text += tokenText;\n            switch (token.type) {\n                case \"strong\":\n                    this.style(current, length, { bold: true });\n                    break;\n                case \"em\":\n                    this.style(current, length, { italic: true });\n                    break;\n                case \"codespan\":\n                    this.style(current, length, {\n                        weightedFontFamily: {\n                            fontFamily: \"Fira Code\",\n                        },\n                    });\n                    break;\n                case \"del\":\n                    this.style(current, length, { strikethrough: true });\n                    break;\n                case \"link\":\n                    this.style(current, length, { link: { url: token.href } });\n                    break;\n                case \"escape\":\n                    console.log(\"ESCAPE\", token);\n                    break;\n            }\n            current += length;\n        }\n        return {\n            requests: this.#styles,\n            text,\n        };\n    }\n}\n",
      "metadata": {
        "title": "docs",
        "source": {
          "code": "import { marked } from \"./marked\";\nimport { unescape } from \"./unescape\";\nimport type {\n  Token,\n  FormattingToken,\n  SpaceToken,\n  RichToken,\n  ListToken,\n} from \"./types\";\nimport { toText, mergeTextParts } from \"./a2/utils\";\nimport transformBlob from \"@blob\";\n\nexport { contextToRequests, markdownToContext, DOC_MIME_TYPE };\n\nconst DOC_MIME_TYPE = \"application/vnd.google-apps.document\";\n\nexport type DocsInsertInlineImageRequest = {\n  insertInlineImage: {\n    uri: string;\n    location: {\n      segmentId?: string;\n      index: number;\n      tabId?: string;\n    };\n  };\n};\n\n// async function transformBlob(args: {\n//   contents: LLMContent[];\n//   transform: string;\n// }): Promise<{ contents: LLMContent[] }> {\n//   return args;\n// }\n\n/**\n * Removes surrounding backticks from each line if each\n * line is surrounded by backticks.\n * This is a bug in Google Drive markdown conversion.\n * Here's hoping it won't do too much damage.\n */\nfunction sanitizeBackticks(s: string): string {\n  return s\n    .split(\"\\n\")\n    .map((line) => {\n      const trimmed = line.trim();\n      if (trimmed.length === 0) return line;\n      if (trimmed.startsWith(\"`\") && trimmed.endsWith(\"`\")) {\n        return trimmed.slice(1, -1);\n      }\n      return line;\n    })\n    .join(\"\\n\");\n}\n\nconst BASE64_DATA_URL_REGEX = /^data:(.+?);base64,(.+)$/;\n\nfunction parseBase64DataUrl(url: string): InlineDataCapabilityPart | null {\n  const matchResult = url.match(BASE64_DATA_URL_REGEX);\n  if (!matchResult || matchResult.length !== 3) {\n    return null;\n  }\n  const [, mimeType, data] = matchResult;\n  return { inlineData: { mimeType, data } };\n}\n\nfunction markdownToContext(markdown: string): LLMContent[] {\n  const tokens = marked.lexer(sanitizeBackticks(markdown)) as Token[];\n  const parts: DataPart[] = mergeTextParts(\n    tokens.flatMap((token) => {\n      if (token.type === \"paragraph\") {\n        return token.tokens.map((token) => {\n          if (token.type === \"image\") {\n            const inlineData = parseBase64DataUrl(token.href);\n            if (inlineData) return inlineData;\n          }\n          return { text: token.raw };\n        });\n      }\n      return { text: token.raw };\n    })\n  );\n  return [{ parts }];\n}\n\nasync function contextToRequests(\n  context: LLMContent[] | undefined,\n  startIndex: number\n): Promise<unknown[]> {\n  const parts = context?.at(-1)?.parts;\n  if (!parts) return [];\n\n  const result: unknown[] = [];\n  let index = startIndex;\n  for (const part of parts) {\n    if (\"text\" in part) {\n      const tokens = marked.lexer(toText(context));\n      const { lastIndex, requests } = tokensToRequests(tokens, index);\n      result.push(...requests);\n      index = lastIndex;\n    } else if (\"inlineData\" in part) {\n      const contents = await transformBlob({\n        contents: [{ parts: [part] }],\n        transform: \"persistent-temporary\",\n      });\n      const storedPart = contents?.contents\n        ?.at(0)\n        ?.parts?.at(0) as StoredDataCapabilityPart;\n      if (storedPart) {\n        result.push({\n          insertInlineImage: {\n            uri: storedPart.storedData.handle,\n            location: {\n              index,\n            },\n          },\n        } satisfies DocsInsertInlineImageRequest);\n      }\n    }\n  }\n  return result;\n}\n\ntype TokensToRequestsResult = { lastIndex: number; requests: unknown[] };\n\n/**\n * Converts markdown tokens to Google Doc Request array for the\n * `batchUpdate` call.\n */\nfunction tokensToRequests(\n  tokens: Token[],\n  startIndex: number\n): TokensToRequestsResult {\n  let current = startIndex;\n  const requests = tokens.flatMap((token) => {\n    switch (token.type) {\n      case \"paragraph\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"space\":\n        return insertSpace(token);\n      case \"code\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"heading\":\n        return insertFormattedText(token, `HEADING_${token.depth}`);\n      case \"blockquote\":\n        return insertFormattedText(token, \"NORMAL_TEXT\");\n      case \"list\":\n        return insertList(token.items, token.ordered, 0);\n    }\n    return [];\n  });\n  return { lastIndex: current, requests };\n\n  function insertFormattedText(token: Token, namedStyleType: string) {\n    const { requests, text: withoutBreak } = new TextStyles(\n      current,\n      token as FormattingToken\n    ).parse();\n    const text = `${withoutBreak}\\n`;\n    if (namedStyleType) {\n      requests.unshift({\n        updateParagraphStyle: {\n          range: range(text.length),\n          paragraphStyle: { namedStyleType },\n          fields: \"namedStyleType\",\n        },\n      });\n    }\n    requests.unshift({ insertText: { text, location: location() } });\n    current += text.length;\n    return requests;\n  }\n\n  function insertSpace(token: SpaceToken) {\n    const text = token.raw.startsWith(\"\\n\") ? token.raw.slice(1) : token.raw;\n    const result = [\n      {\n        insertText: { text, location: location() },\n      },\n    ];\n    return advance(result, text.length);\n  }\n\n  function range(length: number) {\n    return { startIndex: current, endIndex: current + length };\n  }\n\n  function location() {\n    return { index: current };\n  }\n\n  function insertList(items: Token[], ordered: boolean, depth: number) {\n    const start = current;\n    // This is necessary to counteract a gnarly side-effect of creating a\n    // bullet list: the indent markers are being removed during that change,\n    // and change all of the ranges. So we have to make sure that the next\n    // request accounts for that.\n    let depthToRemove = 0;\n    const list = descendIntoList(items, ordered, depth).flat();\n    list.push({\n      createParagraphBullets: {\n        range: { startIndex: start, endIndex: current },\n        bulletPreset: \"BULLET_DISC_CIRCLE_SQUARE\",\n      },\n    });\n    current -= depthToRemove;\n    return list;\n\n    function descendIntoList(items: Token[], ordered: boolean, depth: number) {\n      const list: unknown[] = items.flatMap((item) => {\n        // For item, item.type === \"list_item\".\n        const indent = \"\\t\".repeat(depth);\n        depthToRemove += depth;\n        const result = [];\n        const maybeRichToken: RichToken | undefined =\n          \"tokens\" in item ? item : undefined;\n        const subList = maybeRichToken?.tokens.find(\n          (token) => token?.type === \"list\"\n        );\n        if (subList) {\n          // assume that the first token is actually the text token.\n          result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n          result.push(...descendIntoList(subList.items, ordered, depth + 1));\n        } else {\n          result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n        }\n        return result;\n      });\n      return list;\n    }\n\n    function insertItemText(\n      indent: string,\n      token: ListToken | FormattingToken | undefined\n    ) {\n      const offset = current + indent.length;\n      const { requests, text: withoutIndent } = new TextStyles(\n        offset,\n        token\n      ).parse();\n      const text = `${indent}${withoutIndent}\\n`;\n      requests.unshift({\n        updateParagraphStyle: {\n          range: range(text.length),\n          paragraphStyle: { namedStyleType: \"NORMAL_TEXT\" },\n          fields: \"namedStyleType\",\n        },\n      });\n      requests.unshift({ insertText: { text, location: location() } });\n      current += text.length;\n      return requests;\n    }\n  }\n\n  function advance(result: unknown, length: number) {\n    current += length;\n    return result;\n  }\n}\n\nclass TextStyles {\n  #offset;\n  #tokens: FormattingToken[] = [];\n  #styles: unknown[] = [];\n\n  constructor(offset: number, token: FormattingToken | ListToken | undefined) {\n    this.#offset = offset;\n    if (token && \"tokens\" in token) {\n      this.#tokens = token.tokens;\n    }\n  }\n\n  range(startIndex: number, length: number) {\n    return { startIndex, endIndex: startIndex + length };\n  }\n\n  style(\n    startIndex: number,\n    length: number,\n    textStyle: Record<string, unknown>\n  ) {\n    this.#styles.push({\n      updateTextStyle: {\n        range: this.range(startIndex, length),\n        textStyle,\n        fields: Object.keys(textStyle).join(\",\"),\n      },\n    });\n  }\n\n  parse() {\n    let current = this.#offset;\n    let text = \"\";\n    for (let token of this.#tokens) {\n      let tokenText = unescape(\"text\" in token ? token.text : \"\");\n      const length = tokenText.length;\n      text += tokenText;\n      switch (token.type) {\n        case \"strong\":\n          this.style(current, length, { bold: true });\n          break;\n        case \"em\":\n          this.style(current, length, { italic: true });\n          break;\n        case \"codespan\":\n          this.style(current, length, {\n            weightedFontFamily: {\n              fontFamily: \"Fira Code\",\n            },\n          });\n          break;\n        case \"del\":\n          this.style(current, length, { strikethrough: true });\n          break;\n        case \"link\":\n          this.style(current, length, { link: { url: token.href } });\n          break;\n        case \"escape\":\n          console.log(\"ESCAPE\", token);\n          break;\n      }\n      current += length;\n    }\n    return {\n      requests: this.#styles,\n      text,\n    };\n  }\n}\n",
          "language": "typescript"
        },
        "description": "",
        "runnable": false
      }
    },
    "types": {
      "code": "",
      "metadata": {
        "title": "types",
        "source": {
          "code": "export type * from \"./marked-types\";\n\nexport type ConnectorConfiguration = {\n  file?: {\n    preview: string;\n    id: string;\n    mimeType: string;\n  };\n};\n",
          "language": "typescript"
        },
        "description": "",
        "runnable": false
      }
    },
    "connector-save": {
      "code": "/**\n * @fileoverview Connector Save Export.\n */\nimport {} from \"@describe\";\nimport { toText, ok, err } from \"./a2/utils\";\nimport { contextToRequests, DOC_MIME_TYPE } from \"./docs\";\nimport { connect, query, create, getDoc, updateDoc } from \"./api\";\nexport { invoke as default, describe };\nasync function invoke({ method, id: connectorId, context, info, }) {\n    const mimeType = info?.configuration?.file?.mimeType;\n    const canSave = mimeType === DOC_MIME_TYPE || mimeType === undefined;\n    if (method === \"save\") {\n        if (!canSave) {\n            return err(`Unable to save files of type \"${mimeType}\"`);\n        }\n        const token = await connect({ title: \"Get Auth Token\" });\n        const gettingCollector = await getCollector(token, connectorId, \"Untitled Document\", info?.configuration?.file?.id);\n        if (!ok(gettingCollector))\n            return gettingCollector;\n        const { id, end } = gettingCollector;\n        const requests = await contextToRequests(context, end);\n        const updating = await updateDoc(token, id, { requests }, { title: \"Append to Google Doc\" });\n        if (!ok(updating))\n            return updating;\n        return { context: context || [] };\n    }\n    else if (method == \"canSave\") {\n        return { canSave };\n    }\n    return err(`Unknown method: \"${method}\"`);\n}\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(token, connectorId, title, fileId) {\n    let id;\n    if (!fileId) {\n        const findFile = await query(token, `appProperties has { key = 'google-drive-connector' and value = '${connectorId}' } and trashed = false`, { title: \"Find the doc to append to\" });\n        if (!ok(findFile))\n            return findFile;\n        const file = findFile.files.at(0);\n        if (!file) {\n            const createdFile = await create(token, {\n                name: title,\n                mimeType: DOC_MIME_TYPE,\n                appProperties: {\n                    \"google-drive-connector\": connectorId,\n                },\n            }, { title: \"Create new doc to which to append\" });\n            if (!ok(createdFile))\n                return createdFile;\n            return {\n                id: createdFile.id,\n                end: 1,\n            };\n        }\n        id = file.id;\n    }\n    else {\n        id = fileId;\n    }\n    const gettingDoc = await getDoc(token, id, {\n        title: \"Get current doc contents\",\n    });\n    if (!ok(gettingDoc))\n        return gettingDoc;\n    const end = gettingDoc.body.content.reduce((acc, element) => Math.max(acc, element.endIndex || 0), 1) - 1;\n    return { id, end };\n}\nasync function describe() {\n    return {\n        title: \"Save To Google Drive\",\n        metadata: {\n            tags: [\"connector-save\"],\n        },\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\n",
      "metadata": {
        "title": "connector-save",
        "source": {
          "code": "/**\n * @fileoverview Connector Save Export.\n */\nimport { type DescribeOutputs } from \"@describe\";\nimport { toText, ok, err } from \"./a2/utils\";\nimport { contextToRequests, DOC_MIME_TYPE } from \"./docs\";\nimport { connect, query, create, getDoc, updateDoc } from \"./api\";\nimport type { ConnectorConfiguration } from \"./types\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  id: string;\n  info?: { configuration?: ConnectorConfiguration };\n  method: \"canSave\" | \"save\";\n  context?: LLMContent[];\n};\n\ntype Outputs =\n  | {\n      context: LLMContent[];\n    }\n  | {\n      canSave: boolean;\n    };\n\nasync function invoke({\n  method,\n  id: connectorId,\n  context,\n  info,\n}: Inputs): Promise<Outcome<Outputs>> {\n  const mimeType = info?.configuration?.file?.mimeType;\n  const canSave = mimeType === DOC_MIME_TYPE || mimeType === undefined;\n  if (method === \"save\") {\n    if (!canSave) {\n      return err(`Unable to save files of type \"${mimeType}\"`);\n    }\n    const token = await connect({ title: \"Get Auth Token\" });\n    const gettingCollector = await getCollector(\n      token,\n      connectorId,\n      \"Untitled Document\",\n      info?.configuration?.file?.id\n    );\n    if (!ok(gettingCollector)) return gettingCollector;\n    const { id, end } = gettingCollector;\n    const requests = await contextToRequests(context, end);\n    const updating = await updateDoc(\n      token,\n      id,\n      { requests },\n      { title: \"Append to Google Doc\" }\n    );\n    if (!ok(updating)) return updating;\n    return { context: context || [] };\n  } else if (method == \"canSave\") {\n    return { canSave };\n  }\n  return err(`Unknown method: \"${method}\"`);\n}\n\ntype CollectorData = {\n  id: string;\n  end: number;\n};\n\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(\n  token: string,\n  connectorId: string,\n  title: string,\n  fileId?: string\n): Promise<Outcome<CollectorData>> {\n  let id;\n  if (!fileId) {\n    const findFile = await query(\n      token,\n      `appProperties has { key = 'google-drive-connector' and value = '${connectorId}' } and trashed = false`,\n      { title: \"Find the doc to append to\" }\n    );\n    if (!ok(findFile)) return findFile;\n    const file = findFile.files.at(0);\n    if (!file) {\n      const createdFile = await create(\n        token,\n        {\n          name: title,\n          mimeType: DOC_MIME_TYPE,\n          appProperties: {\n            \"google-drive-connector\": connectorId,\n          },\n        },\n        { title: \"Create new doc to which to append\" }\n      );\n      if (!ok(createdFile)) return createdFile;\n\n      return {\n        id: createdFile.id,\n        end: 1,\n      };\n    }\n    id = file.id;\n  } else {\n    id = fileId;\n  }\n  const gettingDoc = await getDoc(token, id, {\n    title: \"Get current doc contents\",\n  });\n  if (!ok(gettingDoc)) return gettingDoc;\n  const end =\n    (\n      gettingDoc as { body: { content: { endIndex: number }[] } }\n    ).body.content.reduce(\n      (acc, element) => Math.max(acc, element.endIndex || 0),\n      1\n    ) - 1;\n  return { id, end };\n}\n\nasync function describe() {\n  return {\n    title: \"Save To Google Drive\",\n    metadata: {\n      tags: [\"connector-save\"],\n    },\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n        },\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n    } satisfies Schema,\n  } satisfies DescribeOutputs;\n}\n",
          "language": "typescript"
        },
        "description": "Connector Save Export.",
        "runnable": false
      }
    },
    "connector-load": {
      "code": "/**\n * @fileoverview Connector Load Export\n */\nimport {} from \"@describe\";\nimport { toText, ok, err, llm } from \"./a2/utils\";\nimport { contextToRequests, markdownToContext, DOC_MIME_TYPE } from \"./docs\";\nimport { connect, query, exp } from \"./api\";\nexport { invoke as default, describe };\nasync function invoke({ id, info: { configuration }, }) {\n    const token = await connect({ title: \"Getting auth token\" });\n    if (!ok(token))\n        return token;\n    const gettingDoc = await getCollector(token, id, configuration?.file);\n    if (!ok(gettingDoc))\n        return gettingDoc;\n    return { context: gettingDoc };\n}\n/**\n * Gets the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(token, connectorId, file) {\n    const { id: fileId, mimeType } = file || {};\n    let id;\n    if (!fileId) {\n        const findFile = await query(token, `appProperties has { key = 'google-drive-connector' and value = '${connectorId}' } and trashed = false`, { title: \"Find the doc to append to\" });\n        if (!ok(findFile))\n            return findFile;\n        const file = findFile.files.at(0);\n        if (!file) {\n            return [];\n        }\n        id = file.id;\n    }\n    else {\n        id = fileId;\n    }\n    const exporter = new Exporter(token, id, mimeType);\n    return exporter.export();\n}\nclass Exporter {\n    token;\n    id;\n    mimeType;\n    constructor(token, id, mimeType) {\n        this.token = token;\n        this.id = id;\n        this.mimeType = mimeType;\n    }\n    isDoc() {\n        return this.mimeType === DOC_MIME_TYPE;\n    }\n    async export() {\n        const { token, id } = this;\n        if (this.isDoc()) {\n            const gettingDoc = await exp(token, id, \"text/makdown\", {\n                title: \"Get current doc contents\",\n            });\n            if (!ok(gettingDoc))\n                return gettingDoc;\n            if (!(typeof gettingDoc === \"string\")) {\n                return err(`Invalid output from document export. Must be a string`);\n            }\n            return markdownToContext(gettingDoc);\n        }\n        else {\n            const exportingPdf = await exp(token, id, \"application/pdf\", {\n                title: \"Get PDF export of the file\",\n            });\n            if (!ok(exportingPdf))\n                return exportingPdf;\n            return [{ parts: [exportingPdf] }];\n        }\n    }\n}\nasync function describe() {\n    return {\n        metadata: {\n            tags: [\"connector-load\"],\n        },\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\n",
      "metadata": {
        "title": "connector-load",
        "source": {
          "code": "/**\n * @fileoverview Connector Load Export\n */\nimport { type DescribeOutputs } from \"@describe\";\nimport { toText, ok, err, llm } from \"./a2/utils\";\nimport { contextToRequests, markdownToContext, DOC_MIME_TYPE } from \"./docs\";\nimport { connect, query, exp } from \"./api\";\nimport type { ConnectorConfiguration } from \"./types\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  id: string;\n  info: {\n    configuration?: ConnectorConfiguration;\n  };\n};\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nasync function invoke({\n  id,\n  info: { configuration },\n}: Inputs): Promise<Outcome<Outputs>> {\n  const token = await connect({ title: \"Getting auth token\" });\n  if (!ok(token)) return token;\n  const gettingDoc = await getCollector(token, id, configuration?.file);\n  if (!ok(gettingDoc)) return gettingDoc;\n  return { context: gettingDoc };\n}\n\n/**\n * Gets the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(\n  token: string,\n  connectorId: string,\n  file: ConnectorConfiguration[\"file\"] | undefined\n): Promise<Outcome<LLMContent[]>> {\n  const { id: fileId, mimeType } = file || {};\n  let id;\n  if (!fileId) {\n    const findFile = await query(\n      token,\n      `appProperties has { key = 'google-drive-connector' and value = '${connectorId}' } and trashed = false`,\n      { title: \"Find the doc to append to\" }\n    );\n    if (!ok(findFile)) return findFile;\n    const file = findFile.files.at(0);\n    if (!file) {\n      return [];\n    }\n    id = file.id;\n  } else {\n    id = fileId;\n  }\n  const exporter = new Exporter(token, id, mimeType);\n  return exporter.export();\n}\n\nclass Exporter {\n  constructor(\n    public readonly token: string,\n    public readonly id: string,\n    public readonly mimeType: string | undefined\n  ) {}\n\n  isDoc() {\n    return this.mimeType === DOC_MIME_TYPE;\n  }\n\n  async export(): Promise<Outcome<LLMContent[]>> {\n    const { token, id } = this;\n    if (this.isDoc()) {\n      const gettingDoc = await exp(token, id, \"text/makdown\", {\n        title: \"Get current doc contents\",\n      });\n      if (!ok(gettingDoc)) return gettingDoc;\n      if (!(typeof gettingDoc === \"string\")) {\n        return err(`Invalid output from document export. Must be a string`);\n      }\n      return markdownToContext(gettingDoc);\n    } else {\n      const exportingPdf = await exp(token, id, \"application/pdf\", {\n        title: \"Get PDF export of the file\",\n      });\n      if (!ok(exportingPdf)) return exportingPdf;\n      return [{ parts: [exportingPdf as StoredDataCapabilityPart] }];\n    }\n  }\n}\n\nasync function describe() {\n  return {\n    metadata: {\n      tags: [\"connector-load\"],\n    },\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n        },\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n    } satisfies Schema,\n  } satisfies DescribeOutputs;\n}\n",
          "language": "typescript"
        },
        "description": "Connector Load Export",
        "runnable": false
      }
    },
    "marked-types": {
      "code": "/**\n * @fileoverview Marked Types\n */\n",
      "metadata": {
        "title": "marked-types",
        "source": {
          "code": "/**\n * @fileoverview Marked Types\n */\n\nexport type Token =\n  | ParagraphToken\n  | HeadingToken\n  | ListToken\n  | ListItemToken\n  | HrToken\n  | SpaceToken\n  | CodeToken\n  | CodespanToken\n  | EscapeToken\n  | BlockquoteToken;\n\nexport type FormattingToken =\n  | SpaceToken\n  | BrToken\n  | ImageToken\n  | TextToken\n  | LinkToken\n  | EmToken\n  | StrongToken\n  | DelToken\n  | CodespanToken\n  | EscapeToken;\n\nexport type RichToken =\n  | BlockquoteToken\n  | TextToken\n  | HeadingToken\n  | ParagraphToken\n  | ListItemToken;\n\nexport type SpaceToken = {\n  type: \"space\";\n  raw: string;\n};\n\nexport type BrToken = {\n  type: \"br\";\n  raw: string;\n};\n\nexport type CodeToken = {\n  type: \"code\";\n  raw: string;\n  codeblockStyle?: \"indented\";\n  lang?: string;\n  text: string;\n  excaped?: boolean;\n};\n\nexport type CodespanToken = {\n  type: \"codespan\";\n  raw: string;\n  text: string;\n};\n\nexport type BlockquoteToken = {\n  type: \"blockquote\";\n  raw: string;\n  text: string;\n  tokens: FormattingToken[];\n};\n\nexport type EscapeToken = {\n  type: \"escape\";\n  raw: string;\n  text: string;\n};\n\nexport type ImageToken = {\n  type: \"image\";\n  href: string;\n  title?: string;\n  text: string;\n  raw: string;\n};\n\nexport type TextToken = {\n  type: \"text\";\n  text: string;\n  raw: string;\n  tokens: FormattingToken[];\n};\n\nexport type LinkToken = {\n  type: \"link\";\n  href: string;\n  text: string;\n  raw: string;\n};\n\nexport type EmToken = {\n  type: \"em\";\n  raw: string;\n  text: string;\n};\n\nexport type DelToken = {\n  type: \"del\";\n  raw: string;\n  text: string;\n};\n\nexport type StrongToken = {\n  type: \"strong\";\n  raw: string;\n  text: string;\n};\n\nexport type HeadingToken = {\n  type: \"heading\";\n  depth: number;\n  raw: string;\n  text: string;\n  tokens: FormattingToken[];\n};\n\nexport type HrToken = {\n  type: \"hr\";\n  raw: string;\n  text: string;\n};\n\nexport type ParagraphToken = {\n  type: \"paragraph\";\n  text: string;\n  raw: string;\n  tokens: FormattingToken[];\n};\n\nexport type ListToken = {\n  type: \"list\";\n  ordered: boolean;\n  raw: string;\n  items: ListItemToken[];\n};\n\nexport type ListItemToken = {\n  type: \"list_item\";\n  text: string;\n  raw: string;\n  tokens: [TextToken, ListToken?];\n};\n",
          "language": "typescript"
        },
        "description": "Marked Types",
        "runnable": false
      }
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:configurator",
    "#module:connector-save",
    "#module:connector-load"
  ]
}