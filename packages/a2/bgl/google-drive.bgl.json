{
  "title": "Google Drive",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "icon": "gdrive",
    "visual": {
      "presentation": {
        "themes": {
          "f65ea9aa-b8c6-4c80-9667-a08c4f631013": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "f65ea9aa-b8c6-4c80-9667-a08c4f631013"
      }
    },
    "userModified": true,
    "tags": [
      "connector",
      "published",
      "experimental"
    ],
    "comments": [
      {
        "id": "comment-c74afa15",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 281,
            "y": 501,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ]
  },
  "modules": {
    "api": {
      "code": "/**\n * @license\n * Copyright 2024 Google LLC\n * SPDX-License-Identifier: Apache-2.0\n */\nimport { err } from \"./a2/utils\";\nexport { appendSpreadsheetValues, connect, create, createMultipart, createPermission, createPresentation, del, exp, get, getDoc, getPresentation, query, updateDoc, updatePresentation, updateSpreadsheetValues, };\nconst connectionId = \"connection:$sign-in\";\nasync function get(caps, token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply file id.\");\n    }\n    return api(caps, metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"GET\");\n}\nasync function create(caps, token, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the file to create.\");\n    }\n    return api(caps, metadata, token, \"https://www.googleapis.com/drive/v3/files\", \"POST\", body);\n}\nasync function query(caps, token, query, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!query) {\n        return err(\"Please supply the query.\");\n    }\n    return api(caps, metadata, token, `https://www.googleapis.com/drive/v3/files?q=${encodeURIComponent(query)}`, \"GET\");\n}\nasync function del(caps, token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the file to delete\");\n    }\n    return api(caps, metadata, token, `https://www.googleapis.com/drive/v3/files/${id}`, \"DELETE\");\n}\nasync function exp(caps, token, fileId, mimeType, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!fileId) {\n        return err(\"Please supply the file id to export.\");\n    }\n    return api(caps, metadata, token, `https://www.googleapis.com/drive/v3/files/${fileId}/export?mimeType=${mimeType}`, \"GET\");\n}\nasync function getDoc(caps, token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the doc id to get.\");\n    }\n    return api(caps, metadata, token, `https://docs.googleapis.com/v1/documents/${id}`, \"GET\");\n}\nasync function updateDoc(caps, token, id, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the doc to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the doc update request.\");\n    }\n    return api(caps, metadata, token, `https://docs.googleapis.com/v1/documents/${id}:batchUpdate`, \"POST\", body);\n}\nasync function getPresentation(caps, token, id, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    return api(caps, metadata, token, `https://slides.googleapis.com/v1/presentations/${id}`, \"GET\");\n}\nasync function createPresentation(caps, token, title, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    return api(caps, metadata, token, \"https://slides.googleapis.com/v1/presentations\", \"POST\", { title });\n}\nasync function updatePresentation(caps, token, id, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the presentation to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the presentation update request.\");\n    }\n    return api(caps, metadata, token, `https://slides.googleapis.com/v1/presentations/${id}:batchUpdate`, \"POST\", body);\n}\nasync function updateSpreadsheetValues(caps, token, id, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the spreadsheet to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the spreadsheet update request.\");\n    }\n    return api(caps, metadata, token, `https://sheets.googleapis.com/v4/spreadsheets/${id}/values:batchUpdate`, \"POST\", body);\n}\nasync function appendSpreadsheetValues(caps, token, id, range, body, metadata) {\n    if (!token) {\n        return err(\"Authentication token is required.\");\n    }\n    if (!id) {\n        return err(\"Please supply the id of the spreadsheet to update.\");\n    }\n    if (!body) {\n        return err(\"Please supply the body of the spreadsheet update request.\");\n    }\n    return api(caps, metadata, token, `https://sheets.googleapis.com/v4/spreadsheets/${id}/values/${range}:append?valueInputOption=USER_ENTERED`, \"POST\", body);\n}\nasync function connect({ secrets }, metadata) {\n    const { [connectionId]: token } = await secrets({\n        ...meta(metadata),\n        keys: [connectionId],\n    });\n    return token;\n}\nasync function createMultipart({ fetch }, token, metadata, body, mimeType, $metadata) {\n    const boundary = \"BB-BB-BB-BB-BB-BB\";\n    const url = `https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart`;\n    const request = {\n        ...meta($metadata),\n        url,\n        method: \"POST\",\n        headers: {\n            Authorization: `Bearer ${token}`,\n            [\"Content-Type\"]: `multipart/related; boundary=${boundary}`,\n        },\n        body: `--${boundary}\nContent-Type: application/json; charset=UTF-8\n\n${JSON.stringify(metadata, null, 2)}\n--${boundary}\nContent-Type: ${mimeType}; charset=UTF-8\nContent-Transfer-Encoding: base64\n\n${body}\n--${boundary}--`,\n    };\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n    }\n    return response;\n}\nasync function createPermission(caps, token, fileId, permission, metadata) {\n    return api(caps, metadata, token, `https://www.googleapis.com/drive/v3/files/${fileId}/permissions`, \"POST\", permission);\n}\nasync function api({ fetch }, metadata, token, url, method, body = null) {\n    const request = {\n        ...meta(metadata),\n        url,\n        method,\n        headers: {\n            Authorization: `Bearer ${token}`,\n        },\n    };\n    if (body) {\n        request.body = body;\n    }\n    const { response, $error } = await fetch(request);\n    if ($error) {\n        return err(typeof $error === \"string\" ? $error : JSON.stringify($error));\n    }\n    return response;\n}\nfunction meta({ title, description } = {}) {\n    if (!(title || description))\n        return {};\n    const $metadata = {};\n    if (title) {\n        $metadata.title = title;\n    }\n    if (description) {\n        $metadata.description = description;\n    }\n    return { $metadata };\n}\n"
    },
    "configurator": {
      "code": "/**\n * @fileoverview Add a description for your module here.\n */\nimport { createConfigurator } from \"./a2/connector-manager\";\nexport { invoke as default, describe };\nconst CONNECTOR_TITLE = \"Google Drive\";\nconst { invoke, describe } = createConfigurator({\n    title: CONNECTOR_TITLE,\n    initialize: async () => {\n        return { title: \"Untitled Drive File\", configuration: {} };\n    },\n    read: async ({ id: _id, configuration }) => {\n        return {\n            schema: {\n                type: \"object\",\n                properties: {\n                    file: {\n                        type: \"object\",\n                        title: \"Google Drive File\",\n                        description: \"Select Google Drive File\",\n                        behavior: [\"google-drive-file-id\"],\n                    },\n                },\n            },\n            values: configuration,\n        };\n    },\n    preview: async ({ configuration }) => {\n        const { id, mimeType } = configuration.file || {};\n        if (!id || !mimeType)\n            return [\n                {\n                    parts: [{ text: \"Untitled Document\" }],\n                },\n            ];\n        return [{ parts: [{ fileData: { fileUri: id, mimeType } }] }];\n    },\n    write: async ({ id, values }) => {\n        console.log(\"WRITE\", id, values);\n        return values;\n    },\n});\n"
    },
    "connector-load": {
      "code": "import { err, ok } from \"./a2/utils\";\nimport { connect, exp, query } from \"./api\";\nimport { DOC_MIME_TYPE, markdownToContext } from \"./docs\";\nexport { invoke as default, describe };\nasync function invoke({ id, info: { configuration } }, caps) {\n    const token = await connect(caps, { title: \"Getting auth token\" });\n    if (!ok(token))\n        return token;\n    const gettingDoc = await getCollector(caps, token, id, configuration?.file);\n    if (!ok(gettingDoc))\n        return gettingDoc;\n    return { context: gettingDoc };\n}\n/**\n * Gets the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(caps, token, connectorId, file) {\n    const { id: fileId, mimeType } = file || {};\n    let id;\n    if (!fileId) {\n        const findFile = await query(caps, token, `appProperties has { key = 'google-drive-connector' and value = '${connectorId}' } and trashed = false`, { title: \"Find the doc to append to\" });\n        if (!ok(findFile))\n            return findFile;\n        const file = findFile.files.at(0);\n        if (!file) {\n            return [];\n        }\n        id = file.id;\n    }\n    else {\n        id = fileId;\n    }\n    const exporter = new Exporter(caps, token, id, mimeType);\n    return exporter.export();\n}\nclass Exporter {\n    constructor(caps, token, id, mimeType) {\n        this.caps = caps;\n        this.token = token;\n        this.id = id;\n        this.mimeType = mimeType;\n    }\n    isDoc() {\n        return this.mimeType === DOC_MIME_TYPE;\n    }\n    async export() {\n        const { token, id } = this;\n        if (this.isDoc()) {\n            const gettingDoc = await exp(this.caps, token, id, \"text/makdown\", {\n                title: \"Get current doc contents\",\n            });\n            if (!ok(gettingDoc))\n                return gettingDoc;\n            if (!(typeof gettingDoc === \"string\")) {\n                return err(`Invalid output from document export. Must be a string`);\n            }\n            return markdownToContext(gettingDoc);\n        }\n        else {\n            const exportingPdf = await exp(this.caps, token, id, \"application/pdf\", {\n                title: \"Get PDF export of the file\",\n            });\n            if (!ok(exportingPdf))\n                return exportingPdf;\n            return [{ parts: [exportingPdf] }];\n        }\n    }\n}\nasync function describe() {\n    return {\n        metadata: {\n            tags: [\"connector-load\"],\n        },\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\n"
    },
    "connector-save": {
      "code": "import { err, ok } from \"./a2/utils\";\nimport { appendSpreadsheetValues, connect, create, getDoc, getPresentation, query, updateDoc, updatePresentation, } from \"./api\";\nimport { contextToRequests, DOC_MIME_TYPE } from \"./docs\";\nimport { inferSheetValues, SHEETS_MIME_TYPE } from \"./sheets\";\nimport { SimpleSlideBuilder, SLIDES_MIME_TYPE } from \"./slides\";\nimport { inferSlideStructure } from \"./slides-schema\";\nexport { invoke as default, describe };\nfunction contextFromId(id, mimeType) {\n    return [{ parts: [{ storedData: { handle: `drive:/${id}`, mimeType } }] }];\n}\nasync function invoke({ method, id: connectorId, context, title, graphId, info }, caps) {\n    graphId ?? (graphId = \"\");\n    const mimeType = info?.configuration?.file?.mimeType || DOC_MIME_TYPE;\n    const canSave = mimeType === DOC_MIME_TYPE ||\n        mimeType === SLIDES_MIME_TYPE ||\n        mimeType === SHEETS_MIME_TYPE;\n    if (method === \"save\") {\n        if (!canSave) {\n            return err(`Unable to save files of type \"${mimeType}\"`);\n        }\n        const token = await connect(caps, { title: \"Get Auth Token\" });\n        switch (mimeType) {\n            case DOC_MIME_TYPE: {\n                const gettingCollector = await getCollector(caps, token, connectorId, graphId, title ?? \"Untitled Document\", DOC_MIME_TYPE, info?.configuration?.file?.id);\n                if (!ok(gettingCollector))\n                    return gettingCollector;\n                const { id, end } = gettingCollector;\n                const requests = await contextToRequests(context, end);\n                const updating = await updateDoc(caps, token, id, { requests }, { title: \"Append to Google Doc\" });\n                if (!ok(updating))\n                    return updating;\n                return { context: contextFromId(id, DOC_MIME_TYPE) };\n            }\n            case SLIDES_MIME_TYPE: {\n                const [gettingCollector, result] = await Promise.all([\n                    getCollector(caps, token, connectorId, graphId, title ?? \"Untitled Presentation\", SLIDES_MIME_TYPE, info?.configuration?.file?.id),\n                    inferSlideStructure(caps, context),\n                ]);\n                if (!ok(gettingCollector))\n                    return gettingCollector;\n                if (!ok(result))\n                    return result;\n                const { id, end, last } = gettingCollector;\n                const slideBuilder = new SimpleSlideBuilder(end, last);\n                for (const slide of result.slides) {\n                    slideBuilder.addSlide(slide);\n                }\n                const requests = slideBuilder.build([]);\n                console.log(\"REQUESTS\", requests);\n                const updating = await updatePresentation(caps, token, id, { requests }, { title: \"Append to Google Presentation\" });\n                if (!ok(updating))\n                    return updating;\n                return { context: contextFromId(id, SLIDES_MIME_TYPE) };\n            }\n            case SHEETS_MIME_TYPE: {\n                const [gettingCollector, result] = await Promise.all([\n                    getCollector(caps, token, connectorId, graphId, title ?? \"Untitled Spreadsheet\", SHEETS_MIME_TYPE, info?.configuration?.file?.id),\n                    inferSheetValues(caps, context),\n                ]);\n                if (!ok(gettingCollector))\n                    return gettingCollector;\n                if (!ok(result))\n                    return result;\n                const { id } = gettingCollector;\n                console.log(\"VALUES\", result);\n                const appending = await appendSpreadsheetValues(caps, token, id, \"Sheet1\", { values: result }, {\n                    title: \"Append to Google Presentation\",\n                });\n                if (!ok(appending))\n                    return appending;\n                return { context: contextFromId(id, SHEETS_MIME_TYPE) };\n            }\n        }\n    }\n    else if (method == \"canSave\") {\n        return { canSave };\n    }\n    return err(`Unknown method: \"${method}\"`);\n}\n/**\n * Gets or creates the Google Doc id that serves as the collector: the\n * doc to which context is appended.\n */\nasync function getCollector(caps, token, connectorId, graphId, title, mimeType, fileId) {\n    let id;\n    if (!fileId) {\n        const fileKey = `${getTypeKey(mimeType)}${connectorId}${graphId}`;\n        const findFile = await query(caps, token, `appProperties has { key = 'google-drive-connector' and value = '${fileKey}' } and trashed = false`, { title: \"Find the doc to append to\" });\n        if (!ok(findFile))\n            return findFile;\n        const file = findFile.files.at(0);\n        if (!file) {\n            const createdFile = await create(caps, token, {\n                name: title,\n                mimeType,\n                appProperties: {\n                    \"google-drive-connector\": fileKey,\n                },\n            }, { title: \"Create new file to which to append\" });\n            if (!ok(createdFile))\n                return createdFile;\n            if (mimeType === DOC_MIME_TYPE) {\n                return {\n                    id: createdFile.id,\n                    end: 1,\n                };\n            }\n            else if (mimeType === SLIDES_MIME_TYPE) {\n                const gettingPresenation = await getPresentation(caps, token, createdFile.id, {\n                    title: \"Reading presentation\",\n                });\n                if (!ok(gettingPresenation))\n                    return gettingPresenation;\n                return {\n                    id: gettingPresenation.presentationId,\n                    end: 1,\n                    last: gettingPresenation.slides?.at(-1)?.objectId || undefined,\n                };\n            }\n            else if (mimeType === SHEETS_MIME_TYPE) {\n                return { id: createdFile.id, end: 1 };\n            }\n            else {\n                return err(`Unknown mimeType: ${mimeType}`);\n            }\n        }\n        id = file.id;\n    }\n    else {\n        id = fileId;\n    }\n    if (mimeType === DOC_MIME_TYPE) {\n        const gettingDoc = await getDoc(caps, token, id, {\n            title: \"Get current doc contents\",\n        });\n        if (!ok(gettingDoc))\n            return gettingDoc;\n        const end = gettingDoc.body.content.reduce((acc, element) => Math.max(acc, element.endIndex || 0), 1) - 1;\n        return { id, end };\n    }\n    else if (mimeType === SLIDES_MIME_TYPE) {\n        const gettingPresentation = await getPresentation(caps, token, id, {\n            title: \"Get current doc contents\",\n        });\n        if (!ok(gettingPresentation))\n            return gettingPresentation;\n        const end = gettingPresentation.slides?.length || 0;\n        return { id, end };\n    }\n    else if (mimeType === SHEETS_MIME_TYPE) {\n        return { id, end: 1 };\n    }\n    return err(`Unknown mimeType: ${mimeType}`);\n    function getTypeKey(mimeType) {\n        if (mimeType === DOC_MIME_TYPE)\n            return \"doc\";\n        if (mimeType === SHEETS_MIME_TYPE)\n            return \"sheet\";\n        if (mimeType === SLIDES_MIME_TYPE)\n            return \"slides\";\n        return \"\";\n    }\n}\nasync function describe() {\n    return {\n        title: \"Save To Google Drive\",\n        metadata: {\n            tags: [\"connector-save\"],\n        },\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\n"
    },
    "docs": {
      "code": "var __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _TextStyles_offset, _TextStyles_tokens, _TextStyles_styles;\nimport transformBlob from \"@blob\";\nimport { mergeTextParts, toText } from \"./a2/utils\";\nimport { marked } from \"./marked\";\nimport { unescape } from \"./unescape\";\nexport { contextToRequests, DOC_MIME_TYPE, markdownToContext };\nconst DOC_MIME_TYPE = \"application/vnd.google-apps.document\";\n// async function transformBlob(args: {\n//   contents: LLMContent[];\n//   transform: string;\n// }): Promise<{ contents: LLMContent[] }> {\n//   return args;\n// }\n/**\n * Removes surrounding backticks from each line if each\n * line is surrounded by backticks.\n * This is a bug in Google Drive markdown conversion.\n * Here's hoping it won't do too much damage.\n */\nfunction sanitizeBackticks(s) {\n    return s\n        .split(\"\\n\")\n        .map((line) => {\n        const trimmed = line.trim();\n        if (trimmed.length === 0)\n            return line;\n        if (trimmed.startsWith(\"`\") && trimmed.endsWith(\"`\")) {\n            return trimmed.slice(1, -1);\n        }\n        return line;\n    })\n        .join(\"\\n\");\n}\nconst BASE64_DATA_URL_REGEX = /^data:(.+?);base64,(.+)$/;\nfunction parseBase64DataUrl(url) {\n    const matchResult = url.match(BASE64_DATA_URL_REGEX);\n    if (!matchResult || matchResult.length !== 3) {\n        return null;\n    }\n    const [, mimeType, data] = matchResult;\n    return { inlineData: { mimeType, data } };\n}\nfunction markdownToContext(markdown) {\n    const tokens = marked.lexer(sanitizeBackticks(markdown));\n    const parts = mergeTextParts(tokens.flatMap((token) => {\n        if (token.type === \"paragraph\") {\n            return token.tokens.map((token) => {\n                if (token.type === \"image\") {\n                    const inlineData = parseBase64DataUrl(token.href);\n                    if (inlineData)\n                        return inlineData;\n                }\n                return { text: token.raw };\n            });\n        }\n        return { text: token.raw };\n    }));\n    return [{ parts }];\n}\nasync function contextToRequests(context, startIndex) {\n    const parts = context?.at(-1)?.parts;\n    if (!parts)\n        return [];\n    const result = [];\n    let index = startIndex;\n    for (const part of parts) {\n        if (\"text\" in part) {\n            const tokens = marked.lexer(toText(context));\n            const { lastIndex, requests } = tokensToRequests(tokens, index);\n            result.push(...requests);\n            index = lastIndex;\n        }\n        else if (\"inlineData\" in part) {\n            const contents = await transformBlob({\n                contents: [{ parts: [part] }],\n                transform: \"persistent-temporary\",\n            });\n            const storedPart = contents?.contents\n                ?.at(0)\n                ?.parts?.at(0);\n            if (storedPart) {\n                result.push({\n                    insertInlineImage: {\n                        uri: storedPart.storedData.handle,\n                        location: {\n                            index,\n                        },\n                    },\n                });\n            }\n        }\n    }\n    return result;\n}\n/**\n * Converts markdown tokens to Google Doc Request array for the\n * `batchUpdate` call.\n */\nfunction tokensToRequests(tokens, startIndex) {\n    let current = startIndex;\n    const requests = tokens.flatMap((token) => {\n        switch (token.type) {\n            case \"paragraph\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"space\":\n                return insertSpace(token);\n            case \"code\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"heading\":\n                return insertFormattedText(token, `HEADING_${token.depth}`);\n            case \"blockquote\":\n                return insertFormattedText(token, \"NORMAL_TEXT\");\n            case \"list\":\n                return insertList(token.items, token.ordered, 0);\n        }\n        return [];\n    });\n    return { lastIndex: current, requests };\n    function insertFormattedText(token, namedStyleType) {\n        const { requests, text: withoutBreak } = new TextStyles(current, token).parse();\n        const text = `${withoutBreak}\\n`;\n        if (namedStyleType) {\n            requests.unshift({\n                updateParagraphStyle: {\n                    range: range(text.length),\n                    paragraphStyle: { namedStyleType },\n                    fields: \"namedStyleType\",\n                },\n            });\n        }\n        requests.unshift({ insertText: { text, location: location() } });\n        current += text.length;\n        return requests;\n    }\n    function insertSpace(token) {\n        const text = token.raw.startsWith(\"\\n\") ? token.raw.slice(1) : token.raw;\n        const result = [\n            {\n                insertText: { text, location: location() },\n            },\n        ];\n        return advance(result, text.length);\n    }\n    function range(length) {\n        return { startIndex: current, endIndex: current + length };\n    }\n    function location() {\n        return { index: current };\n    }\n    function insertList(items, ordered, depth) {\n        const start = current;\n        // This is necessary to counteract a gnarly side-effect of creating a\n        // bullet list: the indent markers are being removed during that change,\n        // and change all of the ranges. So we have to make sure that the next\n        // request accounts for that.\n        let depthToRemove = 0;\n        const list = descendIntoList(items, ordered, depth).flat();\n        list.push({\n            createParagraphBullets: {\n                range: { startIndex: start, endIndex: current },\n                bulletPreset: \"BULLET_DISC_CIRCLE_SQUARE\",\n            },\n        });\n        current -= depthToRemove;\n        return list;\n        function descendIntoList(items, ordered, depth) {\n            const list = items.flatMap((item) => {\n                // For item, item.type === \"list_item\".\n                const indent = \"\\t\".repeat(depth);\n                depthToRemove += depth;\n                const result = [];\n                const maybeRichToken = \"tokens\" in item ? item : undefined;\n                const subList = maybeRichToken?.tokens.find((token) => token?.type === \"list\");\n                if (subList) {\n                    // assume that the first token is actually the text token.\n                    result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n                    result.push(...descendIntoList(subList.items, ordered, depth + 1));\n                }\n                else {\n                    result.push(insertItemText(indent, maybeRichToken?.tokens.at(0)));\n                }\n                return result;\n            });\n            return list;\n        }\n        function insertItemText(indent, token) {\n            const offset = current + indent.length;\n            const { requests, text: withoutIndent } = new TextStyles(offset, token).parse();\n            const text = `${indent}${withoutIndent}\\n`;\n            requests.unshift({\n                updateParagraphStyle: {\n                    range: range(text.length),\n                    paragraphStyle: { namedStyleType: \"NORMAL_TEXT\" },\n                    fields: \"namedStyleType\",\n                },\n            });\n            requests.unshift({ insertText: { text, location: location() } });\n            current += text.length;\n            return requests;\n        }\n    }\n    function advance(result, length) {\n        current += length;\n        return result;\n    }\n}\nclass TextStyles {\n    constructor(offset, token) {\n        _TextStyles_offset.set(this, void 0);\n        _TextStyles_tokens.set(this, []);\n        _TextStyles_styles.set(this, []);\n        __classPrivateFieldSet(this, _TextStyles_offset, offset, \"f\");\n        if (token && \"tokens\" in token) {\n            __classPrivateFieldSet(this, _TextStyles_tokens, token.tokens, \"f\");\n        }\n    }\n    range(startIndex, length) {\n        return { startIndex, endIndex: startIndex + length };\n    }\n    style(startIndex, length, textStyle) {\n        __classPrivateFieldGet(this, _TextStyles_styles, \"f\").push({\n            updateTextStyle: {\n                range: this.range(startIndex, length),\n                textStyle,\n                fields: Object.keys(textStyle).join(\",\"),\n            },\n        });\n    }\n    parse() {\n        let current = __classPrivateFieldGet(this, _TextStyles_offset, \"f\");\n        let text = \"\";\n        for (const token of __classPrivateFieldGet(this, _TextStyles_tokens, \"f\")) {\n            const tokenText = unescape(\"text\" in token ? token.text : \"\");\n            const length = tokenText.length;\n            text += tokenText;\n            switch (token.type) {\n                case \"strong\":\n                    this.style(current, length, { bold: true });\n                    break;\n                case \"em\":\n                    this.style(current, length, { italic: true });\n                    break;\n                case \"codespan\":\n                    this.style(current, length, {\n                        weightedFontFamily: {\n                            fontFamily: \"Fira Code\",\n                        },\n                    });\n                    break;\n                case \"del\":\n                    this.style(current, length, { strikethrough: true });\n                    break;\n                case \"link\":\n                    this.style(current, length, { link: { url: token.href } });\n                    break;\n                case \"escape\":\n                    console.log(\"ESCAPE\", token);\n                    break;\n            }\n            current += length;\n        }\n        return {\n            requests: __classPrivateFieldGet(this, _TextStyles_styles, \"f\"),\n            text,\n        };\n    }\n}\n_TextStyles_offset = new WeakMap(), _TextStyles_tokens = new WeakMap(), _TextStyles_styles = new WeakMap();\n"
    },
    "marked-types": {
      "code": "/**\n * @fileoverview Marked Types\n */\nexport {};\n"
    },
    "marked": {
      "code": "/**\n * marked v14.1.3 - a markdown parser\n * Copyright (c) 2011-2024, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n/**\n * Gets the original marked default options.\n */\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\nlet _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n/**\n * Helpers\n */\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = new RegExp(escapeTest.source, \"g\");\nconst escapeTestNoEncode = /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/;\nconst escapeReplaceNoEncode = new RegExp(escapeTestNoEncode.source, \"g\");\nconst escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\",\n};\nconst getEscapeReplacement = (ch) => escapeReplacements[ch];\nfunction escape$1(html, encode) {\n  if (encode) {\n    if (escapeTest.test(html)) {\n      return html.replace(escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (escapeTestNoEncode.test(html)) {\n      return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html;\n}\nconst caret = /(^|[^\\[])\\^/g;\nfunction edit(regex, opt) {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  opt = opt || \"\";\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(/%25/g, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nconst noopTest = { exec: () => null };\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return \"|\";\n      } else {\n        // add space before unescaped |\n        return \" |\";\n      }\n    }),\n    cells = row.split(/ \\|/);\n  let i = 0;\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, \"|\");\n  }\n  return cells;\n}\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  return -1;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n  const href = link.href;\n  const title = link.title ? escape$1(link.title) : null;\n  const text = cap[1].replace(/\\\\([\\[\\]])/g, \"$1\");\n  if (cap[0].charAt(0) !== \"!\") {\n    lexer.state.inLink = true;\n    const token = {\n      type: \"link\",\n      raw,\n      href,\n      title,\n      text,\n      tokens: lexer.inlineTokens(text),\n    };\n    lexer.state.inLink = false;\n    return token;\n  }\n  return {\n    type: \"image\",\n    raw,\n    href,\n    title,\n    text: escape$1(text),\n  };\n}\nfunction indentCodeCompensation(raw, text) {\n  const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text\n    .split(\"\\n\")\n    .map((node) => {\n      const matchIndentInNode = node.match(/^\\s+/);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n      const [indentInNode] = matchIndentInNode;\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n      return node;\n    })\n    .join(\"\\n\");\n}\n/**\n * Tokenizer\n */\nclass _Tokenizer {\n  options;\n  rules; // set by the lexer\n  lexer; // set by the lexer\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0],\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(/^(?: {1,4}| {0,3}\\t)/gm, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text,\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\");\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2]\n          ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\")\n          : cap[2],\n        text,\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      // remove trailing #s\n      if (/#$/.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || / $/.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\"),\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (/^ {0,3}>/.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(/\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g, \"\\n    $1\")\n          .replace(/^ {0,3}>[ \\t]?/gm, \"\");\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens[tokens.length - 1];\n        if (lastToken?.type === \"code\") {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          // include continuation in nested blockquote\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.text.length) +\n            newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          // include continuation in nested list\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw =\n            raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text =\n            text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText\n            .substring(tokens[tokens.length - 1].raw.length)\n            .split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: [],\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      // Get next list item\n      const itemRegex = new RegExp(\n        `^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`\n      );\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2]\n          .split(\"\\n\", 1)[0]\n          .replace(/^\\t+/, (t) => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(/[^ ]/); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && /^[ \\t]*$/.test(nextLine)) {\n          // Items begin with at most one blank line\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`\n          );\n          const hrRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`\n          );\n          const fencesBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`\n          );\n          const headingBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}#`\n          );\n          const htmlBeginRegex = new RegExp(\n            `^ {0,${Math.min(3, indent - 1)}}<[a-z].*>`,\n            \"i\"\n          );\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(/^ {1,4}(?=( {4})*[^ ])/g, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(/\\t/g, \"    \");\n            }\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (\n              nextLineWithoutTabs.search(/[^ ]/) >= indent ||\n              !nextLine.trim()\n            ) {\n              // Dedent if possible\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(/\\t/g, \"    \").search(/[^ ]/) >= 4) {\n                // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              // Check if current line is blank\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (/\\n[ \\t]*\\n[ \\t]*$/.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = /^\\[[ xX]\\] /.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(/^\\[[ xX]\\] +/, \"\");\n          }\n        }\n        list.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n        list.raw += raw;\n      }\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      list.items[list.items.length - 1].raw =\n        list.items[list.items.length - 1].raw.trimEnd();\n      list.items[list.items.length - 1].text =\n        list.items[list.items.length - 1].text.trimEnd();\n      list.raw = list.raw.trimEnd();\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(\n            (t) => t.type === \"space\"\n          );\n          const hasMultipleLineBreaks =\n            spacers.length > 0 && spacers.some((t) => /\\n.*\\n/.test(t.raw));\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n      return list;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(/\\s+/g, \" \");\n      const href = cap[2]\n        ? cap[2]\n            .replace(/^<(.*)>$/, \"$1\")\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : \"\";\n      const title = cap[3]\n        ? cap[3]\n            .substring(1, cap[3].length - 1)\n            .replace(this.rules.inline.anyPunctuation, \"$1\")\n        : cap[3];\n      return {\n        type: \"def\",\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!/[:|]/.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(/^\\||\\| *$/g, \"\").split(\"|\");\n    const rows =\n      cap[3] && cap[3].trim()\n        ? cap[3].replace(/\\n[ \\t]*$/, \"\").split(\"\\n\")\n        : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n    for (const align of aligns) {\n      if (/^ *-+: *$/.test(align)) {\n        item.align.push(\"right\");\n      } else if (/^ *:-+: *$/.test(align)) {\n        item.align.push(\"center\");\n      } else if (/^ *:-+ *$/.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(\n        splitCells(row, item.header.length).map((cell, i) => {\n          return {\n            text: cell,\n            tokens: this.lexer.inline(cell),\n            header: false,\n            align: item.align[i],\n          };\n        })\n      );\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text =\n        cap[1].charAt(cap[1].length - 1) === \"\\n\"\n          ? cap[1].slice(0, -1)\n          : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: escape$1(cap[1]),\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (\n        !this.lexer.state.inRawBlock &&\n        /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = true;\n      } else if (\n        this.lexer.state.inRawBlock &&\n        /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])\n      ) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!/>$/.test(trimmedUrl)) {\n          return;\n        }\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (/^</.test(href)) {\n        if (this.options.pedantic && !/>$/.test(trimmedUrl)) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(\n        cap,\n        {\n          href: href\n            ? href.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : href,\n          title: title\n            ? title.replace(this.rules.inline.anyPunctuation, \"$1\")\n            : title,\n        },\n        cap[0],\n        this.lexer\n      );\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if (\n      (cap = this.rules.inline.reflink.exec(src)) ||\n      (cap = this.rules.inline.nolink.exec(src))\n    ) {\n      const linkString = (cap[2] || cap[1]).replace(/\\s+/g, \" \");\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (\n      !nextChar ||\n      !prevChar ||\n      this.rules.inline.punctuation.exec(prevChar)\n    ) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg =\n        match[0][0] === \"*\"\n          ? this.rules.inline.emStrongRDelimAst\n          : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim =\n          match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue; // skip single * in __abc*abc__\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(\n          0,\n          lLength + match.index + lastCharLength + rLength\n        );\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(/\\n/g, \" \");\n      const hasNonSpaceChars = /[^ ]/.test(text);\n      const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      text = escape$1(text, true);\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0],\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[1]);\n        href = \"mailto:\" + text;\n      } else {\n        text = escape$1(cap[1]);\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if ((cap = this.rules.inline.url.exec(src))) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = escape$1(cap[0]);\n        href = \"mailto:\" + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = escape$1(cap[0]);\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: \"text\",\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      let text;\n      if (this.lexer.state.inRawBlock) {\n        text = cap[0];\n      } else {\n        text = escape$1(cap[0]);\n      }\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n}\n\n/**\n * Block-Level Grammar\n */\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences =\n  /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheading = edit(\n  /^(?!bull |blockCode|fences|blockquote|heading|html)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/\n)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .getRegex();\nconst _paragraph =\n  /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(\n  /^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/\n)\n  .replace(\"label\", _blockLabel)\n  .replace(\n    \"title\",\n    /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/\n  )\n  .getRegex();\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\nconst _tag =\n  \"address|article|aside|base|basefont|blockquote|body|caption\" +\n  \"|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption\" +\n  \"|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe\" +\n  \"|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option\" +\n  \"|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title\" +\n  \"|tr|track|ul\";\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  \"^ {0,3}(?:\" + // optional indentation\n    \"<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)\" + // (1)\n    \"|comment[^\\\\n]*(\\\\n+|$)\" + // (2)\n    \"|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)\" + // (3)\n    \"|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)\" + // (4)\n    \"|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)\" + // (5)\n    \"|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (6)\n    \"|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) open tag\n    \"|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)\" + // (7) closing tag\n    \")\",\n  \"i\"\n)\n  .replace(\"comment\", _comment)\n  .replace(\"tag\", _tag)\n  .replace(\n    \"attribute\",\n    / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst paragraph = edit(_paragraph)\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n  .replace(\"|table\", \"\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace(\"paragraph\", paragraph)\n  .getRegex();\n/**\n * Normal Block Grammar\n */\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n/**\n * GFM Block Grammar\n */\nconst gfmTable = edit(\n  \"^ *([^\\\\n ].*)\\\\n\" + // Header\n    \" {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)\" + // Align\n    \"(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\"\n) // Cells\n  .replace(\"hr\", hr)\n  .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n  .replace(\"blockquote\", \" {0,3}>\")\n  .replace(\"code\", \"(?: {4}| {0,3}\\t)[^\\\\n]\")\n  .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n  .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n  .replace(\n    \"html\",\n    \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n  )\n  .replace(\"tag\", _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\nconst blockGfm = {\n  ...blockNormal,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\")\n    .replace(\"|lheading\", \"\") // setext headings don't interrupt commonmark paragraphs\n    .replace(\"table\", gfmTable) // interrupt paragraphs with table\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\")\n    .replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \") // only lists starting from 1 can interrupt\n    .replace(\n      \"html\",\n      \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\"\n    )\n    .replace(\"tag\", _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\nconst blockPedantic = {\n  ...blockNormal,\n  html: edit(\n    \"^ *(?:comment *(?:\\\\n|\\\\s*$)\" +\n      \"|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)\" + // closed tag\n      \"|<tag(?:\\\"[^\\\"]*\\\"|'[^']*'|\\\\s[^'\\\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))\"\n  )\n    .replace(\"comment\", _comment)\n    .replace(\n      /tag/g,\n      \"(?!(?:\" +\n        \"a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub\" +\n        \"|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\" +\n        \"\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\"\n    )\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace(\"hr\", hr)\n    .replace(\"heading\", \" *#{1,6} *[^\\n]\")\n    .replace(\"lheading\", lheading)\n    .replace(\"|table\", \"\")\n    .replace(\"blockquote\", \" {0,3}>\")\n    .replace(\"|fences\", \"\")\n    .replace(\"|list\", \"\")\n    .replace(\"|html\", \"\")\n    .replace(\"|tag\", \"\")\n    .getRegex(),\n};\n/**\n * Inline-Level Grammar\n */\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText =\n  /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = \"\\\\p{P}\\\\p{S}\";\nconst punctuation = edit(/^((?![*_])[\\spunctuation])/, \"u\")\n  .replace(/punctuation/g, _punctuation)\n  .getRegex();\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip =\n  /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nconst emStrongLDelim = edit(\n  /^(?:\\*+(?:((?!\\*)[punct])|[^\\s*]))|^_+(?:((?!_)[punct])|([^\\s_]))/,\n  \"u\"\n)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst emStrongRDelimAst = edit(\n  \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)\" + // Skip orphan inside strong\n    \"|[^*]+(?=[^*])\" + // Consume to delim\n    \"|(?!\\\\*)[punct](\\\\*+)(?=[\\\\s]|$)\" + // (1) #*** can only be a Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?!\\\\*)(?=[punct\\\\s]|$)\" + // (2) a***#, a*** can only be a Right Delimiter\n    \"|(?!\\\\*)[punct\\\\s](\\\\*+)(?=[^punct\\\\s])\" + // (3) #***a, ***a can only be Left Delimiter\n    \"|[\\\\s](\\\\*+)(?!\\\\*)(?=[punct])\" + // (4) ***# can only be Left Delimiter\n    \"|(?!\\\\*)[punct](\\\\*+)(?!\\\\*)(?=[punct])\" + // (5) #***# can be either Left or Right Delimiter\n    \"|[^punct\\\\s](\\\\*+)(?=[^punct\\\\s])\",\n  \"gu\"\n) // (6) a***a can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  \"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)\" + // Skip orphan inside strong\n    \"|[^_]+(?=[^_])\" + // Consume to delim\n    \"|(?!_)[punct](_+)(?=[\\\\s]|$)\" + // (1) #___ can only be a Right Delimiter\n    \"|[^punct\\\\s](_+)(?!_)(?=[punct\\\\s]|$)\" + // (2) a___#, a___ can only be a Right Delimiter\n    \"|(?!_)[punct\\\\s](_+)(?=[^punct\\\\s])\" + // (3) #___a, ___a can only be Left Delimiter\n    \"|[\\\\s](_+)(?!_)(?=[punct])\" + // (4) ___# can only be Left Delimiter\n    \"|(?!_)[punct](_+)(?!_)(?=[punct])\",\n  \"gu\"\n) // (5) #___# can be either Left or Right Delimiter\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst anyPunctuation = edit(/\\\\([punct])/, \"gu\")\n  .replace(/punct/g, _punctuation)\n  .getRegex();\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace(\n    \"email\",\n    /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/\n  )\n  .getRegex();\nconst _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nconst tag = edit(\n  \"^comment\" +\n    \"|^</[a-zA-Z][\\\\w:-]*\\\\s*>\" + // self-closing tag\n    \"|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>\" + // open tag\n    \"|^<\\\\?[\\\\s\\\\S]*?\\\\?>\" + // processing instruction, e.g. <?php ?>\n    \"|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>\" + // declaration, e.g. <!DOCTYPE html>\n    \"|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\"\n) // CDATA section\n  .replace(\"comment\", _inlineComment)\n  .replace(\n    \"attribute\",\n    /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/\n  )\n  .getRegex();\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/)\n  .replace(\n    \"title\",\n    /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/\n  )\n  .getRegex();\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace(\"label\", _inlineLabel)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace(\"ref\", _blockLabel)\n  .getRegex();\nconst reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\")\n  .replace(\"reflink\", reflink)\n  .replace(\"nolink\", nolink)\n  .getRegex();\n/**\n * Normal Inline Grammar\n */\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n/**\n * Pedantic Inline Grammar\n */\nconst inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace(\"label\", _inlineLabel)\n    .getRegex(),\n};\n/**\n * GFM Inline Grammar\n */\nconst inlineGfm = {\n  ...inlineNormal,\n  escape: edit(escape).replace(\"])\", \"~|])\").getRegex(),\n  url: edit(\n    /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n    \"i\"\n  )\n    .replace(\n      \"email\",\n      /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/\n    )\n    .getRegex(),\n  _backpedal:\n    /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n/**\n * GFM + Line Breaks Inline Grammar\n */\nconst inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text)\n    .replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\")\n    .replace(/\\{2,\\}/g, \"*\")\n    .getRegex(),\n};\n/**\n * exports\n */\nconst block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\nconst inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\n/**\n * Block Lexer\n */\nclass _Lexer {\n  tokens;\n  options;\n  state;\n  tokenizer;\n  inlineQueue;\n  constructor(options) {\n    // TokenList cannot be created in one go\n    this.tokens = [];\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n    const rules = {\n      block: block.normal,\n      inline: inline.normal,\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(/\\r\\n|\\r/g, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(/\\t/g, \"    \").replace(/^ +$/gm, \"\");\n    }\n    let token;\n    let lastToken;\n    let cutSrc;\n    while (src) {\n      if (\n        this.options.extensions &&\n        this.options.extensions.block &&\n        this.options.extensions.block.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // newline\n      if ((token = this.tokenizer.space(src))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.length === 1 && tokens.length > 0) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          tokens[tokens.length - 1].raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.code(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        // An indented code block cannot interrupt a paragraph.\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // fences\n      if ((token = this.tokenizer.fences(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // heading\n      if ((token = this.tokenizer.heading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // hr\n      if ((token = this.tokenizer.hr(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // blockquote\n      if ((token = this.tokenizer.blockquote(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // list\n      if ((token = this.tokenizer.list(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // html\n      if ((token = this.tokenizer.html(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // def\n      if ((token = this.tokenizer.def(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (\n          lastToken &&\n          (lastToken.type === \"paragraph\" || lastToken.type === \"text\")\n        ) {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n      // table (gfm)\n      if ((token = this.tokenizer.table(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // lheading\n      if ((token = this.tokenizer.lheading(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        lastToken = tokens[tokens.length - 1];\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      // text\n      if ((token = this.tokenizer.text(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let token, lastToken, cutSrc;\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match;\n    let keepPrevChar, prevChar;\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while (\n          (match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) !=\n          null\n        ) {\n          if (\n            links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))\n          ) {\n            maskedSrc =\n              maskedSrc.slice(0, match.index) +\n              \"[\" +\n              \"a\".repeat(match[0].length - 2) +\n              \"]\" +\n              maskedSrc.slice(\n                this.tokenizer.rules.inline.reflinkSearch.lastIndex\n              );\n          }\n        }\n      }\n    }\n    // Mask out other blocks\n    while (\n      (match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"[\" +\n        \"a\".repeat(match[0].length - 2) +\n        \"]\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    // Mask out escaped characters\n    while (\n      (match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) !=\n      null\n    ) {\n      maskedSrc =\n        maskedSrc.slice(0, match.index) +\n        \"++\" +\n        maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      // extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.inline &&\n        this.options.extensions.inline.some((extTokenizer) => {\n          if ((token = extTokenizer.call({ lexer: this }, src, tokens))) {\n            src = src.substring(token.raw.length);\n            tokens.push(token);\n            return true;\n          }\n          return false;\n        })\n      ) {\n        continue;\n      }\n      // escape\n      if ((token = this.tokenizer.escape(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // tag\n      if ((token = this.tokenizer.tag(src))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // link\n      if ((token = this.tokenizer.link(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // reflink, nolink\n      if ((token = this.tokenizer.reflink(src, this.tokens.links))) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && token.type === \"text\" && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      // em & strong\n      if ((token = this.tokenizer.emStrong(src, maskedSrc, prevChar))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // code\n      if ((token = this.tokenizer.codespan(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // br\n      if ((token = this.tokenizer.br(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // del (gfm)\n      if ((token = this.tokenizer.del(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // autolink\n      if ((token = this.tokenizer.autolink(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      cutSrc = src;\n      if (this.options.extensions && this.options.extensions.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if ((token = this.tokenizer.inlineText(cutSrc))) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        lastToken = tokens[tokens.length - 1];\n        if (lastToken && lastToken.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n}\n\n/**\n * Renderer\n */\nclass _Renderer {\n  options;\n  parser; // set by the parser\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({ text, lang, escaped }) {\n    const langString = (lang || \"\").match(/^\\S*/)?.[0];\n    const code = text.replace(/\\n$/, \"\") + \"\\n\";\n    if (!langString) {\n      return (\n        \"<pre><code>\" +\n        (escaped ? code : escape$1(code, true)) +\n        \"</code></pre>\\n\"\n      );\n    }\n    return (\n      '<pre><code class=\"language-' +\n      escape$1(langString) +\n      '\">' +\n      (escaped ? code : escape$1(code, true)) +\n      \"</code></pre>\\n\"\n    );\n  }\n  blockquote({ tokens }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n  html({ text }) {\n    return text;\n  }\n  heading({ tokens, depth }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens.length > 0 && item.tokens[0].type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (\n            item.tokens[0].tokens &&\n            item.tokens[0].tokens.length > 0 &&\n            item.tokens[0].tokens[0].type === \"text\"\n          ) {\n            item.tokens[0].tokens[0].text =\n              checkbox + \" \" + item.tokens[0].tokens[0].text;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\\n`;\n  }\n  checkbox({ checked }) {\n    return (\n      \"<input \" +\n      (checked ? 'checked=\"\" ' : \"\") +\n      'disabled=\"\" type=\"checkbox\">'\n    );\n  }\n  paragraph({ tokens }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n  table(token) {\n    let header = \"\";\n    // header\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return (\n      \"<table>\\n\" + \"<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\"\n    );\n  }\n  tablerow({ text }) {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({ tokens }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({ tokens }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({ text }) {\n    return `<code>${text}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({ tokens }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({ href, title, tokens }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({ href, title, text }) {\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${title}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : token.text;\n  }\n}\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nclass _TextRenderer {\n  // no need for block level renderers\n  strong({ text }) {\n    return text;\n  }\n  em({ text }) {\n    return text;\n  }\n  codespan({ text }) {\n    return text;\n  }\n  del({ text }) {\n    return text;\n  }\n  html({ text }) {\n    return text;\n  }\n  text({ text }) {\n    return text;\n  }\n  link({ text }) {\n    return \"\" + text;\n  }\n  image({ text }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n}\n\n/**\n * Parsing & Compiling\n */\nclass _Parser {\n  options;\n  renderer;\n  textRenderer;\n  constructor(options) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call(\n          { parser: this },\n          genericToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"space\",\n            \"hr\",\n            \"heading\",\n            \"code\",\n            \"table\",\n            \"blockquote\",\n            \"list\",\n            \"html\",\n            \"paragraph\",\n            \"text\",\n          ].includes(genericToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\": {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case \"hr\": {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case \"heading\": {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case \"code\": {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case \"table\": {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case \"blockquote\": {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case \"list\": {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case \"html\": {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case \"paragraph\": {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case \"text\": {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n            textToken = tokens[++i];\n            body += \"\\n\" + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: \"paragraph\",\n              raw: body,\n              text: body,\n              tokens: [{ type: \"text\", raw: body, text: body }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer) {\n    renderer = renderer || this.renderer;\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      // Run any renderer extensions\n      if (\n        this.options.extensions &&\n        this.options.extensions.renderers &&\n        this.options.extensions.renderers[anyToken.type]\n      ) {\n        const ret = this.options.extensions.renderers[anyToken.type].call(\n          { parser: this },\n          anyToken\n        );\n        if (\n          ret !== false ||\n          ![\n            \"escape\",\n            \"html\",\n            \"link\",\n            \"image\",\n            \"strong\",\n            \"em\",\n            \"codespan\",\n            \"br\",\n            \"del\",\n            \"text\",\n          ].includes(anyToken.type)\n        ) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\": {\n          out += renderer.text(token);\n          break;\n        }\n        case \"html\": {\n          out += renderer.html(token);\n          break;\n        }\n        case \"link\": {\n          out += renderer.link(token);\n          break;\n        }\n        case \"image\": {\n          out += renderer.image(token);\n          break;\n        }\n        case \"strong\": {\n          out += renderer.strong(token);\n          break;\n        }\n        case \"em\": {\n          out += renderer.em(token);\n          break;\n        }\n        case \"codespan\": {\n          out += renderer.codespan(token);\n          break;\n        }\n        case \"br\": {\n          out += renderer.br(token);\n          break;\n        }\n        case \"del\": {\n          out += renderer.del(token);\n          break;\n        }\n        case \"text\": {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return \"\";\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n\nclass _Hooks {\n  options;\n  block;\n  constructor(options) {\n    this.options = options || _defaults;\n  }\n  static passThroughHooks = new Set([\n    \"preprocess\",\n    \"postprocess\",\n    \"processAllTokens\",\n  ]);\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html) {\n    return html;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n\nclass Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n  constructor(...args) {\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\": {\n          const tableToken = token;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case \"list\": {\n          const listToken = token;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach(\n              (childTokens) => {\n                const tokens = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens, callback));\n              }\n            );\n          } else if (genericToken.tokens) {\n            values = values.concat(\n              this.walkTokens(genericToken.tokens, callback)\n            );\n          }\n        }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {},\n    };\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack };\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function (...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            // Tokenizer Extensions\n            if (\n              !ext.level ||\n              (ext.level !== \"block\" && ext.level !== \"inline\")\n            ) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              // Function to check for start of token\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer =\n          this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(\n                  (ret) => {\n                    return prevHook.call(hooks, ret);\n                  }\n                );\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = { ...this.defaults, ...opts };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n  lexer(src, options) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n  parser(tokens, options) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse = (src, options) => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(\n          new Error(\n            \"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"\n          )\n        );\n      }\n      // throw error in case of non string input\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(\n          new Error(\"marked(): input parameter is undefined or null\")\n        );\n      }\n      if (typeof src !== \"string\") {\n        return throwError(\n          new Error(\n            \"marked(): input parameter is of type \" +\n              Object.prototype.toString.call(src) +\n              \", string expected\"\n          )\n        );\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer = opt.hooks\n        ? opt.hooks.provideLexer()\n        : blockType\n          ? _Lexer.lex\n          : _Lexer.lexInline;\n      const parser = opt.hooks\n        ? opt.hooks.provideParser()\n        : blockType\n          ? _Parser.parse\n          : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then((src) => lexer(src, opt))\n          .then((tokens) =>\n            opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens\n          )\n          .then((tokens) =>\n            opt.walkTokens\n              ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(\n                  () => tokens\n                )\n              : tokens\n          )\n          .then((tokens) => parser(tokens, opt))\n          .then((html) => (opt.hooks ? opt.hooks.postprocess(html) : html))\n          .catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html);\n        }\n        return html;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse;\n  }\n  onError(silent, async) {\n    return (e) => {\n      e.message +=\n        \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg =\n          \"<p>An error occurred:</p><pre>\" +\n          escape$1(e.message + \"\", true) +\n          \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n\nconst markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options = marked.setOptions = function (options) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\n/**\n * Use Extension\n */\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n/**\n * Run callback for every token\n */\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = _Parser.parse;\nconst lexer = _Lexer.lex;\n\nexport {\n  _Hooks as Hooks,\n  _Lexer as Lexer,\n  Marked,\n  _Parser as Parser,\n  _Renderer as Renderer,\n  _TextRenderer as TextRenderer,\n  _Tokenizer as Tokenizer,\n  _defaults as defaults,\n  _getDefaults as getDefaults,\n  lexer,\n  marked,\n  options,\n  parse,\n  parseInline,\n  parser,\n  setOptions,\n  use,\n  walkTokens,\n};\n//# sourceMappingURL=marked.esm.js.map\n"
    },
    "sheets": {
      "code": "import { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { err, llm, ok } from \"./a2/utils\";\nexport { inferSheetValues, SHEETS_MIME_TYPE };\nconst SHEETS_MIME_TYPE = \"application/vnd.google-apps.spreadsheet\";\nfunction sheetSchema() {\n    return {\n        type: \"object\",\n        properties: {\n            spreadsheet_values: {\n                type: \"array\",\n                items: {\n                    type: \"array\",\n                    items: {\n                        type: \"string\",\n                    },\n                },\n            },\n        },\n        required: [\"spreadsheet_values\"],\n    };\n}\nasync function inferSheetValues(caps, contents) {\n    if (!contents) {\n        return err(`Unable to infer spreadsheet values. No information was provided.`);\n    }\n    const prompt = new GeminiPrompt(caps, {\n        body: {\n            contents,\n            systemInstruction: llm `Your job is to generate spreadsheet values from the provided input.\nMake sure that the values you generate reflect the input as precisely as possible`.asContent(),\n            generationConfig: {\n                responseMimeType: \"application/json\",\n                responseSchema: sheetSchema(),\n            },\n        },\n    });\n    const invoking = await prompt.invoke();\n    if (!ok(invoking))\n        return invoking;\n    const result = invoking.last.parts?.at(0)?.json;\n    if (!result) {\n        return err(`Unable to infer spreadsheet values. Invalid response from Gemini.`);\n    }\n    return result.spreadsheet_values;\n}\n"
    },
    "slides-schema": {
      "code": "/**\n * @fileoverview Defines the schema for simple slides JSON output\n */\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { err, llm, ok } from \"./a2/utils\";\nexport { inferSlideStructure };\nfunction simpleSlidesSchema() {\n    const slide = {\n        type: \"object\",\n        properties: {\n            title: { type: \"string\", description: \"Slide title (plain text)\" },\n            subtitle: {\n                type: \"string\",\n                description: \"Slide subtitle (plain text, can be empty for a text slide)\",\n            },\n            body: {\n                type: \"string\",\n                description: \"Slide body (markdown, can be empty for a title slide)\",\n            },\n        },\n        required: [\"title\"],\n    };\n    return {\n        type: \"object\",\n        properties: {\n            slides: {\n                description: \"A collection of slides\",\n                type: \"array\",\n                items: slide,\n            },\n        },\n        required: [\"slides\"],\n    };\n}\nasync function inferSlideStructure(caps, contents) {\n    if (!contents) {\n        return err(`Unable to infer slide structure. No information was provided.`);\n    }\n    const prompt = new GeminiPrompt(caps, {\n        body: {\n            contents,\n            systemInstruction: llm `Your job is to generate a slide deck from the provided input.\nMake sure that the deck represents the key information from the content.\nKeep each slide body text short so that the audience doesn't have to read long sheets of text on each slide.\nIf necessary, break down the deck into sections using title slides`.asContent(),\n            generationConfig: {\n                responseMimeType: \"application/json\",\n                responseSchema: simpleSlidesSchema(),\n            },\n        },\n    });\n    const invoking = await prompt.invoke();\n    if (!ok(invoking))\n        return invoking;\n    const result = invoking.last.parts?.at(0)?.json;\n    if (!result) {\n        return err(`Unable to infer slide structure. Invalid response from Gemini.`);\n    }\n    return result;\n}\n"
    },
    "slides": {
      "code": "/**\n * @fileoverview Slides bits.\n */\nvar __classPrivateFieldSet = (this && this.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n};\nvar __classPrivateFieldGet = (this && this.__classPrivateFieldGet) || function (receiver, state, kind, f) {\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n};\nvar _SlideBuilder_instances, _SlideBuilder_slides, _SlideBuilder_images, _SlideBuilder_startIndex, _SlideBuilder_objectToDelete, _SlideBuilder_depthAdjustment, _SlideBuilder_hasContent, _SlideBuilder_addToken, _SlideBuilder_slide_get, _SlideBuilder_newHeading, _SlideBuilder_newParagraph, _SlideBuilder_getBodyText, _SlideBuilder_addListToBody, _SlideBuilder_parseText, _SlideBuilder_finalizeSlide, _SlideBuilder_newSlide, _SlideBuilder_addImage, _SimpleSlideBuilder_slides, _SimpleSlideBuilder_id, _SimpleSlideBuilder_startIndex, _SimpleSlideBuilder_objectToDelete;\nimport { generateId } from \"./a2/utils\";\nimport { marked } from \"./marked\";\nimport { unescape } from \"./unescape\";\nexport { SimpleSlideBuilder, SlideBuilder, SLIDES_MIME_TYPE, slidesToRequests };\nconst SLIDES_MIME_TYPE = \"application/vnd.google-apps.presentation\";\nclass SlideBuilder {\n    constructor(startIndex = 0, objectId) {\n        _SlideBuilder_instances.add(this);\n        _SlideBuilder_slides.set(this, []);\n        _SlideBuilder_images.set(this, []);\n        _SlideBuilder_startIndex.set(this, void 0);\n        _SlideBuilder_objectToDelete.set(this, void 0);\n        _SlideBuilder_depthAdjustment.set(this, 0);\n        __classPrivateFieldSet(this, _SlideBuilder_startIndex, startIndex, \"f\");\n        __classPrivateFieldSet(this, _SlideBuilder_objectToDelete, objectId, \"f\");\n    }\n    addMarkdown(markdown) {\n        const bodyText = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_getBodyText).call(this);\n        if (__classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get).title || bodyText.text || bodyText.images?.length) {\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_newSlide).call(this);\n        }\n        const tokens = marked.lexer(markdown);\n        tokens.forEach((token) => __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_addToken).call(this, token));\n    }\n    addInlineData(data) {\n        let bodyText = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_getBodyText).call(this);\n        if (__classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get).title || bodyText.text || bodyText.images?.length) {\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_newSlide).call(this);\n            bodyText = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_getBodyText).call(this);\n        }\n        bodyText.images ?? (bodyText.images = []);\n        bodyText.images.push(__classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_addImage).call(this, {\n            type: \"image\",\n            href: `data:${data.mimeType};base64,${data.data}`,\n        }));\n    }\n    images() {\n        return __classPrivateFieldGet(this, _SlideBuilder_images, \"f\");\n    }\n    build(imageUrls) {\n        __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_finalizeSlide).call(this);\n        console.log(\"SLIDES\", __classPrivateFieldGet(this, _SlideBuilder_slides, \"f\"));\n        const requests = slidesToRequests(__classPrivateFieldGet(this, _SlideBuilder_slides, \"f\"), imageUrls);\n        if (__classPrivateFieldGet(this, _SlideBuilder_objectToDelete, \"f\")) {\n            requests.unshift({\n                deleteObject: {\n                    objectId: __classPrivateFieldGet(this, _SlideBuilder_objectToDelete, \"f\"),\n                },\n            });\n        }\n        return requests;\n    }\n}\n_SlideBuilder_slides = new WeakMap(), _SlideBuilder_images = new WeakMap(), _SlideBuilder_startIndex = new WeakMap(), _SlideBuilder_objectToDelete = new WeakMap(), _SlideBuilder_depthAdjustment = new WeakMap(), _SlideBuilder_instances = new WeakSet(), _SlideBuilder_hasContent = function _SlideBuilder_hasContent() { }, _SlideBuilder_addToken = function _SlideBuilder_addToken(token) {\n    const { type } = token;\n    switch (type) {\n        case \"hr\":\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_newSlide).call(this);\n            break;\n        case \"paragraph\":\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_newParagraph).call(this, token.tokens);\n            break;\n        case \"heading\":\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_newHeading).call(this, token);\n            break;\n        case \"list\":\n            __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_addListToBody).call(this, token);\n            break;\n    }\n}, _SlideBuilder_slide_get = function _SlideBuilder_slide_get() {\n    return __classPrivateFieldGet(this, _SlideBuilder_slides, \"f\").at(-1);\n}, _SlideBuilder_newHeading = function _SlideBuilder_newHeading(token) {\n    if (token.depth === 1) {\n        __classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get).title = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_parseText).call(this, token.tokens);\n    }\n    else {\n        __classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get).subtitle = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_parseText).call(this, token.tokens);\n    }\n}, _SlideBuilder_newParagraph = function _SlideBuilder_newParagraph(tokens) {\n    const bodyText = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_getBodyText).call(this);\n    const offset = bodyText.text.length - __classPrivateFieldGet(this, _SlideBuilder_depthAdjustment, \"f\");\n    const { text, styles, lists, images = [], } = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_parseText).call(this, tokens, offset);\n    bodyText.text += text;\n    bodyText.styles.push(...styles);\n    bodyText.lists.push(...lists);\n    bodyText.images ?? (bodyText.images = []);\n    bodyText.images.push(...images);\n}, _SlideBuilder_getBodyText = function _SlideBuilder_getBodyText() {\n    const slide = __classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get);\n    if (!slide.body.length) {\n        slide.body.push({\n            text: { text: \"\", styles: [], lists: [] },\n        });\n    }\n    const body = slide.body.at(-1);\n    if (!body.text) {\n        body.text = { text: \"\", styles: [], lists: [] };\n    }\n    return body.text;\n}, _SlideBuilder_addListToBody = function _SlideBuilder_addListToBody(token) {\n    const { items } = token;\n    const bodyText = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_getBodyText).call(this);\n    const listOffset = bodyText.text.length;\n    let length = 0;\n    let localOffset = listOffset;\n    const addListItems = (depth, items) => {\n        items.forEach((item) => {\n            const [textToken, listToken] = item.tokens;\n            const { text, styles } = __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_parseText).call(this, textToken.tokens, localOffset);\n            bodyText.text += `${\"\\t\".repeat(depth)}${text}`;\n            __classPrivateFieldSet(this, _SlideBuilder_depthAdjustment, __classPrivateFieldGet(this, _SlideBuilder_depthAdjustment, \"f\") + depth, \"f\");\n            localOffset += text.length;\n            length += text.length;\n            bodyText.styles.push(...styles);\n            if (listToken) {\n                addListItems(depth + 1, listToken.items);\n            }\n        });\n    };\n    addListItems(0, items);\n    bodyText.lists.push({ start: listOffset, end: listOffset + length });\n}, _SlideBuilder_parseText = function _SlideBuilder_parseText(tokens, current = 0) {\n    let text = \"\";\n    const styles = [];\n    const images = [];\n    tokens.forEach((token) => {\n        if (token.type === \"image\") {\n            images.push(__classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_addImage).call(this, token));\n            return;\n        }\n        const { type, raw: t } = token;\n        const length = t.length;\n        text += unescape(t);\n        const range = { start: current, end: current + length };\n        switch (type) {\n            case \"strong\":\n                styles.push({ range, bold: true });\n                break;\n            case \"em\":\n                styles.push({ range, italic: true });\n                break;\n            case \"del\":\n                styles.push({ range, strikethrough: true });\n                break;\n            case \"link\":\n                styles.push({ range, link: token.href });\n                break;\n        }\n        current += length;\n    });\n    return { text: `${text}\\n`, styles, lists: [], images };\n}, _SlideBuilder_finalizeSlide = function _SlideBuilder_finalizeSlide() {\n    const slide = __classPrivateFieldGet(this, _SlideBuilder_instances, \"a\", _SlideBuilder_slide_get);\n    if (!slide)\n        return;\n    const hasText = !!slide.body?.at(0)?.text?.text;\n    if (!hasText) {\n        slide.layout = \"TITLE\";\n    }\n    else {\n        slide.layout = \"TITLE_AND_BODY\";\n        delete slide.subtitle;\n    }\n    __classPrivateFieldSet(this, _SlideBuilder_depthAdjustment, 0, \"f\");\n}, _SlideBuilder_newSlide = function _SlideBuilder_newSlide() {\n    __classPrivateFieldGet(this, _SlideBuilder_instances, \"m\", _SlideBuilder_finalizeSlide).call(this);\n    __classPrivateFieldGet(this, _SlideBuilder_slides, \"f\").push({\n        objectId: `Slide-${__classPrivateFieldGet(this, _SlideBuilder_startIndex, \"f\") + __classPrivateFieldGet(this, _SlideBuilder_slides, \"f\").length}`,\n        layout: \"TITLE_AND_BODY\",\n        body: [],\n    });\n}, _SlideBuilder_addImage = function _SlideBuilder_addImage(token) {\n    const id = __classPrivateFieldGet(this, _SlideBuilder_images, \"f\").length;\n    __classPrivateFieldGet(this, _SlideBuilder_images, \"f\").push(token);\n    return id;\n};\nfunction slidesToRequests(slides, imageUrls) {\n    const requests = [];\n    slides.forEach((slide) => {\n        const request = {\n            objectId: slide.objectId,\n            slideLayoutReference: { predefinedLayout: slide.layout },\n            placeholderIdMappings: mapPlaceholders(slide.objectId, slide.layout),\n        };\n        requests.push({ createSlide: request });\n        if (slide.title) {\n            requests.push({\n                insertText: {\n                    text: slide.title.text,\n                    objectId: `${slide.objectId}-title`,\n                },\n            });\n        }\n        if (slide.subtitle) {\n            requests.push({\n                insertText: {\n                    text: slide.subtitle.text,\n                    objectId: `${slide.objectId}-subtitle`,\n                },\n            });\n        }\n        slide.body.forEach((body) => {\n            const bodyText = body.text;\n            if (!bodyText)\n                return;\n            if (bodyText.images?.length) {\n                requests.push({\n                    createImage: {\n                        url: imageUrls[bodyText.images[0]],\n                        elementProperties: {\n                            pageObjectId: slide.objectId,\n                        },\n                    },\n                });\n            }\n            else if (bodyText.text) {\n                const objectId = `${slide.objectId}-body`;\n                requests.push({\n                    insertText: { text: bodyText.text, objectId },\n                });\n                bodyText.lists.forEach((list) => {\n                    requests.push({\n                        createParagraphBullets: {\n                            objectId,\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: list.start,\n                                endIndex: list.end,\n                            },\n                        },\n                    });\n                });\n                bodyText.styles.forEach((style) => {\n                    requests.push({\n                        updateTextStyle: {\n                            objectId,\n                            ...getTextStyle(style),\n                            textRange: {\n                                type: \"FIXED_RANGE\",\n                                startIndex: style.range.start,\n                                endIndex: style.range.end,\n                            },\n                        },\n                    });\n                });\n            }\n        });\n    });\n    return requests;\n}\nclass SimpleSlideBuilder {\n    constructor(last = 0, objectId) {\n        _SimpleSlideBuilder_slides.set(this, []);\n        _SimpleSlideBuilder_id.set(this, generateId());\n        _SimpleSlideBuilder_startIndex.set(this, void 0);\n        _SimpleSlideBuilder_objectToDelete.set(this, void 0);\n        __classPrivateFieldSet(this, _SimpleSlideBuilder_startIndex, last + 1, \"f\");\n        __classPrivateFieldSet(this, _SimpleSlideBuilder_objectToDelete, objectId, \"f\");\n    }\n    addSlide(s) {\n        const slide = {\n            objectId: `Slide-${__classPrivateFieldGet(this, _SimpleSlideBuilder_id, \"f\")}-${__classPrivateFieldGet(this, _SimpleSlideBuilder_startIndex, \"f\") + __classPrivateFieldGet(this, _SimpleSlideBuilder_slides, \"f\").length}`,\n            layout: \"BLANK\",\n            body: [],\n        };\n        __classPrivateFieldGet(this, _SimpleSlideBuilder_slides, \"f\").push(slide);\n        slide.title = simpleText(s.title);\n        if (s.subtitle) {\n            slide.subtitle = simpleText(s.subtitle);\n        }\n        if (s.body) {\n            slide.body = [{ text: simpleText(s.body) }];\n        }\n        const hasText = !!slide.body?.at(0)?.text?.text;\n        if (!hasText) {\n            slide.layout = \"TITLE\";\n        }\n        else {\n            slide.layout = \"TITLE_AND_BODY\";\n            delete slide.subtitle;\n        }\n        function simpleText(text) {\n            return { text, styles: [], lists: [] };\n        }\n    }\n    build(imageUrls) {\n        console.log(\"SLIDES\", __classPrivateFieldGet(this, _SimpleSlideBuilder_slides, \"f\"));\n        const requests = slidesToRequests(__classPrivateFieldGet(this, _SimpleSlideBuilder_slides, \"f\"), imageUrls);\n        if (__classPrivateFieldGet(this, _SimpleSlideBuilder_objectToDelete, \"f\")) {\n            requests.unshift({\n                deleteObject: {\n                    objectId: __classPrivateFieldGet(this, _SimpleSlideBuilder_objectToDelete, \"f\"),\n                },\n            });\n        }\n        return requests;\n    }\n}\n_SimpleSlideBuilder_slides = new WeakMap(), _SimpleSlideBuilder_id = new WeakMap(), _SimpleSlideBuilder_startIndex = new WeakMap(), _SimpleSlideBuilder_objectToDelete = new WeakMap();\nfunction getTextStyle(style) {\n    const { link: url, ...rest } = style;\n    const linkStyle = url ? { link: { url } } : {};\n    const fields = Object.keys(rest);\n    if (url)\n        fields.push(\"link\");\n    return { style: { ...linkStyle, ...rest }, fields: fields.join(\",\") };\n}\nfunction mapPlaceholders(slideId, layout) {\n    const mappings = [];\n    switch (layout) {\n        case \"TITLE\":\n            mappings.push({\n                layoutPlaceholder: { type: \"CENTERED_TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"SUBTITLE\", index: 0 },\n                objectId: `${slideId}-subtitle`,\n            });\n            break;\n        case \"TITLE_AND_BODY\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            mappings.push({\n                layoutPlaceholder: { type: \"BODY\", index: 0 },\n                objectId: `${slideId}-body`,\n            });\n            break;\n        case \"MAIN_POINT\":\n            mappings.push({\n                layoutPlaceholder: { type: \"TITLE\", index: 0 },\n                objectId: `${slideId}-title`,\n            });\n            break;\n    }\n    return mappings;\n}\n"
    },
    "types": {
      "code": "export {};\n"
    },
    "unescape": {
      "code": "export { unescape };\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/gi;\nconst namedEntities = {\n    colon: \":\",\n    quot: '\"',\n    amp: \"&\",\n    lt: \"<\",\n    gt: \">\",\n    apos: \"'\",\n    // add more as needed\n};\nfunction unescape(html) {\n    return html.replace(unescapeTest, (_, n) => {\n        n = n.toLowerCase();\n        if (n in namedEntities)\n            return namedEntities[n];\n        if (n.charAt(0) === \"#\") {\n            const code = n.charAt(1) === \"x\" ? parseInt(n.substring(2), 16) : +n.substring(1);\n            return code >= 0 && code <= 0x10ffff ? String.fromCodePoint(code) : \"\";\n        }\n        return \"\";\n    });\n}\n"
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:configurator",
    "#module:connector-save",
    "#module:connector-load"
  ]
}