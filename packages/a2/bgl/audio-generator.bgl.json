{
  "title": "A2 Audio Generation",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {
      "presentation": {
        "themes": {
          "5f3ca599-8fee-46fb-951f-0d47b16a6d56": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "5f3ca599-8fee-46fb-951f-0d47b16a6d56"
      }
    },
    "tags": [
      "published",
      "tool",
      "component"
    ]
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Generates audio (tts) output using supplied context.\n */\nimport { ArgumentNameGenerator } from \"./a2/introducer\";\nimport { ListExpander } from \"./a2/lists\";\nimport { executeStep, } from \"./a2/step-executor\";\nimport { Template } from \"./a2/template\";\nimport { ToolManager } from \"./a2/tool-manager\";\nimport { defaultLLMContent, encodeBase64, joinContent, ok, toLLMContent, toLLMContentInline, toLLMContentStored, toText, toTextConcat, } from \"./a2/utils\";\nconst VoiceMap = {\n    \"Male (English)\": \"en-US-male\",\n    \"Female (English)\": \"en-US-female\",\n}; // Use 'as const' for stricter type inference\nconst VOICES = Object.keys(VoiceMap);\nexport { invoke as default, describe };\nasync function callAudioGen(prompt, voice) {\n    let voiceParam = \"en-US-female\";\n    if (voice in VoiceMap) {\n        voiceParam = VoiceMap[voice];\n    }\n    const executionInputs = {};\n    executionInputs[\"text_to_speak\"] = {\n        chunks: [\n            {\n                mimetype: \"text/plain\",\n                data: encodeBase64(prompt),\n            },\n        ],\n    };\n    executionInputs[\"voice_key\"] = {\n        chunks: [\n            {\n                mimetype: \"text/plain\",\n                data: encodeBase64(voiceParam),\n            },\n        ],\n    };\n    const inputParameters = [\"text_to_speak\"];\n    const body = {\n        planStep: {\n            stepName: \"GenerateAudio\",\n            modelApi: \"tts\",\n            inputParameters: inputParameters,\n            systemPrompt: \"\",\n            output: \"generated_speech\",\n        },\n        execution_inputs: executionInputs,\n    };\n    const response = await executeStep(body);\n    if (!ok(response)) {\n        return toLLMContent(\"TTS generation failed: \" + response.$error);\n    }\n    if (!response.executionOutputs) {\n        return toLLMContent(\"TTS returned no audio\");\n    }\n    let returnVal;\n    for (const value of Object.values(response.executionOutputs)) {\n        const mimetype = value.chunks[0].mimetype;\n        if (mimetype.startsWith(\"audio\")) {\n            if (mimetype.endsWith(\"/storedData\")) {\n                returnVal = toLLMContentStored(mimetype.replace(\"/storedData\", \"\"), value.chunks[0].data);\n            }\n            else {\n                returnVal = toLLMContentInline(mimetype, value.chunks[0].data);\n            }\n        }\n    }\n    if (!returnVal) {\n        return toLLMContent(\"Error: No audio returned from backend\");\n    }\n    console.log(returnVal);\n    return returnVal;\n}\nasync function invoke({ context, text, voice, ...params }) {\n    context ?? (context = []);\n    let instructionText = \"\";\n    if (text) {\n        instructionText = toText(text).trim();\n    }\n    const template = new Template(toLLMContent(instructionText));\n    const toolManager = new ToolManager(new ArgumentNameGenerator());\n    const substituting = await template.substitute(params, async ({ path: url, instance }) => toolManager.addTool(url, instance));\n    if (!ok(substituting)) {\n        return substituting;\n    }\n    console.log(\"context\");\n    console.log(context);\n    console.log(\"instruction\");\n    console.log(text);\n    console.log(\"substituting\");\n    console.log(substituting);\n    const results = await new ListExpander(substituting, context).map(async (itemInstruction, itemContext) => {\n        const combinedInstruction = toTextConcat(joinContent(toText(itemInstruction), itemContext, false));\n        if (!combinedInstruction) {\n            return toLLMContent(\"Please provide the text to be converted to speech.\");\n        }\n        console.log(\"PROMPT: \", combinedInstruction);\n        return callAudioGen(combinedInstruction, voice);\n    });\n    if (!ok(results))\n        return results;\n    return { context: results };\n}\nasync function describe({ inputs: { text } }) {\n    const template = new Template(text);\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                text: {\n                    type: \"object\",\n                    behavior: [\"llm-content\", \"config\", \"hint-preview\"],\n                    title: \"Text\",\n                    description: \"Construct the inputs to be spoken with text-to-speech. Use @ to reference previous step outputs.\",\n                    default: defaultLLMContent(),\n                },\n                voice: {\n                    type: \"string\",\n                    behavior: [\"hint-text\", \"config\", \"hint-advanced\"],\n                    title: \"Voice\",\n                    icon: \"voice-selection\",\n                    enum: VOICES,\n                    description: \"The voice you'd like to generate with\",\n                    default: \"Female (English)\",\n                },\n                ...template.schemas(),\n            },\n            behavior: [\"at-wireable\"],\n            ...template.requireds(),\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                    behavior: [\"hint-audio\", \"main-port\"],\n                },\n            },\n            additionalProperties: false,\n        },\n        title: \"Make Speech\",\n        metadata: {\n            icon: \"generative-audio\",\n            tags: [\"quick-access\", \"generative\"],\n            order: 3,\n        },\n    };\n}\n"
    }
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "exports": [
    "#module:main"
  ]
}