/**
 * @fileoverview Gemini Model Family.
 */

import fetch from "@fetch";
import secrets from "@secrets";
import output from "@output";

import { ok, err, isLLMContentArray } from "./utils";
import { flattenContext } from "./lists";

const defaultSafetySettings = (): SafetySetting[] => [
  {
    category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    threshold: "OFF",
  },
  {
    category: "HARM_CATEGORY_HARASSMENT",
    threshold: "OFF",
  },
  {
    category: "HARM_CATEGORY_DANGEROUS_CONTENT",
    threshold: "OFF",
  },
];

function endpointURL(model: string) {
  // const $metadata = {
  //   title: "Get GEMINI_KEY",
  //   description: "Getting GEMINI_KEY from secrets",
  // };
  // const key = await secrets({ $metadata, keys: ["GEMINI_KEY"] });
  return `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`;
}

export { invoke as default, describe, defaultSafetySettings };

const VALID_MODALITIES = ["Text", "Text and Image", "Audio"] as const;
type ValidModalities = (typeof VALID_MODALITIES)[number];

export type HarmBlockThreshold =
  // Content with NEGLIGIBLE will be allowed.
  | "BLOCK_LOW_AND_ABOVE"
  // Content with NEGLIGIBLE and LOW will be allowed.
  | "BLOCK_MEDIUM_AND_ABOVE"
  // Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
  | "BLOCK_ONLY_HIGH"
  // All content will be allowed.
  | "BLOCK_NONE"
  // Turn off the safety filter.
  | "OFF";

export type HarmCategory =
  // Gemini - Harassment content
  | "HARM_CATEGORY_HARASSMENT"
  //	Gemini - Hate speech and content.
  | "HARM_CATEGORY_HATE_SPEECH"
  // Gemini - Sexually explicit content.
  | "HARM_CATEGORY_SEXUALLY_EXPLICIT"
  // 	Gemini - Dangerous content.
  | "HARM_CATEGORY_DANGEROUS_CONTENT"
  // Gemini - Content that may be used to harm civic integrity.
  | "HARM_CATEGORY_CIVIC_INTEGRITY";

export type GeminiSchema = {
  type: "string" | "number" | "integer" | "boolean" | "object" | "array";
  format?: string;
  description?: string;
  nullable?: boolean;
  enum?: string[];
  maxItems?: string;
  minItems?: string;
  properties?: Record<string, GeminiSchema>;
  required?: string[];
  items?: GeminiSchema;
};

export type Modality = "TEXT" | "IMAGE" | "AUDIO";

export type GenerationConfig = {
  responseMimeType?: "text/plain" | "application/json" | "text/x.enum";
  responseSchema?: GeminiSchema;
  responseModalities?: Modality[];
};

export type SafetySetting = {
  category: HarmCategory;
  threshold: HarmBlockThreshold;
};

export type Metadata = {
  title?: string;
  description?: string;
};

export type GeminiBody = {
  contents: LLMContent[];
  tools?: Tool[];
  toolConfig?: ToolConfig;
  systemInstruction?: LLMContent;
  safetySettings?: SafetySetting[];
  generationConfig?: GenerationConfig;
};

export type GeminiInputs = {
  // The wireable/configurable properties.
  model?: string;
  context?: LLMContent[];
  systemInstruction?: LLMContent;
  prompt?: LLMContent;
  modality?: ValidModalities;
  // The "private API" properties
  $metadata?: Metadata;
  body: GeminiBody;
};

export type Tool = {
  functionDeclarations?: FunctionDeclaration[];
  googleSearch?: {};
  codeExecution?: CodeExecution[];
};

export type ToolConfig = {
  functionCallingConfig?: FunctionCallingConfig;
};

export type FunctionCallingConfig = {
  mode?: "MODE_UNSPECIFIED" | "AUTO" | "ANY" | "NONE";
  allowedFunctionNames?: string[];
};

export type FunctionDeclaration = {
  name: string;
  description: string;
  parameters?: GeminiSchema;
};

export type CodeExecution = {
  // Type contains no fields.
};

export type FinishReason =
  // Natural stop point of the model or provided stop sequence.
  | "STOP"
  // The maximum number of tokens as specified in the request was reached.
  | "MAX_TOKENS"
  // The response candidate content was flagged for safety reasons.
  | "SAFETY"
  // The response candidate content was flagged for image safety reasons.
  | "IMAGE_SAFETY"
  // The response candidate content was flagged for recitation reasons.
  | "RECITATION"
  // The response candidate content was flagged for using an unsupported language.
  | "LANGUAGE"
  // Unknown reason.
  | "OTHER"
  // Token generation stopped because the content contains forbidden terms.
  | "BLOCKLIST"
  // Token generation stopped for potentially containing prohibited content.
  | "PROHIBITED_CONTENT"
  // Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
  | "SPII"
  // The function call generated by the model is invalid.
  | "MALFORMED_FUNCTION_CALL";

export type GroundingMetadata = {
  groundingChunks: {
    web: {
      uri: string;
      title: string;
    };
  }[];
  groundingSupports: {
    groundingChunkIndices: number[];
    confidenceScores: number[];
    segment: {
      partIndex: number;
      startIndex: number;
      endIndex: number;
      text: string;
    };
  };
  webSearchQueries: string[];
  searchEntryPoint: {
    renderedContent: string;
    /**
     * Base64 encoded JSON representing array of <search term, search url> tuple.
     * A base64-encoded string.
     */
    sdkBlob: string;
  };
  retrievalMetadata: {
    googleSearchDynamicRetrievalScore: number;
  };
};

export type Candidate = {
  content?: LLMContent;
  finishReason?: FinishReason;
  safetyRatings?: SafetySetting[];
  tokenOutput: number;
  groundingMetadata: GroundingMetadata;
};

export type GeminiAPIOutputs = {
  candidates: Candidate[];
};

export type GeminiOutputs =
  | GeminiAPIOutputs
  | {
      context: LLMContent[];
    };

const MODELS: readonly string[] = [
  "gemini-2.0-flash",
  "gemini-2.0-flash-001",
  "gemini-2.0-flash-lite-preview-02-05",
  "gemini-2.0-flash-exp",
  "gemini-2.0-flash-thinking-exp",
  "gemini-2.0-flash-thinking-exp-01-21",
  "gemini-2.0-pro-exp-02-05",
  "gemini-1.5-flash-latest",
  "gemini-1.5-pro-latest",
  "gemini-exp-1206",
  "gemini-exp-1121",
  "learnlm-1.5-pro-experimental",
  "gemini-1.5-pro-001",
  "gemini-1.5-pro-002",
  "gemini-1.5-pro-exp-0801",
  "gemini-1.5-pro-exp-0827",
  "gemini-1.5-flash-001",
  "gemini-1.5-flash-002",
  "gemini-1.5-flash-8b-exp-0924",
  "gemini-1.5-flash-8b-exp-0827",
  "gemini-1.5-flash-exp-0827",
];

const NO_RETRY_CODES: readonly number[] = [400, 429, 404, 403];

type FetchErrorResponse = {
  $error: string;
  status: number;
  statusText: string;
  contentType: string;
  responseHeaders: Record<string, string>;
};

/**
 * Using
 * `{"error":{"code":400,"message":"Invalid JSON payloâ€¦'contents[0].parts[0]': Cannot find field."}]}]}
 * as template for this type.
 */
type GeminiError = {
  error: {
    code: number;
    details: {
      type: string;
      fieldViolations: {
        description: string;
        field: string;
      }[];
    }[];
    message: string;
    status: string;
  };
};

/**
 * Modifies the body to remove any
 * Breadboard-specific extensions to LLM Content
 */
function conformBody(body: GeminiBody): GeminiBody {
  return {
    ...body,
    contents: flattenContext(
      body.contents.map((content) => {
        return {
          ...content,
          parts: content.parts.map((part) => {
            if ("json" in part) {
              return { text: JSON.stringify(part.json) };
            }
            return part;
          }),
        };
      }),
      true
    ),
  };
}

async function getAccessToken() {
  const signInSecretName = "connection:$sign-in";
  const result = await secrets({ keys: [signInSecretName] });
  return result[signInSecretName];
}

async function callAPI(
  retries: number,
  model: string,
  body: GeminiBody,
  $metadata?: Metadata
): Promise<Outcome<GeminiAPIOutputs>> {
  const accessToken = await getAccessToken();
  let $error: string = "Unknown error";
  while (retries) {
    const result = await fetch({
      $metadata,
      url: endpointURL(model),
      method: "POST",
      headers: {
        Authorization: `Bearer ${accessToken}`,
      },
      body: conformBody(body),
    });
    if (!ok(result)) {
      // Fetch is a bit weird, because it returns various props
      // along with the `$error`. Let's handle that here.
      const { status, $error: errObject } = result as FetchErrorResponse;
      if (!status) {
        if (errObject) return { $error: errObject };
        // This is not an error response, presume fatal error.
        return { $error };
      }
      $error = maybeExtractError(errObject);
      if (NO_RETRY_CODES.includes(status)) {
        return { $error };
      }
    } else {
      const outputs = result.response as GeminiAPIOutputs;
      const candidate = outputs.candidates?.at(0);
      if (!candidate) {
        return err("Unable to get a good response from Gemini");
      }
      if ("content" in candidate) {
        return outputs;
      }
      if (candidate.finishReason === "IMAGE_SAFETY") {
        return err(
          "The response candidate content was flagged for image safety reasons."
        );
      }
    }
    retries--;
  }
  return { $error };
}

function maybeExtractError(e: string): string {
  try {
    const parsed = JSON.parse(e) as GeminiError;
    return parsed.error.message;
  } catch (error) {
    return e;
  }
}

function isEmptyLLMContent(content?: LLMContent): content is undefined {
  if (!content || !content.parts || content.parts.length === 0) return true;
  return content.parts.every((part) => {
    if ("text" in part) {
      return !part.text?.trim();
    }
    return true;
  });
}

function addModality(body: GeminiBody, modality?: ValidModalities) {
  if (!modality) return;
  switch (modality) {
    case "Text":
      // No change, defaults.
      break;
    case "Text and Image":
      body.generationConfig ??= {};
      body.generationConfig.responseModalities = ["TEXT", "IMAGE"];
      break;
    case "Audio":
      body.generationConfig ??= {};
      body.generationConfig.responseModalities = ["AUDIO"];
      break;
  }
}

function constructBody(
  context: LLMContent[] = [],
  systemInstruction?: LLMContent,
  prompt?: LLMContent,
  modality?: ValidModalities
): GeminiBody {
  const contents = [...context];
  if (!isEmptyLLMContent(prompt)) {
    contents.push(prompt);
  }
  const body: GeminiBody = {
    contents,
    safetySettings: defaultSafetySettings(),
  };
  const canHaveSystemInstruction = modality === "Text";
  if (!isEmptyLLMContent(systemInstruction) && canHaveSystemInstruction) {
    body.systemInstruction = systemInstruction;
  }
  addModality(body, modality);
  return body;
}

function augmentBody(
  body: GeminiBody,
  systemInstruction?: LLMContent,
  prompt?: LLMContent,
  modality?: ValidModalities
): GeminiBody {
  if (!body.systemInstruction || !isEmptyLLMContent(systemInstruction)) {
    body.systemInstruction = systemInstruction;
  }
  if (!isEmptyLLMContent(prompt)) {
    body.contents = [...body.contents, prompt];
  }
  addModality(body, modality);
  return body;
}

function validateInputs(inputs: GeminiInputs): Outcome<void> {
  if ("body" in (inputs as object)) {
    return;
  }
  if (inputs.context) {
    const { context } = inputs;
    if (!Array.isArray(context)) {
      return err("Incoming context must be an array.");
    }
    if (!isLLMContentArray(context)) {
      return err("Malformed incoming context");
    }
    return;
  }
  return err("Either body or context is required");
}

async function invoke(inputs: GeminiInputs): Promise<Outcome<GeminiOutputs>> {
  const validatingInputs = validateInputs(inputs);
  if (!ok(validatingInputs)) {
    return validatingInputs;
  }
  let { model } = inputs;
  if (!model) {
    model = MODELS[0];
  }
  const { context, systemInstruction, prompt, modality, body, $metadata } =
    inputs;
  // TODO: Make this configurable.
  const retries = 5;
  if (!("body" in inputs)) {
    // Public API is being used.
    // Behave as if we're wired in.
    const result = await callAPI(
      retries,
      model,
      constructBody(context, systemInstruction, prompt, modality)
    );
    if (!ok(result)) {
      return result;
    }
    const content = result.candidates.at(0)?.content;
    if (!content) {
      return err("Unable to get a good response from Gemini");
    }
    return { context: [...context!, content] };
  } else {
    // Private API is being used.
    // Behave as if we're being invoked.
    return callAPI(
      retries,
      model,
      augmentBody(body, systemInstruction, prompt, modality),
      $metadata
    );
  }
}

type DescribeInputs = {
  inputs: {
    modality?: ValidModalities;
    model: string;
  };
};

async function describe({ inputs }: DescribeInputs) {
  const canHaveModalities = inputs.model === "gemini-2.0-flash-exp";
  const canHaveSystemInstruction =
    !canHaveModalities || (canHaveModalities && inputs.modality == "Text");
  const maybeAddSystemInstruction: Schema["properties"] =
    canHaveSystemInstruction
      ? {
          systemInstruction: {
            type: "object",
            behavior: ["llm-content", "config"],
            title: "System Instruction",
            default: '{"role":"user","parts":[{"text":""}]}',
            description:
              "(Optional) Give the model additional context on what to do," +
              "like specific rules/guidelines to adhere to or specify behavior" +
              "separate from the provided context",
          },
        }
      : {};
  const maybeAddModalities: Schema["properties"] = canHaveModalities
    ? {
        modality: {
          type: "string",
          enum: [...VALID_MODALITIES],
          title: "Output Modality",
          behavior: ["config"],
          description:
            "(Optional) Tell the model what kind of output you're looking for.",
        },
      }
    : {};
  return {
    inputSchema: {
      type: "object",
      properties: {
        model: {
          type: "string",
          behavior: ["config"],
          title: "Model Name",
          enum: MODELS as string[],
          default: MODELS[0],
        },
        prompt: {
          type: "object",
          behavior: ["llm-content", "config"],
          title: "Prompt",
          default: '{"role":"user","parts":[{"text":""}]}',
          description:
            "(Optional) A prompt. Will be added to the end of the the conversation context.",
        },
        ...maybeAddSystemInstruction,
        ...maybeAddModalities,
        context: {
          type: "array",
          items: {
            type: "object",
            behavior: ["llm-content"],
          },
          title: "Context in",
          behavior: ["main-port"],
        },
      },
    } satisfies Schema,
    outputSchema: {
      type: "object",
      properties: {
        context: {
          type: "array",
          items: {
            type: "object",
            behavior: ["llm-content"],
          },
          title: "Context out",
        },
      },
    } satisfies Schema,
    metadata: {
      icon: "generative",
    },
  };
}
