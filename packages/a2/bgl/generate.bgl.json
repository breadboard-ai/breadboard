{
  "title": "A2 Generate",
  "description": "",
  "version": "0.0.1",
  "nodes": [],
  "edges": [],
  "metadata": {
    "comments": [
      {
        "id": "comment-cc94afe8",
        "text": "Intentionally Left Blank",
        "metadata": {
          "title": "Comment",
          "visual": {
            "x": 531,
            "y": 374,
            "collapsed": "expanded",
            "outputHeight": 0
          }
        }
      }
    ],
    "visual": {
      "presentation": {
        "themes": {
          "5f3ca599-8fee-46fb-951f-0d47b16a6d56": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "5f3ca599-8fee-46fb-951f-0d47b16a6d56"
      }
    },
    "tags": [
      "published",
      "tool",
      "component"
    ],
    "userModified": true
  },
  "imports": {
    "a2": {
      "url": "./a2.bgl.json"
    }
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Mega step for generation capabilities.\n */\nimport describeGraph from \"@describe\";\nimport invokeGraph from \"@invoke\";\nimport { ok } from \"./a2/utils\";\nimport { readFlags } from \"./a2/settings\";\nimport { forEach } from \"./a2/for-each\";\nexport { invoke as default, describe };\nconst MODES = [\n    {\n        id: \"text-2.0-flash\",\n        type: \"text\",\n        url: \"embed://a2/generate-text.bgl.json#daf082ca-c1aa-4aff-b2c8-abeb984ab66c\",\n        title: \"Gemini 2.0 Flash\",\n        description: \"For everyday tasks, plus more\",\n        icon: \"text_analysis\",\n        modelName: \"gemini-2.0-flash\",\n        promptPlaceholderText: \"Type your prompt here. Use @ to include other content.\",\n    },\n    {\n        id: \"text\",\n        type: \"text\",\n        url: \"embed://a2/generate-text.bgl.json#daf082ca-c1aa-4aff-b2c8-abeb984ab66c\",\n        title: \"Gemini 2.5 Flash\",\n        description: \"Uses advanced reasoning\",\n        icon: \"text_analysis\",\n        modelName: \"gemini-2.5-flash-preview-05-20\",\n        promptPlaceholderText: \"Type your prompt here. Use @ to include other content.\",\n    },\n    {\n        id: \"text-2.5-pro\",\n        type: \"text\",\n        url: \"embed://a2/generate-text.bgl.json#daf082ca-c1aa-4aff-b2c8-abeb984ab66c\",\n        title: \"Gemini 2.5 Pro\",\n        description: \"Best for complex tasks\",\n        icon: \"text_analysis\",\n        modelName: \"gemini-2.5-pro-preview-06-05\",\n        promptPlaceholderText: \"Type your prompt here. Use @ to include other content.\",\n    },\n    {\n        id: \"think\",\n        type: \"think\",\n        url: \"embed://a2/go-over-list.bgl.json#module:main\",\n        title: \"Plan and Execute with Gemini 2.0 Flash\",\n        description: \"Plans and executes complex tasks\",\n        icon: \"spark\",\n        modelName: \"gemini-2.0-flash\",\n        promptPlaceholderText: \"Type your goal here. Use @ to include other content.\",\n    },\n    {\n        id: \"deep-research\",\n        type: \"deep-research\",\n        url: \"embed://a2/deep-research.bgl.json#module:main\",\n        title: \"Deep Research with Gemini 2.5 Flash\",\n        description: \"In-depth research on your topic\",\n        icon: \"spark\",\n        modelName: \"gemini-2.5-flash\",\n        promptPlaceholderText: \"Type your research query here. Use @ to include other content.\",\n    },\n    {\n        id: \"image-gen\",\n        type: \"image-gen\",\n        url: \"embed://a2/a2.bgl.json#module:image-generator\",\n        title: \"Imagen 4\",\n        description: \"Generates images from text\",\n        icon: \"photo_spark\",\n        promptPlaceholderText: \"Type your image prompt here. Use @ to include other content.\",\n        info: \"Image generation has limited free quota\",\n    },\n    {\n        id: \"image\",\n        type: \"image\",\n        url: \"embed://a2/a2.bgl.json#module:image-editor\",\n        title: \"Gemini 2.0 Flash: Image Generation\",\n        description: \"Generates images from text and images\",\n        icon: \"photo_spark\",\n        promptPlaceholderText: \"Type your image prompt here. Use @ to include other content.\",\n        info: \"Image generation has limited free quota\",\n    },\n    {\n        id: \"audio\",\n        type: \"audio\",\n        url: \"embed://a2/audio-generator.bgl.json#module:main\",\n        title: \"AudioLM\",\n        description: \"Generates speech from text\",\n        icon: \"audio_magic_eraser\",\n        promptPlaceholderText: \"Type the text to speak here. Use @ to include other content.\",\n        info: \"Audio generation has limited free quota\",\n    },\n    {\n        id: \"video\",\n        type: \"video\",\n        url: \"embed://a2/video-generator.bgl.json#module:main\",\n        title: \"Veo\",\n        description: \"Generates videos from text and images\",\n        icon: \"videocam_auto\",\n        promptPlaceholderText: \"Type your video prompt here. Use @ to include other content.\",\n        info: \"Video generation has limited free quota\",\n    },\n    {\n        id: \"music\",\n        type: \"music\",\n        url: \"embed://a2/music-generator.bgl.json#module:main\",\n        title: \"Lyria 2\",\n        description: \"Generates instrumental music from text\",\n        icon: \"audio_magic_eraser\",\n        promptPlaceholderText: \"Type your music prompt here. Use @ to include other content.\",\n        info: \"Music generation has limited free quota\",\n    },\n];\nconst DEFAULT_MODE = MODES[0];\nconst modeMap = new Map(MODES.map((mode) => [mode.id, mode]));\nconst PROMPT_PORT = \"config$prompt\";\nconst ASK_USER_PORT = \"config$ask-user\";\nconst LIST_PORT = \"config$list\";\n// Maps the prompt port to various names of the other ports.\nconst portMapForward = new Map([\n    [\n        MODES[0].id,\n        new Map([\n            [PROMPT_PORT, \"description\"],\n            [ASK_USER_PORT, \"p-chat\"],\n            [LIST_PORT, \"p-list\"],\n        ]),\n    ],\n    [\n        MODES[1].id,\n        new Map([\n            [PROMPT_PORT, \"description\"],\n            [ASK_USER_PORT, \"p-chat\"],\n            [LIST_PORT, \"p-list\"],\n        ]),\n    ],\n    [\n        MODES[2].id,\n        new Map([\n            [PROMPT_PORT, \"description\"],\n            [ASK_USER_PORT, \"p-chat\"],\n            [LIST_PORT, \"p-list\"],\n        ]),\n    ],\n    [\n        MODES[3].id,\n        new Map([\n            [PROMPT_PORT, \"plan\"],\n            [LIST_PORT, \"z-list\"],\n        ]),\n    ],\n    [\n        MODES[4].id,\n        new Map([\n            [PROMPT_PORT, \"query\"],\n            [LIST_PORT, \"z-list\"],\n        ]),\n    ],\n    [MODES[5].id, new Map([[PROMPT_PORT, \"instruction\"]])],\n    [MODES[6].id, new Map([[PROMPT_PORT, \"instruction\"]])],\n    [MODES[7].id, new Map([[PROMPT_PORT, \"text\"]])],\n    [MODES[8].id, new Map([[PROMPT_PORT, \"instruction\"]])],\n    [MODES[9].id, new Map([[PROMPT_PORT, \"text\"]])],\n]);\nconst portMapReverse = new Map(Array.from(portMapForward.entries()).map(([mode, map]) => {\n    const inverted = new Map();\n    for (const [from, to] of map) {\n        inverted.set(to, from);\n    }\n    return [mode, inverted];\n}));\nfunction translate(ports, map) {\n    return Object.fromEntries(Object.entries(ports).map(([name, value]) => [map.get(name) || name, value]));\n}\nfunction forwardPorts(mode, ports) {\n    const forwardingMap = portMapForward.get(mode);\n    if (!forwardingMap)\n        return ports;\n    return translate(ports, forwardingMap);\n}\nfunction receivePorts(mode, ports) {\n    const reverseMap = portMapReverse.get(mode);\n    if (!reverseMap)\n        return ports;\n    return translate(ports, reverseMap);\n}\nfunction getMode(modeId) {\n    return modeMap.get(modeId || DEFAULT_MODE.id) || DEFAULT_MODE;\n}\nasync function invoke({ \"generation-mode\": mode, ...rest }) {\n    const { url: $board, type, modelName } = getMode(mode);\n    const flags = await readFlags();\n    let generateForEach = false;\n    if (ok(flags)) {\n        generateForEach = flags.generateForEach;\n    }\n    // Model is treated as part of the Mode, but actually maps N:1\n    // on actual underlying step type.\n    if (modelName) {\n        console.log(`Generating with ${modelName}`);\n        rest[\"p-model-name\"] = modelName;\n    }\n    if (generateForEach) {\n        return forEach(rest, async (prompt) => {\n            const ports = { ...rest };\n            ports[PROMPT_PORT] = prompt;\n            return invokeGraph({ $board, ...forwardPorts(type, ports) });\n        });\n    }\n    else {\n        return invokeGraph({ $board, ...forwardPorts(type, rest) });\n    }\n}\nasync function describe({ inputs: { \"generation-mode\": mode, ...rest }, asType, }) {\n    const metadata = {\n        title: \"Generate\",\n        description: \"Uses Gemini to generate content and call tools\",\n        metadata: {\n            icon: \"generative\",\n            tags: [\"quick-access\", \"generative\", \"generate\"],\n            order: 1,\n        },\n    };\n    // When asked for to be described as type, skip trying to\n    // get the detailed schema and just return metadata.\n    if (asType) {\n        return {\n            ...metadata,\n            inputSchema: {},\n            outputSchema: {},\n        };\n    }\n    const flags = await readFlags();\n    let generateForEachSchema = {};\n    const generateForEachBehavior = [];\n    if (ok(flags) && flags.generateForEach) {\n        generateForEachSchema = {\n            \"p-for-each\": {\n                type: \"boolean\",\n                title: \"Generate for each input\",\n                behavior: [\"config\", \"hint-preview\", \"hint-advanced\"],\n                icon: \"summarize\",\n                description: \"When checked, this step will try to detect a list of items as its input and run for each item in the list\",\n            },\n        };\n        generateForEachBehavior.push(\"hint-for-each-mode\");\n    }\n    const { url, type } = getMode(mode);\n    const describing = await describeGraph({ url, inputs: rest });\n    const behavior = [...generateForEachBehavior];\n    let modeSchema = {};\n    if (ok(describing)) {\n        modeSchema = receivePorts(type, describing.inputSchema.properties || modeSchema);\n        behavior.push(...(describing.inputSchema.behavior || []));\n    }\n    return {\n        title: \"Generate\",\n        description: \"Uses Gemini to generate content and call tools\",\n        metadata: {\n            icon: \"generative\",\n            tags: [\"quick-access\", \"generative\", \"generate\"],\n            order: 1,\n        },\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                \"generation-mode\": {\n                    type: \"string\",\n                    title: \"Mode\",\n                    enum: MODES,\n                    behavior: [\"config\", \"hint-preview\", \"reactive\", \"hint-controller\"],\n                },\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                    behavior: [\"main-port\"],\n                },\n                ...generateForEachSchema,\n                ...modeSchema,\n            },\n            behavior,\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                    behavior: [\"main-port\"],\n                },\n            },\n        },\n    };\n}\n"
    }
  },
  "exports": [
    "#module:main"
  ],
  "assets": {}
}