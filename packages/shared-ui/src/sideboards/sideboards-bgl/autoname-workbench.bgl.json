{
  "title": "Autoname Workbench",
  "description": "",
  "version": "0.0.1",
  "main": "main",
  "nodes": [
    {
      "id": "input",
      "type": "input",
      "metadata": {
        "title": "Input"
      }
    },
    {
      "id": "run-module",
      "type": "runModule",
      "configuration": {
        "$module": "main"
      },
      "metadata": {
        "title": "Autoname Workbench"
      }
    },
    {
      "id": "output",
      "type": "output",
      "metadata": {
        "title": "Output"
      }
    }
  ],
  "edges": [
    {
      "from": "input",
      "to": "run-module",
      "out": "*",
      "in": ""
    },
    {
      "from": "run-module",
      "to": "output",
      "out": "*",
      "in": ""
    }
  ],
  "metadata": {
    "visual": {
      "presentation": {
        "themes": {
          "39239b49-62d0-4182-b919-924c4db67941": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "39239b49-62d0-4182-b919-924c4db67941"
      }
    },
    "userModified": true,
    "tags": [],
    "parameters": {}
  },
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Add a description for your module here.\n */\nimport invokeGraph from \"@invoke\";\nimport output from \"@output\";\nimport { EVAL_SET } from \"./eval-set\";\nexport { invoke as default, describe };\nasync function autoname(json, description) {\n    const inputs = {\n        context: [{ parts: [{ json }] }],\n    };\n    const autonaming = (await invokeGraph({\n        $board: \"file://sideboards-bgl/autoname.bgl.json\",\n        ...inputs,\n    }));\n    if (\"$error\" in autonaming) {\n        console.error(\"ERROR AUTONAMING\", autonaming.$error);\n        return;\n    }\n    await report(autonaming.context, description);\n}\nasync function invoke() {\n    for (const item of EVAL_SET) {\n        const { description, ...inputs } = item;\n        await autoname(inputs, description);\n    }\n    return { context: [] };\n}\nasync function describe() {\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {},\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\nasync function report(details, description) {\n    const title = description;\n    const detailsSchema = {\n        title,\n        type: \"object\",\n        behavior: [\"llm-content\"],\n    };\n    const schema = {\n        type: \"object\",\n        properties: {\n            details: detailsSchema,\n        },\n    };\n    const { delivered } = await output({\n        $metadata: {\n            title,\n        },\n        schema,\n        details,\n    });\n    return delivered;\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Add a description for your module here.\n */\n\nimport invokeGraph from \"@invoke\";\nimport output from \"@output\";\n\nimport { EVAL_SET } from \"./eval-set\";\n\nexport { invoke as default, describe };\n\nexport type Inputs = {\n  context: LLMContent[];\n};\n\nexport type Outputs = {\n  context: LLMContent[];\n};\n\nasync function autoname(json: JsonSerializable, description: string) {\n  const inputs: Inputs = {\n    context: [{ parts: [{ json }] }],\n  };\n  const autonaming = (await invokeGraph({\n    $board: \"file://sideboards-bgl/autoname.bgl.json\",\n    ...inputs,\n  })) as Outcome<Outputs>;\n  if (\"$error\" in autonaming) {\n    console.error(\"ERROR AUTONAMING\", autonaming.$error);\n    return;\n  }\n  await report(autonaming.context, description);\n}\n\nasync function invoke(): Promise<Outcome<Outputs>> {\n  for (const item of EVAL_SET) {\n    const { description, ...inputs } = item;\n    await autoname(inputs, description);\n  }\n  return { context: [] };\n}\n\nasync function describe() {\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {},\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n    } satisfies Schema,\n  };\n}\n\nasync function report(\n  details: LLMContent[],\n  description: string\n): Promise<boolean> {\n  const title = description;\n\n  const detailsSchema: Schema = {\n    title,\n    type: \"object\",\n    behavior: [\"llm-content\"],\n  };\n\n  const schema: Schema = {\n    type: \"object\",\n    properties: {\n      details: detailsSchema,\n    },\n  };\n\n  const { delivered } = await output({\n    $metadata: {\n      title,\n    },\n    schema,\n    details,\n  });\n  return delivered;\n}\n",
          "language": "typescript"
        },
        "description": "Add a description for your module here.",
        "runnable": true
      }
    },
    "eval-set": {
      "code": "/**\n * @fileoverview The Eval Set for Autoname\n */\nexport { EVAL_SET };\nconst USER_INPUT_TYPE = \"embed://a2/a2.bgl.json#21ee02e7-83fa-49d0-964c-0cab10eafc2c\";\nconst GENERATE_TYPE = \"embed://a2/generate.bgl.json#module:main\";\nconst DISPLAY_TYPE = \"embed://a2/a2.bgl.json#module:render-outputs\";\nconst EVAL_SET = [\n    {\n        description: \"User input with descriptive text\",\n        nodeConfigurationUpdate: {\n            type: USER_INPUT_TYPE,\n            configuration: {\n                description: {\n                    parts: [\n                        {\n                            text: \"Paste or type your document content here.\",\n                        },\n                    ],\n                    role: \"user\",\n                },\n                \"p-modality\": \"Any\",\n            },\n        },\n    },\n    {\n        description: \"User input with no text, but a chiclet\",\n        nodeConfigurationUpdate: {\n            type: USER_INPUT_TYPE,\n            configuration: {\n                description: {\n                    role: \"user\",\n                    parts: [\n                        {\n                            text: '{{\"type\":\"in\",\"path\":\"1464b633-d235-4b1c-ab2d-fb99e970bc98\",\"title\":\"Make Speech\"}}',\n                        },\n                    ],\n                },\n                \"p-modality\": \"Any\",\n            },\n        },\n    },\n    {\n        description: \"Generate game video\",\n        nodeConfigurationUpdate: {\n            type: GENERATE_TYPE,\n            configuration: {\n                config$prompt: {\n                    parts: [\n                        {\n                            text: '{{\"type\":\"in\",\"path\":\"node_step_video_instruction\",\"title\":\"Generate Video Instruction\"}}',\n                        },\n                    ],\n                    role: \"user\",\n                },\n                \"generation-mode\": \"video\",\n            },\n        },\n    },\n    {\n        description: \"Generate video descriptions\",\n        nodeConfigurationUpdate: {\n            configuration: {\n                config$prompt: {\n                    parts: [\n                        {\n                            text: 'You are a creative scriptwriter specializing in crafting concise and visually descriptive narratives for short video clips. Your task is to transform a documentary part summary into a detailed visual description suitable for input into a generative AI video model. The output should focus solely on describing the visual content of a video clip that will be less than 6 seconds long and contain no audio.\\n# Step by Step instructions\\n1. Take the provided Document Parts Summary.\\n2. Write a detailed visual description for the first part of the Document Parts Summary, ensuring it is suitable for a video clip less than 6 seconds long with no audio.\\n3. Check if you have generated a visual description for each part of the Document Parts Summary. If not, go back to step 2 and write a detailed visual description for the next part, making sure it is suitable for a video clip less than 6 seconds long with no audio.\\n\\n\\nDocument Parts Summary:\\n\"\"\"\\n{{\"type\":\"in\",\"path\":\"node_step_document_parts_summary\",\"title\":\"Divide Document Into Parts\"}}\\n\"\"\"\\nIMPORTANT NOTE: Start directly with the output, do not output any delimiters.\\nOutput:\\n',\n                        },\n                    ],\n                    role: \"user\",\n                },\n                \"generation-mode\": \"text\",\n                config$list: true,\n            },\n            type: GENERATE_TYPE,\n        },\n    },\n    {\n        description: \"Generate with list=false\",\n        nodeConfigurationUpdate: {\n            configuration: {\n                \"b-system-instruction\": {\n                    role: \"user\",\n                    parts: [\n                        {\n                            text: 'You are working as part of an AI system, so no chit-chat and no explaining what you\\'re doing and why.\\nDO NOT start with \"Okay\", or \"Alright\" or any preambles. Just the output, please.',\n                        },\n                    ],\n                },\n                \"config$ask-user\": false,\n                config$list: false,\n                config$prompt: {\n                    role: \"user\",\n                    parts: [\n                        {\n                            text: \"Write me a poem about monkeys. Make sure it's funny and lighthearted, and mentions donuts\",\n                        },\n                    ],\n                },\n                \"generation-mode\": \"text-2.0-flash\",\n            },\n            type: GENERATE_TYPE,\n        },\n    },\n    {\n        description: \"Generate HTML Page\",\n        nodeConfigurationUpdate: {\n            type: DISPLAY_TYPE,\n            configuration: {\n                text: {\n                    parts: [\n                        {\n                            text: 'Generate an HTML webpage that serves as a three-part documentary series. The webpage should display the videos and their corresponding scripts. The layout should be clean and easy to navigate, allowing users to watch each video and read its script sequentially. Consider a simple, responsive design.\\n\\ndocumentary_videos: {{\"type\":\"in\",\"path\":\"node_step_documentary_videos\",\"title\":\"Generate Documentary Videos\"}}\\n\\nvideo_scripts: {{\"type\":\"in\",\"path\":\"node_step_video_scripts\",\"title\":\"Generate Video Scripts\"}}',\n                        },\n                    ],\n                    role: \"user\",\n                },\n                \"b-system-instruction\": {\n                    parts: [\n                        {\n                            text: 'You are an AI Web Developer. Your task is to generate a single, self-contained HTML document for rendering in an iframe, based on user instructions and data.\\n\\n**Visual aesthetic:**\\n    * Aesthetics are crucial. Make the page look amazing, especially on mobile.\\n    * Respect any instructions on style, color palette, or reference examples provided by the user.\\n**Design & Functionality:**\\n    * Thoroughly analyze the user\\'s instructions to determine the desired type of webpage, application, or visualization. What are the key features, layouts, or functionality?\\n    * Analyze any provided data to identify the most compelling layout or visualization of it. For example, if the user requests a visualization, select an appropriate chart type (bar, line, pie, scatter, etc.) to create the most insightful and visually compelling representation. Or if user instructions say `use a carousel format`, you should consider how to break the content and any media into different card components to display within the carousel.\\n    * If requirements are underspecified, make reasonable assumptions to complete the design and functionality. Your goal is to deliver a working product with no placeholder content.\\n    * Ensure the generated code is valid and functional. Return only the code, and open the HTML codeblock with the literal string \"```html\".\\n    * The output must be a complete and valid HTML document with no placeholder content for the developer to fill in.\\n\\n**Libraries:**\\n  Unless otherwise specified, use:\\n    * Tailwind for CSS\\n',\n                        },\n                    ],\n                    role: \"user\",\n                },\n                \"p-render-mode\": \"Auto\",\n                \"b-render-model-name\": \"gemini-flash\",\n            },\n        },\n    },\n];\n",
      "metadata": {
        "title": "eval-set",
        "source": {
          "code": "/**\n * @fileoverview The Eval Set for Autoname\n */\n\nexport { EVAL_SET };\n\nconst USER_INPUT_TYPE =\n  \"embed://a2/a2.bgl.json#21ee02e7-83fa-49d0-964c-0cab10eafc2c\";\nconst GENERATE_TYPE = \"embed://a2/generate.bgl.json#module:main\";\nconst DISPLAY_TYPE = \"embed://a2/a2.bgl.json#module:render-outputs\";\n\ntype Eval = {\n  description: string;\n  nodeConfigurationUpdate: {\n    type: string;\n    configuration: Record<string, JsonSerializable>;\n  };\n};\n\nconst EVAL_SET: Eval[] = [\n  {\n    description: \"User input with descriptive text\",\n    nodeConfigurationUpdate: {\n      type: USER_INPUT_TYPE,\n      configuration: {\n        description: {\n          parts: [\n            {\n              text: \"Paste or type your document content here.\",\n            },\n          ],\n          role: \"user\",\n        },\n        \"p-modality\": \"Any\",\n      },\n    },\n  },\n  {\n    description: \"User input with no text, but a chiclet\",\n    nodeConfigurationUpdate: {\n      type: USER_INPUT_TYPE,\n      configuration: {\n        description: {\n          role: \"user\",\n          parts: [\n            {\n              text: '{{\"type\":\"in\",\"path\":\"1464b633-d235-4b1c-ab2d-fb99e970bc98\",\"title\":\"Make Speech\"}}',\n            },\n          ],\n        },\n        \"p-modality\": \"Any\",\n      },\n    },\n  },\n  {\n    description: \"Generate game video\",\n    nodeConfigurationUpdate: {\n      type: GENERATE_TYPE,\n      configuration: {\n        config$prompt: {\n          parts: [\n            {\n              text: '{{\"type\":\"in\",\"path\":\"node_step_video_instruction\",\"title\":\"Generate Video Instruction\"}}',\n            },\n          ],\n          role: \"user\",\n        },\n        \"generation-mode\": \"video\",\n      },\n    },\n  },\n  {\n    description: \"Generate video descriptions\",\n    nodeConfigurationUpdate: {\n      configuration: {\n        config$prompt: {\n          parts: [\n            {\n              text: 'You are a creative scriptwriter specializing in crafting concise and visually descriptive narratives for short video clips. Your task is to transform a documentary part summary into a detailed visual description suitable for input into a generative AI video model. The output should focus solely on describing the visual content of a video clip that will be less than 6 seconds long and contain no audio.\\n# Step by Step instructions\\n1. Take the provided Document Parts Summary.\\n2. Write a detailed visual description for the first part of the Document Parts Summary, ensuring it is suitable for a video clip less than 6 seconds long with no audio.\\n3. Check if you have generated a visual description for each part of the Document Parts Summary. If not, go back to step 2 and write a detailed visual description for the next part, making sure it is suitable for a video clip less than 6 seconds long with no audio.\\n\\n\\nDocument Parts Summary:\\n\"\"\"\\n{{\"type\":\"in\",\"path\":\"node_step_document_parts_summary\",\"title\":\"Divide Document Into Parts\"}}\\n\"\"\"\\nIMPORTANT NOTE: Start directly with the output, do not output any delimiters.\\nOutput:\\n',\n            },\n          ],\n          role: \"user\",\n        },\n        \"generation-mode\": \"text\",\n        config$list: true,\n      },\n      type: GENERATE_TYPE,\n    },\n  },\n  {\n    description: \"Generate with list=false\",\n    nodeConfigurationUpdate: {\n      configuration: {\n        \"b-system-instruction\": {\n          role: \"user\",\n          parts: [\n            {\n              text: 'You are working as part of an AI system, so no chit-chat and no explaining what you\\'re doing and why.\\nDO NOT start with \"Okay\", or \"Alright\" or any preambles. Just the output, please.',\n            },\n          ],\n        },\n        \"config$ask-user\": false,\n        config$list: false,\n        config$prompt: {\n          role: \"user\",\n          parts: [\n            {\n              text: \"Write me a poem about monkeys. Make sure it's funny and lighthearted, and mentions donuts\",\n            },\n          ],\n        },\n        \"generation-mode\": \"text-2.0-flash\",\n      },\n      type: GENERATE_TYPE,\n    },\n  },\n  {\n    description: \"Generate HTML Page\",\n    nodeConfigurationUpdate: {\n      type: DISPLAY_TYPE,\n      configuration: {\n        text: {\n          parts: [\n            {\n              text: 'Generate an HTML webpage that serves as a three-part documentary series. The webpage should display the videos and their corresponding scripts. The layout should be clean and easy to navigate, allowing users to watch each video and read its script sequentially. Consider a simple, responsive design.\\n\\ndocumentary_videos: {{\"type\":\"in\",\"path\":\"node_step_documentary_videos\",\"title\":\"Generate Documentary Videos\"}}\\n\\nvideo_scripts: {{\"type\":\"in\",\"path\":\"node_step_video_scripts\",\"title\":\"Generate Video Scripts\"}}',\n            },\n          ],\n          role: \"user\",\n        },\n        \"b-system-instruction\": {\n          parts: [\n            {\n              text: 'You are an AI Web Developer. Your task is to generate a single, self-contained HTML document for rendering in an iframe, based on user instructions and data.\\n\\n**Visual aesthetic:**\\n    * Aesthetics are crucial. Make the page look amazing, especially on mobile.\\n    * Respect any instructions on style, color palette, or reference examples provided by the user.\\n**Design & Functionality:**\\n    * Thoroughly analyze the user\\'s instructions to determine the desired type of webpage, application, or visualization. What are the key features, layouts, or functionality?\\n    * Analyze any provided data to identify the most compelling layout or visualization of it. For example, if the user requests a visualization, select an appropriate chart type (bar, line, pie, scatter, etc.) to create the most insightful and visually compelling representation. Or if user instructions say `use a carousel format`, you should consider how to break the content and any media into different card components to display within the carousel.\\n    * If requirements are underspecified, make reasonable assumptions to complete the design and functionality. Your goal is to deliver a working product with no placeholder content.\\n    * Ensure the generated code is valid and functional. Return only the code, and open the HTML codeblock with the literal string \"```html\".\\n    * The output must be a complete and valid HTML document with no placeholder content for the developer to fill in.\\n\\n**Libraries:**\\n  Unless otherwise specified, use:\\n    * Tailwind for CSS\\n',\n            },\n          ],\n          role: \"user\",\n        },\n        \"p-render-mode\": \"Auto\",\n        \"b-render-model-name\": \"gemini-flash\",\n      },\n    },\n  },\n];\n",
          "language": "typescript"
        },
        "description": "The Eval Set for Autoname",
        "runnable": false
      }
    }
  }
}