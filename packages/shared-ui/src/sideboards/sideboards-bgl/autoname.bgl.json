{
  "title": "Autonaming",
  "description": "",
  "version": "0.0.1",
  "imports": {
    "a2": {
      "url": "embed://a2/a2.bgl.json"
    }
  },
  "main": "main",
  "modules": {
    "main": {
      "code": "/**\n * @fileoverview Add a description for your module here.\n */\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { defaultSafetySettings } from \"./a2/gemini\";\nimport { err, ok, llm, isLLMContent, toText } from \"./a2/utils\";\nimport { NodeConfigurationUpdateMode } from \"./node-configuration-update\";\nexport { invoke as default, describe };\nfunction getArguments(context) {\n    const part = context?.at(-1)?.parts?.at(0);\n    if (!(part && \"json\" in part)) {\n        return err(`Invalid arguments: ${context}`);\n    }\n    return part.json;\n}\nfunction cantAutoname() {\n    return [{ parts: [{ json: { notEnoughContext: true } }] }];\n}\nconst MODES = {\n    nodeConfigurationUpdate: NodeConfigurationUpdateMode,\n};\nasync function invoke({ context }) {\n    const args = getArguments(context);\n    if (!ok(args))\n        return args;\n    const mode = MODES[Object.keys(args)[0]];\n    if (!mode) {\n        return err(`Unknown mode: ${JSON.stringify(args)}`);\n    }\n    const modeHandler = new mode(args);\n    if (!modeHandler.canAutoname()) {\n        return { context: cantAutoname() };\n    }\n    const naming = await new GeminiPrompt({\n        model: \"gemini-2.0-flash-lite\",\n        body: {\n            contents: modeHandler.prompt(),\n            safetySettings: defaultSafetySettings(),\n            generationConfig: {\n                responseMimeType: \"application/json\",\n                responseSchema: modeHandler.schema(),\n            },\n        },\n    }).invoke();\n    if (!ok(naming))\n        return naming;\n    return { context: naming.all };\n}\nasync function describe() {\n    return {\n        inputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context in\",\n                },\n            },\n        },\n        outputSchema: {\n            type: \"object\",\n            properties: {\n                context: {\n                    type: \"array\",\n                    items: { type: \"object\", behavior: [\"llm-content\"] },\n                    title: \"Context out\",\n                },\n            },\n        },\n    };\n}\n",
      "metadata": {
        "title": "main",
        "source": {
          "code": "/**\n * @fileoverview Add a description for your module here.\n */\n\nimport { GeminiPrompt } from \"./a2/gemini-prompt\";\nimport { type GeminiSchema, defaultSafetySettings } from \"./a2/gemini\";\nimport { err, ok, llm, isLLMContent, toText } from \"./a2/utils\";\n\nimport type { AutonameMode, Arguments, NodeConfigurationUpdate } from \"./types\";\nimport { NodeConfigurationUpdateMode } from \"./node-configuration-update\";\n\nexport { invoke as default, describe };\n\ntype Inputs = {\n  context: LLMContent[];\n};\n\ntype Outputs = {\n  context: LLMContent[];\n};\n\nfunction getArguments(context?: LLMContent[]): Outcome<Arguments> {\n  const part = context?.at(-1)?.parts?.at(0);\n  if (!(part && \"json\" in part)) {\n    return err(`Invalid arguments: ${context}`);\n  }\n  return part.json as Arguments;\n}\n\nfunction cantAutoname() {\n  return [{ parts: [{ json: { notEnoughContext: true } }] }];\n}\n\nconst MODES: Record<string, new (args: Arguments) => AutonameMode> = {\n  nodeConfigurationUpdate: NodeConfigurationUpdateMode,\n};\n\nasync function invoke({ context }: Inputs): Promise<Outcome<Outputs>> {\n  const args = getArguments(context);\n  if (!ok(args)) return args;\n  const mode = MODES[Object.keys(args)[0]];\n  if (!mode) {\n    return err(`Unknown mode: ${JSON.stringify(args)}`);\n  }\n  const modeHandler = new mode(args);\n  if (!modeHandler.canAutoname()) {\n    return { context: cantAutoname() };\n  }\n  const naming = await new GeminiPrompt({\n    model: \"gemini-2.0-flash-lite\",\n    body: {\n      contents: modeHandler.prompt(),\n      safetySettings: defaultSafetySettings(),\n      generationConfig: {\n        responseMimeType: \"application/json\",\n        responseSchema: modeHandler.schema(),\n      },\n    },\n  }).invoke();\n  if (!ok(naming)) return naming;\n  return { context: naming.all };\n}\n\nasync function describe() {\n  return {\n    inputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context in\",\n        },\n      },\n    } satisfies Schema,\n    outputSchema: {\n      type: \"object\",\n      properties: {\n        context: {\n          type: \"array\",\n          items: { type: \"object\", behavior: [\"llm-content\"] },\n          title: \"Context out\",\n        },\n      },\n    } satisfies Schema,\n  };\n}\n",
          "language": "typescript"
        },
        "description": "Add a description for your module here.",
        "runnable": true
      }
    },
    "node-configuration-update": {
      "code": "/**\n * @fileoverview Handles node configuration updates\n */\nimport { isLLMContent, toText, llm } from \"./a2/utils\";\nimport {} from \"./a2/gemini\";\nimport { Template } from \"./a2/template\";\nexport { NodeConfigurationUpdateMode };\nconst USER_INPUT_TYPE = \"embed://a2/a2.bgl.json#21ee02e7-83fa-49d0-964c-0cab10eafc2c\";\nconst GENERATE_TYPE = \"embed://a2/generate.bgl.json#module:main\";\nconst DISPLAY_TYPE = \"embed://a2/a2.bgl.json#module:render-outputs\";\nconst STEPS = new Map([\n    [\n        USER_INPUT_TYPE,\n        (c) => createStepHandler(\"be presented to the application user to request their input\", textFromConfiguration(c, [\"description\"])),\n    ],\n    [\n        GENERATE_TYPE,\n        (c) => createStepHandler(`be used by one of the steps as a prompt for an LLM that outputs ${outputFromConfiguration(c)}`, textFromConfiguration(c, [\"config$prompt\"])),\n    ],\n    [\n        DISPLAY_TYPE,\n        (c) => createStepHandler(\"be used by one of the steps as a prompt for an LLM to render HTML for display\", textFromConfiguration(c, [\"text\"])),\n    ],\n]);\nfunction outputFromConfiguration(c) {\n    if (c && \"generation-mode\" in c) {\n        const mode = c[\"generation-mode\"];\n        switch (mode) {\n            case \"image-gen\":\n                return \"a single image\";\n            case \"image\":\n                return \"images and text\";\n            case \"audio\":\n                return \"audio\";\n            case \"video\":\n                return \"video\";\n            default:\n                return \"text\";\n        }\n    }\n    return \"text\";\n}\nfunction createStepHandler(typeSpecficPrompt, text) {\n    return {\n        canAutoname: text.length > 10,\n        prompt: [\n            llm `\n  Analyze the text below and provide suggestions for title and description that could be used\n  to automatically label this text as one of the steps in a visual, a no-code application builder.\n  Builders are creating applications by placing steps on a canvas and wiring them together into a visual flow.\n  This text will ${typeSpecficPrompt}.\n\n  Important:\n  - Both the title and intent must be accurate, concise, and specific to the text\n  - The description must be one sentence\n  - Each title must be verb-first, action oriented, short and to the point\n  - The builders are non-technical, so avoid overly technical jargon\n\n  Text:\n  \n  ${text}\n\n  `.asContent(),\n        ],\n    };\n}\nconst DEFAULT_STEP_HANDLER = {\n    canAutoname: false,\n    prompt: [],\n};\nfunction stepHandlerFromArgs(args) {\n    const type = args.nodeConfigurationUpdate?.type;\n    const configuration = args.nodeConfigurationUpdate?.configuration;\n    if (!type || !configuration)\n        return DEFAULT_STEP_HANDLER;\n    const factory = STEPS.get(type);\n    if (!factory)\n        return DEFAULT_STEP_HANDLER;\n    return factory(configuration);\n}\nclass NodeConfigurationUpdateMode {\n    args;\n    #stepHandler;\n    constructor(args) {\n        this.args = args;\n        this.#stepHandler = stepHandlerFromArgs(args);\n        console.log(\"PROMPT\", toText(this.#stepHandler.prompt));\n    }\n    canAutoname() {\n        return this.#stepHandler.canAutoname;\n    }\n    prompt() {\n        return this.#stepHandler.prompt;\n    }\n    schema() {\n        return {\n            type: \"object\",\n            properties: {\n                title: {\n                    type: \"string\",\n                    description: \"Suggested title for the prompt, verb-first, action oriented. Two words.\",\n                },\n                description: {\n                    type: \"string\",\n                    description: \"Suggested description for the prompt. Seven words or less\",\n                },\n            },\n            required: [\"title\", \"description\"],\n        };\n    }\n}\nfunction textFromConfiguration(configuration, allow) {\n    if (!configuration)\n        return \"\";\n    return Object.entries(configuration)\n        .map(([name, value]) => {\n        if (!allow.includes(name))\n            return \"\";\n        if (isLLMContent(value)) {\n            const template = new Template(value);\n            return toText(template.simpleSubstitute((part) => {\n                if (part.type == \"tool\")\n                    return part.title;\n                if (part.type === \"asset\")\n                    return `{{${part.title}}}`;\n                return ``;\n            }));\n        }\n        return JSON.stringify(value);\n    })\n        .join(\"\");\n}\n",
      "metadata": {
        "title": "node-configuration-update",
        "source": {
          "code": "/**\n * @fileoverview Handles node configuration updates\n */\n\nimport { isLLMContent, toText, llm } from \"./a2/utils\";\nimport { type GeminiSchema } from \"./a2/gemini\";\nimport { Template } from \"./a2/template\";\n\nimport type { AutonameMode, Arguments } from \"./types\";\n\nexport { NodeConfigurationUpdateMode };\n\nconst USER_INPUT_TYPE =\n  \"embed://a2/a2.bgl.json#21ee02e7-83fa-49d0-964c-0cab10eafc2c\";\nconst GENERATE_TYPE = \"embed://a2/generate.bgl.json#module:main\";\nconst DISPLAY_TYPE = \"embed://a2/a2.bgl.json#module:render-outputs\";\n\ntype StepHandler = {\n  canAutoname: boolean;\n  prompt: LLMContent[];\n};\n\ntype StepMap = Map<\n  string,\n  (configuration: Record<string, JsonSerializable>) => StepHandler\n>;\n\nconst STEPS: StepMap = new Map([\n  [\n    USER_INPUT_TYPE,\n    (c) =>\n      createStepHandler(\n        \"be presented to the application user to request their input\",\n        textFromConfiguration(c, [\"description\"])\n      ),\n  ],\n  [\n    GENERATE_TYPE,\n    (c) =>\n      createStepHandler(\n        `be used by one of the steps as a prompt for an LLM that outputs ${outputFromConfiguration(c)}`,\n        textFromConfiguration(c, [\"config$prompt\"])\n      ),\n  ],\n  [\n    DISPLAY_TYPE,\n    (c) =>\n      createStepHandler(\n        \"be used by one of the steps as a prompt for an LLM to render HTML for display\",\n        textFromConfiguration(c, [\"text\"])\n      ),\n  ],\n]);\n\nfunction outputFromConfiguration(\n  c: Record<string, JsonSerializable> | undefined\n) {\n  if (c && \"generation-mode\" in c) {\n    const mode = c[\"generation-mode\"] as string;\n    switch (mode) {\n      case \"image-gen\":\n        return \"a single image\";\n      case \"image\":\n        return \"images and text\";\n      case \"audio\":\n        return \"audio\";\n      case \"video\":\n        return \"video\";\n      default:\n        return \"text\";\n    }\n  }\n  return \"text\";\n}\n\nfunction createStepHandler(\n  typeSpecficPrompt: string,\n  text: string\n): StepHandler {\n  return {\n    canAutoname: text.length > 10,\n    prompt: [\n      llm`\n  Analyze the text below and provide suggestions for title and description that could be used\n  to automatically label this text as one of the steps in a visual, a no-code application builder.\n  Builders are creating applications by placing steps on a canvas and wiring them together into a visual flow.\n  This text will ${typeSpecficPrompt}.\n\n  Important:\n  - Both the title and intent must be accurate, concise, and specific to the text\n  - The description must be one sentence\n  - Each title must be verb-first, action oriented, short and to the point\n  - The builders are non-technical, so avoid overly technical jargon\n\n  Text:\n  \n  ${text}\n\n  `.asContent(),\n    ],\n  };\n}\n\nconst DEFAULT_STEP_HANDLER: StepHandler = {\n  canAutoname: false,\n  prompt: [],\n};\n\nfunction stepHandlerFromArgs(args: Arguments): StepHandler {\n  const type = args.nodeConfigurationUpdate?.type;\n  const configuration = args.nodeConfigurationUpdate?.configuration;\n  if (!type || !configuration) return DEFAULT_STEP_HANDLER;\n  const factory = STEPS.get(type);\n  if (!factory) return DEFAULT_STEP_HANDLER;\n  return factory(configuration);\n}\n\nclass NodeConfigurationUpdateMode implements AutonameMode {\n  #stepHandler: StepHandler;\n\n  constructor(public readonly args: Arguments) {\n    this.#stepHandler = stepHandlerFromArgs(args);\n    console.log(\"PROMPT\", toText(this.#stepHandler.prompt));\n  }\n\n  canAutoname() {\n    return this.#stepHandler.canAutoname;\n  }\n  prompt(): LLMContent[] {\n    return this.#stepHandler.prompt;\n  }\n\n  schema(): GeminiSchema {\n    return {\n      type: \"object\",\n      properties: {\n        title: {\n          type: \"string\",\n          description:\n            \"Suggested title for the prompt, verb-first, action oriented. Two words.\",\n        },\n        description: {\n          type: \"string\",\n          description:\n            \"Suggested description for the prompt. Seven words or less\",\n        },\n      },\n      required: [\"title\", \"description\"],\n    };\n  }\n}\n\nfunction textFromConfiguration(\n  configuration: Record<string, JsonSerializable> | undefined,\n  allow: string[]\n): string {\n  if (!configuration) return \"\";\n\n  return Object.entries(configuration)\n    .map(([name, value]) => {\n      if (!allow.includes(name)) return \"\";\n      if (isLLMContent(value)) {\n        const template = new Template(value);\n        return toText(\n          template.simpleSubstitute((part) => {\n            if (part.type == \"tool\") return part.title;\n            if (part.type === \"asset\") return `{{${part.title}}}`;\n            return ``;\n          })\n        );\n      }\n      return JSON.stringify(value);\n    })\n    .join(\"\");\n}\n",
          "language": "typescript"
        },
        "description": "Handles node configuration updates",
        "runnable": false
      }
    },
    "types": {
      "code": "/**\n * @fileoverview Common types.\n */\n",
      "metadata": {
        "title": "types",
        "source": {
          "code": "/**\n * @fileoverview Common types.\n */\n\nimport type { GeminiSchema } from \"./a2/gemini\";\n\nexport type NodeConfigurationUpdate = {\n  configuration?: Record<string, JsonSerializable>;\n  /**\n   * Node type\n   */\n  type?: string;\n};\n\nexport type Arguments = {\n  nodeConfigurationUpdate?: NodeConfigurationUpdate;\n};\n\nexport type AutonameMode = {\n  canAutoname(): boolean;\n  prompt(): LLMContent[];\n  schema(): GeminiSchema;\n};\n\n/**\n * Represents an edge in a graph.\n */\nexport type Edge = {\n  /**\n   * The node that the edge is coming from.\n   */\n  from: string;\n\n  /**\n   * The node that the edge is going to.\n   */\n  to: string;\n\n  /**\n   * The input of the `to` node. If this value is undefined, then\n   * the then no data is passed as output of the `from` node.\n   */\n  in?: string;\n\n  /**\n   * The output of the `from` node. If this value is \"*\", then all outputs\n   * of the `from` node are passed to the `to` node. If this value is undefined,\n   * then no data is passed to any inputs of the `to` node.\n   */\n  out?: string;\n\n  /**\n   * If true, this edge is optional: the data that passes through it is not\n   * considered a required input to the node.\n   */\n  optional?: boolean;\n\n  /**\n   * If true, this edge acts as a constant: the data that passes through it\n   * remains available even after the node has consumed it.\n   */\n  constant?: boolean;\n};\n\ntype PartialGraphDescriptor = {\n  title?: string;\n  metadata?: {\n    intent?: string;\n    instruction?: string;\n    userModified?: string;\n    visual?: unknown;\n  };\n  parameters?: {\n    type: \"object\";\n    properties: {\n      context: {\n        type: \"string\";\n      };\n    };\n  };\n  description?: string;\n  nodes: PartialNodeDescriptor[];\n  edges: Edge[];\n};\n\ntype PartialNodeDescriptor = {\n  id: string;\n  configuration: Record<string, object>;\n  metadata?: {\n    title?: string;\n    description?: string;\n    userModified?: boolean;\n  };\n};\n",
          "language": "typescript"
        },
        "description": "Common types.",
        "runnable": false
      }
    }
  },
  "metadata": {
    "tags": [],
    "visual": {
      "presentation": {
        "themes": {
          "98f67196-378d-4397-ae1b-fe3aead245c5": {
            "themeColors": {
              "primaryColor": "#246db5",
              "secondaryColor": "#5cadff",
              "backgroundColor": "#ffffff",
              "textColor": "#1a1a1a",
              "primaryTextColor": "#ffffff"
            },
            "template": "basic",
            "splashScreen": {
              "storedData": {
                "handle": "/images/app/generic-flow.jpg",
                "mimeType": "image/jpeg"
              }
            }
          }
        },
        "theme": "98f67196-378d-4397-ae1b-fe3aead245c5"
      }
    }
  },
  "nodes": [
    {
      "id": "input",
      "type": "input",
      "metadata": {
        "title": "Input"
      }
    },
    {
      "id": "run-module",
      "type": "runModule",
      "configuration": {
        "$module": "main"
      },
      "metadata": {
        "title": "Autonaming"
      }
    },
    {
      "id": "output",
      "type": "output",
      "metadata": {
        "title": "Output"
      }
    }
  ],
  "edges": [
    {
      "from": "input",
      "to": "run-module",
      "out": "*",
      "in": ""
    },
    {
      "from": "run-module",
      "to": "output",
      "out": "*",
      "in": ""
    }
  ]
}