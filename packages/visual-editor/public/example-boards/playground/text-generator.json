{
  "title": "Text Generator",
  "description": "This is a text generator. It can generate text using various LLMs. Currently, it supports the following models: Google Gemini Pro and OpenAI GPT-3.5 Turbo.",
  "version": "0.1.0",
  "edges": [
    {
      "from": "input-0",
      "to": "llm-response",
      "out": "text",
      "in": "text"
    },
    {
      "from": "input-0",
      "to": "runJavascript-0",
      "out": "model",
      "in": "model"
    },
    {
      "from": "llm-response",
      "to": "output-0",
      "out": "text",
      "in": "textOutput"
    },
    {
      "from": "runJavascript-0",
      "to": "llm-response",
      "out": "board",
      "in": "$board"
    },
    {
      "from": "runJavascript-0",
      "to": "llm-response",
      "out": "model",
      "in": "model"
    }
  ],
  "nodes": [
    {
      "id": "input-0",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "model": {
              "type": "string",
              "enum": [
                "Gemini Pro",
                "GPT 3.5 Turbo"
              ]
            },
            "text": {
              "type": "string",
              "title": "Text",
              "description": "The text to generate"
            }
          },
          "required": [
            "model",
            "text"
          ]
        }
      }
    },
    {
      "id": "output-0",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "textOutput": {
              "type": [
                "array",
                "boolean",
                "null",
                "number",
                "object",
                "string"
              ],
              "title": "Text",
              "description": "The generated text"
            }
          },
          "required": [
            "textOutput"
          ]
        }
      }
    },
    {
      "id": "llm-response",
      "type": "invoke",
      "configuration": {}
    },
    {
      "id": "runJavascript-0",
      "type": "runJavascript",
      "configuration": {
        "code": "const run = ({model:model2})=>{const models={\"Gemini Pro\":\"https://raw.githubusercontent.com/breadboard-ai/breadboard/main/packages/gemini-kit/graphs/gemini-generator.json\",\"GPT 3.5 Turbo\":\"https://raw.githubusercontent.com/breadboard-ai/breadboard/main/packages/visual-editor/public/example-boards/playground/openai-gpt-35-turbo.json\"};const path=models[model2];if(model2==\"Gemini Pro\"){return{board:{kind:\"board\",path},model:\"gemini-1.5-pro-latest\"}}else{return{board:{kind:\"board\",path},model:\"N/A\"}}};",
        "inputSchema": {
          "type": "object",
          "properties": {
            "model": {
              "type": "string",
              "enum": [
                "Gemini Pro",
                "GPT 3.5 Turbo"
              ]
            }
          }
        },
        "name": "run",
        "outputSchema": {
          "type": "object",
          "properties": {
            "board": {
              "type": "object",
              "properties": {
                "kind": {
                  "type": "string"
                },
                "path": {
                  "type": "string"
                }
              },
              "required": [
                "kind",
                "path"
              ],
              "additionalProperties": false
            },
            "model": {
              "type": "string"
            }
          }
        },
        "raw": true
      }
    }
  ]
}