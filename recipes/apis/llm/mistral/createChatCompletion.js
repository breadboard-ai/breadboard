import { base, recipe } from "@google-labs/breadboard";

import { core } from "@google-labs/core-kit";
import { starter } from "@google-labs/llm-starter";

/*
To run this: 

1. Create an environment variable called MISTRAL_API_KEY with your API key
2. npx breadboard run createChatCompletion.js --kit @google-labs/core-kit --kit @google-labs/llm-starter -i "{ \"api_inputs\": {
      \"authentication\": {
        \"bearer\": \"MISTRAL_API_KEY\"
      },
      \"application/json\": {
        \"messages\": [
          {
            \"role\": \"user\",
            \"content\": \"What is the best French cheese?\"
          }
        ],
        \"model\": \"mistral-small\"
      }
    }
}"
*/

const metaData = {
  title: "Create Chat Completion",
  description:
    "Creates a chat completion from the Mistral API (Generated by OpenAPI recipe)",
  version: "0.0.3",
};

/*
 Note currently the tool to generate the OpenAPI spec does not support the security Scheme, therefore secrets will not work, you have to use an input called key.
*/
export default await recipe(() => {
  const input = base.input({ $id: "input" });

  return core.invoke({
    path: "../createChatCompletion.json",
    input: input.api_inputs,
    ...input,
    ...starter.secrets({ keys: ["MISTRAL_API_KEY"] }),
  });
}).serialize(metaData);
