{
  "title": "Text Generator",
  "description": "This is a text generator. It can generate text using various LLMs. Currently, it supports the follwogin models: Google Gemini Pro, Google PaLM text-bison-001, OpenAI GPT-3.5 Turbo, and a mock model.",
  "version": "0.0.2",
  "edges": [
    {
      "from": "mock",
      "to": "textOutput",
      "out": "text",
      "in": "text"
    },
    {
      "from": "mock",
      "to": "streamOutput",
      "out": "stream",
      "in": "stream"
    },
    {
      "from": "gemini",
      "to": "textOutput",
      "out": "text",
      "in": "text"
    },
    {
      "from": "gemini",
      "to": "streamOutput",
      "out": "stream",
      "in": "stream"
    },
    {
      "from": "palmGenerator",
      "to": "textOutput",
      "out": "text",
      "in": "text"
    },
    {
      "from": "palmGenerator",
      "to": "streamOutput",
      "out": "stream",
      "in": "stream"
    },
    {
      "from": "gpt35",
      "to": "textOutput",
      "out": "text",
      "in": "text"
    },
    {
      "from": "gpt35",
      "to": "streamOutput",
      "out": "stream",
      "in": "stream"
    },
    {
      "from": "fn-3",
      "to": "mock",
      "out": "mock",
      "in": "choose"
    },
    {
      "from": "fn-3",
      "to": "gemini",
      "out": "gemini",
      "in": "choose"
    },
    {
      "from": "fn-3",
      "to": "palmGenerator",
      "out": "palm",
      "in": "choose"
    },
    {
      "from": "fn-3",
      "to": "gpt35",
      "out": "gpt35",
      "in": "choose"
    },
    {
      "from": "input",
      "to": "fn-3",
      "out": "MODEL",
      "in": "MODEL"
    },
    {
      "from": "input",
      "to": "mock",
      "out": "*",
      "in": ""
    },
    {
      "from": "input",
      "to": "gemini",
      "out": "*",
      "in": ""
    },
    {
      "from": "input",
      "to": "palmGenerator",
      "out": "*",
      "in": ""
    },
    {
      "from": "input",
      "to": "gpt35",
      "out": "*",
      "in": ""
    }
  ],
  "nodes": [
    {
      "id": "textOutput",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Text",
              "description": "The generated text"
            }
          }
        }
      }
    },
    {
      "id": "mock",
      "type": "invoke",
      "configuration": {
        "path": "mock-text-generator.json"
      }
    },
    {
      "id": "gemini",
      "type": "invoke",
      "configuration": {
        "path": "gemini-generator.json"
      }
    },
    {
      "id": "palmGenerator",
      "type": "invoke",
      "configuration": {
        "path": "palm-text-generator.json"
      }
    },
    {
      "id": "gpt35",
      "type": "invoke",
      "configuration": {
        "path": "openai-gpt-35-turbo.json"
      }
    },
    {
      "id": "fn-3",
      "type": "invoke",
      "configuration": {
        "path": "#fn-3"
      }
    },
    {
      "id": "input",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "title": "Text",
              "description": "The text to generate"
            },
            "useStreaming": {
              "type": "boolean",
              "title": "Stream",
              "description": "Whether to stream the output",
              "default": "false"
            },
            "MODEL": {
              "type": "string",
              "title": "Model",
              "description": "The model to use for generation",
              "enum": [
                "Gemini Pro",
                "GPT 3.5 Turbo",
                "PaLM",
                "mock"
              ],
              "examples": [
                "Gemini Pro"
              ]
            }
          },
          "required": [
            "text"
          ]
        }
      }
    },
    {
      "id": "streamOutput",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "stream": {
              "type": "object",
              "title": "Stream",
              "description": "The generated text",
              "format": "stream"
            }
          }
        }
      }
    }
  ],
  "graphs": {
    "fn-3": {
      "edges": [
        {
          "from": "fn-3-input",
          "to": "fn-3-run",
          "out": "*"
        },
        {
          "from": "fn-3-run",
          "to": "fn-3-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "fn-3-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "fn-3-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function fn_3({MODEL}) {switch(MODEL){case\"Gemini Pro\":return{gemini:true};case\"PaLM\":return{palm:true};case\"mock\":return{mock:true};case\"GPT 3.5 Turbo\":return{gpt35:true};default:return{other:`Unsupported model: ${MODEL}`}}}",
            "name": "fn_3",
            "raw": true
          }
        },
        {
          "id": "fn-3-output",
          "type": "output",
          "configuration": {}
        }
      ]
    }
  }
}