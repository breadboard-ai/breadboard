{
  "title": "Text Generator Recipe",
  "description": "This is a text generator. It can generate text using various LLMs. Currently, it supports the follwogin models: Google PaLM text-bison-001, OpenAI GPT-3.5 Turbo, and a mock model. The mock model simply echoes back the input text. It's good for testing.",
  "version": "0.0.1",
  "edges": [
    {
      "from": "palm-generateText-6",
      "to": "output-3",
      "out": "completion",
      "in": "text"
    },
    {
      "from": "invoke-7",
      "to": "output-3",
      "out": "text",
      "in": "text"
    },
    {
      "from": "invoke-7",
      "to": "output-4",
      "out": "stream",
      "in": "stream"
    },
    {
      "from": "fn-8",
      "to": "output-3",
      "out": "text",
      "in": "text"
    },
    {
      "from": "fn-8",
      "to": "listToStream-9",
      "out": "list",
      "in": "list"
    },
    {
      "from": "fn-10",
      "to": "palm-generateText-6",
      "out": "palm",
      "in": "palm"
    },
    {
      "from": "fn-10",
      "to": "invoke-7",
      "out": "gpt35",
      "in": "gpt35"
    },
    {
      "from": "fn-10",
      "to": "fn-8",
      "out": "mock",
      "in": "mock"
    },
    {
      "from": "fn-10",
      "to": "output-3",
      "out": "other",
      "in": "text"
    },
    {
      "from": "input-1",
      "to": "palm-generateText-6",
      "out": "text",
      "in": "text"
    },
    {
      "from": "input-1",
      "to": "invoke-7",
      "out": "text",
      "in": "text"
    },
    {
      "from": "input-1",
      "to": "invoke-7",
      "out": "useStreaming",
      "in": "useStreaming"
    },
    {
      "from": "input-1",
      "to": "fn-8",
      "out": "text",
      "in": "text"
    },
    {
      "from": "input-1",
      "to": "fn-8",
      "out": "useStreaming",
      "in": "useStreaming"
    },
    {
      "from": "input-1",
      "to": "fn-10",
      "out": "model",
      "in": "model"
    },
    {
      "from": "input-1",
      "to": "fn-10",
      "out": "useStreaming",
      "in": "useStreaming"
    },
    {
      "from": "secrets-5",
      "to": "palm-generateText-6",
      "out": "PALM_KEY",
      "in": "PALM_KEY"
    },
    {
      "from": "listToStream-9",
      "to": "output-4",
      "out": "*",
      "in": ""
    }
  ],
  "nodes": [
    {
      "id": "output-3",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "description": "The generated text",
              "title": "Text"
            }
          },
          "required": [
            "text"
          ],
          "additionalProperties": false
        }
      }
    },
    {
      "id": "palm-generateText-6",
      "type": "palm-generateText",
      "configuration": {}
    },
    {
      "id": "invoke-7",
      "type": "invoke",
      "configuration": {
        "path": "openai-gpt-35-turbo.json"
      }
    },
    {
      "id": "fn-8",
      "type": "invoke",
      "configuration": {
        "path": "#fn-8"
      }
    },
    {
      "id": "fn-10",
      "type": "invoke",
      "configuration": {
        "path": "#fn-10"
      }
    },
    {
      "id": "input-1",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "text": {
              "type": "string",
              "description": "The text to generate",
              "title": "Text"
            },
            "useStreaming": {
              "type": "boolean",
              "description": "Whether to stream the output",
              "default": false,
              "title": "Stream"
            },
            "model": {
              "type": "string",
              "enum": [
                "PaLM",
                "GPT 3.5 Turbo",
                "mock"
              ],
              "description": "The model to use for generation",
              "default": "PaLM",
              "title": "Model"
            }
          },
          "required": [
            "text"
          ],
          "additionalProperties": false
        }
      }
    },
    {
      "id": "secrets-5",
      "type": "secrets",
      "configuration": {
        "keys": [
          "PALM_KEY"
        ]
      }
    },
    {
      "id": "output-4",
      "type": "output",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "stream": {
              "type": "object",
              "title": "Stream",
              "description": "The generated text",
              "format": "stream"
            }
          }
        }
      }
    },
    {
      "id": "listToStream-9",
      "type": "listToStream",
      "configuration": {}
    }
  ],
  "graphs": {
    "fn-8": {
      "edges": [
        {
          "from": "fn-8-input",
          "to": "fn-8-run",
          "out": "*"
        },
        {
          "from": "fn-8-run",
          "to": "fn-8-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "fn-8-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "fn-8-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function fn_8(inputs2) {const{text,useStreaming}=inputs2;const result=`Mock model with streaming off echoes back: ${text}`;if(useStreaming){const list=result.split(\" \");return{list}}return{text:result}}",
            "name": "fn_8",
            "raw": true
          }
        },
        {
          "id": "fn-8-output",
          "type": "output",
          "configuration": {}
        }
      ]
    },
    "fn-10": {
      "edges": [
        {
          "from": "fn-10-input",
          "to": "fn-10-run",
          "out": "*"
        },
        {
          "from": "fn-10-run",
          "to": "fn-10-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "fn-10-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "fn-10-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function fn_10({model,useStreaming}) {switch(model){case\"PaLM\":if(useStreaming){return{other:`Streaming is not supported for ${model}`}}return{palm:true};case\"mock\":return{mock:true};case\"GPT 3.5 Turbo\":return{gpt35:true};default:return{other:`Unsupported model: ${model}`}}}",
            "name": "fn_10",
            "raw": true
          }
        },
        {
          "id": "fn-10-output",
          "type": "output",
          "configuration": {}
        }
      ]
    }
  }
}