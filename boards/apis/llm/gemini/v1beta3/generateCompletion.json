{
  "url": "file:///Users/paulkinlan/Code/labs-prototypes/recipes/apis/llm/gemini/v1beta3/generateCompletion.json",
  "title": "Generate Completion",
  "description": "Creates a completion from Gemini for use in generateCompletion standard recipe",
  "version": "0.0.3",
  "edges": [
    {
      "from": "convertGeminiGenerateTextResponse",
      "to": "output-2",
      "out": "*",
      "in": ""
    },
    {
      "from": "invoke-3",
      "to": "convertGeminiGenerateTextResponse",
      "out": "*",
      "in": ""
    },
    {
      "from": "convertGeminiGenerateTextRequest",
      "to": "invoke-3",
      "out": "*",
      "in": ""
    },
    {
      "from": "input-1",
      "to": "convertGeminiGenerateTextRequest",
      "out": "prompt",
      "in": "prompt"
    },
    {
      "from": "input-1",
      "to": "convertGeminiGenerateTextRequest",
      "out": "temperature",
      "in": "temperature"
    },
    {
      "from": "input-1",
      "to": "convertGeminiGenerateTextRequest",
      "out": "topP",
      "in": "topP"
    },
    {
      "from": "input-1",
      "to": "convertGeminiGenerateTextRequest",
      "out": "topK",
      "in": "topK"
    }
  ],
  "nodes": [
    {
      "id": "output-2",
      "type": "output",
      "configuration": {}
    },
    {
      "id": "convertGeminiGenerateTextResponse",
      "type": "invoke",
      "configuration": {
        "path": "#convertGeminiGenerateTextResponse"
      }
    },
    {
      "id": "invoke-3",
      "type": "invoke",
      "configuration": {
        "path": "./api/generativelanguage.models.generateText.json"
      }
    },
    {
      "id": "convertGeminiGenerateTextRequest",
      "type": "invoke",
      "configuration": {
        "path": "#convertGeminiGenerateTextRequest"
      }
    },
    {
      "id": "input-1",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "prompt": {
              "title": "prompt",
              "description": "The prompt to complete",
              "type": "string"
            },
            "temperature": {
              "title": "temperature",
              "description": "The model temperature (0.0-1.0 - lower value more creative)",
              "type": "number",
              "default": 0.9
            },
            "topP": {
              "title": "topP",
              "description": "The model topP",
              "type": "number",
              "default": 1
            },
            "topK": {
              "title": "topK",
              "description": "The model topK",
              "type": "number",
              "default": 1
            }
          },
          "required": [
            "prompt"
          ]
        }
      }
    }
  ],
  "kits": [],
  "graphs": {
    "convertGeminiGenerateTextResponse": {
      "edges": [
        {
          "from": "convertGeminiGenerateTextResponse-input",
          "to": "convertGeminiGenerateTextResponse-run",
          "out": "*"
        },
        {
          "from": "convertGeminiGenerateTextResponse-run",
          "to": "convertGeminiGenerateTextResponse-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "convertGeminiGenerateTextResponse-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "convertGeminiGenerateTextResponse-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function convertGeminiGenerateTextResponse(api_response) {\n    return { text_response: api_response.candidates[0].content.parts.text };\n  }",
            "name": "convertGeminiGenerateTextResponse",
            "raw": true
          }
        },
        {
          "id": "convertGeminiGenerateTextResponse-output",
          "type": "output",
          "configuration": {}
        }
      ]
    },
    "convertGeminiGenerateTextRequest": {
      "edges": [
        {
          "from": "convertGeminiGenerateTextRequest-input",
          "to": "convertGeminiGenerateTextRequest-run",
          "out": "*"
        },
        {
          "from": "convertGeminiGenerateTextRequest-run",
          "to": "convertGeminiGenerateTextRequest-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "convertGeminiGenerateTextRequest-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "convertGeminiGenerateTextRequest-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function convertGeminiGenerateTextRequest({ prompt, temperature, topP, topK }) {\n    const request = {\n      temperature: temperature,\n      // maxOutputTokens: api_inputs.maxOutputTokens || undefined,\n      topK: topK,\n      // candidateCount: undefined, // candidateCount is not well defined across LLMs as a concept yet.\n      topP: topP,\n      prompt: {\n        text: prompt,\n      },\n      // stopSequences: api_inputs.stopSequences || undefined,\n      // safetySettings: undefined, // Safety Settings is not well defined across LLMs as a concept yet.\n    };\n\n    return { requestBody: request };\n  }",
            "name": "convertGeminiGenerateTextRequest",
            "raw": true
          }
        },
        {
          "id": "convertGeminiGenerateTextRequest-output",
          "type": "output",
          "configuration": {}
        }
      ]
    }
  }
}