{
  "url": "file:///Users/paulkinlan/Code/labs-prototypes/boards/apis/llm/mistral/createCompletion.json",
  "title": "Generate Completion with Mistral",
  "description": "Creates a completion from Mistral for use in generateCompletion standard board",
  "version": "0.0.3",
  "edges": [
    {
      "from": "convertMistralcreateChatCompletionResponse",
      "to": "output-2",
      "out": "*",
      "in": ""
    },
    {
      "from": "invoke-3",
      "to": "convertMistralcreateChatCompletionResponse",
      "out": "*",
      "in": ""
    },
    {
      "from": "convertMistralcreateChatCompletionRequest",
      "to": "invoke-3",
      "out": "*",
      "in": ""
    },
    {
      "from": "input-1",
      "to": "convertMistralcreateChatCompletionRequest",
      "out": "prompt",
      "in": "prompt"
    },
    {
      "from": "input-1",
      "to": "convertMistralcreateChatCompletionRequest",
      "out": "temperature",
      "in": "temperature"
    },
    {
      "from": "input-1",
      "to": "convertMistralcreateChatCompletionRequest",
      "out": "topP",
      "in": "topP"
    },
    {
      "from": "input-1",
      "to": "convertMistralcreateChatCompletionRequest",
      "out": "model",
      "in": "model"
    },
    {
      "from": "input-1",
      "to": "convertMistralcreateChatCompletionRequest",
      "out": "authentication",
      "in": "authentication"
    }
  ],
  "nodes": [
    {
      "id": "output-2",
      "type": "output",
      "configuration": {}
    },
    {
      "id": "convertMistralcreateChatCompletionResponse",
      "type": "invoke",
      "configuration": {
        "path": "#convertMistralcreateChatCompletionResponse"
      }
    },
    {
      "id": "invoke-3",
      "type": "invoke",
      "configuration": {
        "path": "./api/createChatCompletion.json"
      }
    },
    {
      "id": "convertMistralcreateChatCompletionRequest",
      "type": "invoke",
      "configuration": {
        "path": "#convertMistralcreateChatCompletionRequest"
      }
    },
    {
      "id": "input-1",
      "type": "input",
      "configuration": {
        "schema": {
          "type": "object",
          "properties": {
            "prompt": {
              "title": "prompt",
              "description": "The prompt to complete",
              "type": "string"
            },
            "temperature": {
              "title": "temperature",
              "description": "The model temperature (0.0-1.0 - lower value more creative)",
              "type": "number",
              "default": 0.7
            },
            "topP": {
              "title": "topP",
              "description": "The model topP",
              "type": "number",
              "default": 1
            },
            "model": {
              "title": "model",
              "description": "The model to interact with",
              "default": "mistral-small",
              "type": "string"
            },
            "authentication": {
              "type": "string",
              "title": "authentication"
            }
          },
          "required": [
            "prompt",
            "model",
            "authentication"
          ]
        }
      }
    }
  ],
  "kits": [],
  "graphs": {
    "convertMistralcreateChatCompletionResponse": {
      "edges": [
        {
          "from": "convertMistralcreateChatCompletionResponse-input",
          "to": "convertMistralcreateChatCompletionResponse-run",
          "out": "*"
        },
        {
          "from": "convertMistralcreateChatCompletionResponse-run",
          "to": "convertMistralcreateChatCompletionResponse-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "convertMistralcreateChatCompletionResponse-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "convertMistralcreateChatCompletionResponse-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function convertMistralcreateChatCompletionResponse({ api_json_response }) {\n      return { text_response: api_json_response.choices[0].message.content };\n    }",
            "name": "convertMistralcreateChatCompletionResponse",
            "raw": true
          }
        },
        {
          "id": "convertMistralcreateChatCompletionResponse-output",
          "type": "output",
          "configuration": {}
        }
      ]
    },
    "convertMistralcreateChatCompletionRequest": {
      "edges": [
        {
          "from": "convertMistralcreateChatCompletionRequest-input",
          "to": "convertMistralcreateChatCompletionRequest-run",
          "out": "*"
        },
        {
          "from": "convertMistralcreateChatCompletionRequest-run",
          "to": "convertMistralcreateChatCompletionRequest-output",
          "out": "*"
        }
      ],
      "nodes": [
        {
          "id": "convertMistralcreateChatCompletionRequest-input",
          "type": "input",
          "configuration": {}
        },
        {
          "id": "convertMistralcreateChatCompletionRequest-run",
          "type": "runJavascript",
          "configuration": {
            "code": "function convertMistralcreateChatCompletionRequest({ model, prompt, temperature, topP, authentication }) {\n        const request = {\n          messages: [\n            {\n              role: \"user\",\n              content: prompt,\n            },\n          ],\n          temperature: temperature,\n          model,\n          top_p: topP,\n        };\n\n        return { authentication, requestBody: request };\n      }",
            "name": "convertMistralcreateChatCompletionRequest",
            "raw": true
          }
        },
        {
          "id": "convertMistralcreateChatCompletionRequest-output",
          "type": "output",
          "configuration": {}
        }
      ]
    }
  }
}